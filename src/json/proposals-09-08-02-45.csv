id,Name,Email,Organization,Role,Bio,bluesky,mastodon,linkedin,github,website,twitter,Title,Language,Track,Abstract,Details,Status,meta,lastEmailSent,lastEmailTemplate,logs,file
183,Xitong LI,lix@hec.fr,法国巴黎高等商学院 (HEC),信息系统和运营管理教授," 2006 年获清华大学工程学博士，后获 MIT 斯隆管理学院管理学博士。研究领域涵盖信息技术经济学、社交媒体、AI 等，聚焦数字经济与 AI 影响，采用计量经济分析等方法。
成果发表于多本顶级期刊，获多项学术奖，研究获 ANR、Hi! PARIS 等资助。现任多刊编辑，曾主导学术会议，创办高管论坛促产学融合，获 INFORMS 早期职业奖等，近年研究 AI 与人类决策协作等。",(N/A),(N/A),https://www.linkedin.com/in/xitong-li-b61ba121?originalSubdomain=fr,(N/A),https://www.hec.edu/en/faculty-research/faculty-directory/faculty-member/li-xitong,(N/A),Understanding the impacts of different AI-empowered applications from a research perspective,English,AI Next,"Given AI’ abilities to process “big data” and perform the tasks consistently, algorithms are expected to outperform humans in many circumstances. We therefore see vast implementations of algorithmic decision-makers, advisors, and recommenders in our business and society, with the least mature category of algorithmic decision-makers and the most mature category of algorithmic recommenders. With the recent emergence and rising of generative AI, new forms of applications with more capabilities than ever have emerged. In this seminar, I will introduce a series of published and ongoing research works that aim to understand the impact of the various AI-empowered applications and their interactions with humans from a research perspective.",(N/A),Accept,[object Object],1757313838992,proposal-hangzhou-accepted,[object Object],(N/A)
182,申小伟,yoter@126.com,沐曦,资深经理,2017年博士毕业于中科院计算所，主要研究方向为计算机系统结构和高性能计算。现在负责沐曦推理引擎产品研发。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),沐曦推理引擎的极致性能,Chinese,Chitu Community 1st Meetup,主要介绍沐曦小模型和LLM推理引擎产品,(N/A),Accept,[object Object],1757089394188,proposal-hangzhou-accepted,[object Object],(N/A)
181,李智星,zhixing.li@z.ai,智谱,副总裁,"李智星，男，副教授，硕导，清华大学博士后，智谱副总裁。研究方向为人工智能、机器学习、自然语言处理。
历任重庆邮电大学副教授、阿里巴巴人工智能实验室知识问答算法负责人，满帮集团AI算法总监。在KEG实验室工作期间，担任欧盟第七框架国际合作项目XLIKE主研。在重庆邮电大学工作期间，任三项国家重点研发计划研究骨干，主持并完成国家级项目一项，省部级项目三项。主导了阿里巴巴首款智能硬件设备天猫精灵的知识问答引擎建设及满帮集团算法中台建设。在智谱负责公司重点战略客户招商银行、招商局集团、邮储银行、建设银行、工商银行、平安保险、北京政数局等多个关键性项目。",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),GLM：从想象力到生产力,Chinese,Chitu Community 1st Meetup,  以“让机器像人一样思考，用可信赖AI让人类更美好”为愿景，智谱致力于打造新一代认知智能大模型，专注于做大模型的中国创新。   2025 年 1 月，智谱发布全新端到端模型 GLM-Realtime，支持清唱、2 分钟记忆及 Function Call 功能。3 月，智谱发布首个具备深度研究和操作能力的 AI Agent，AutoGLM 沉思。7 月，智谱发布新一代旗舰模型 GLM-4.5，首次在单个模型中实现将推理、编码和智能体能力原生融合，以满足智能体应用的复杂需求。在 MMLU Pro、AIME 24、HLE 等 12 个最具有代表性的评测基准中，GLM-4.5 的综合平均分取得全球模型第三、国产模型第一，开源模型第一。,(N/A),Accept,[object Object],1757089483430,proposal-hangzhou-accepted,[object Object],(N/A)
180,李冀,470390366@qq.com,上海智能算力科技有限公司,上海仪电智算科技maas平台负责人,上海仪电智算科技maas平台,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),自主创新算力平台建设,Chinese,Chitu Community 1st Meetup,"YiCloud 仪电智算云平台摘要
核心定位
YiCloud 仪电智算云是面向 AI 应用落地的 ​训推一体智算云平台，致力于解决 AI 模型从研发到规模化部署的核心痛点，实现“开发即上线”的高效闭环。
关键能力

1.​训推一体化架构​
•统一平台支持训练、微调、推理全流程
•消除平台孤岛，实现模型从训练到服务的无缝衔接
•支持多模型版本管理与灰度发布
  
2.​智能资源调度​
•异构资源智能调度（支持 NVIDIA/昇腾/沐曦/壁仞/天数等国产芯片）
•万卡级任务秒级下发能力
•训练资源利用率 >99%，有效解决资源闲置问题
  
3.​弹性推理服务​
•高并发动态调度技术
•支持按指标自动扩缩容
•保障业务高峰期的稳定服务（成本可控、性能不降）
  
4.​国产化全栈适配​
•芯片层：兼容主流国产AI芯片
•框架层：深度适配 DeepLink 训练框架
•引擎层：支持国产 chitu 推理引擎
•模型层：适配 Qwen、DeepSeek 等国产大模型
  
",(N/A),Accept,[object Object],1757089476104,proposal-hangzhou-accepted,[object Object],(N/A)
179,William Guo,guowei@whaleops.com,WhaleOps,CEO,"CEO of WhaleOps, ASF Member, Apache DolphinScheduler PMC, Apache SeaTunnel PMC, Author of the book Data Analytics Thinking 《数据分析思维》 
With over 20 years of experience in the field, William has held key big data roles at Teradata, IBM, and CICC. He also served as Head of Data at Wanda E-commerce, led the big data platform at Lenovo, and was CTO of Analysys.
",(N/A),(N/A),https://www.linkedin.com/in/williamk2000/,(N/A),(N/A),(N/A),Crossing Borders: Turning Open Source Innovation into a Global Business,Chinese,Open Source Globalization Workshop,"In this age of limitless digital possibilities, open source is not only a symbol of technological innovation but also a key driver of global business expansion. This talk will take you through the journey of open source projects from inception to crossing borders and entering global markets. As a founder who started in the open source community and successfully turned it into a global business, I will share how open source innovation can break regional barriers and gain the support of global enterprises and investors.

We will explore how to build a sustainable business model using open source, tackle challenges in different markets, and commercialize globally. Through real-life case studies, I will analyze how to turn technological passion and community support into long-term business success.

If you're a technical founder facing the challenge of expanding your open source project from local to global markets, or if you're interested in how open source entrepreneurship can scale globally, this talk will provide you with practical insights and strategies.",(N/A),Accept,[object Object],1757053666457,proposal-hangzhou-accepted,[object Object],(N/A)
178,Jian Li,lijian@chitu.ai,Qingcheng.ai,Software Engineer,Chitu Developer @ Qingcheng.ai,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),从 “能跑” 到 “好用”：Chitu 工业化部署实践与效率工具链,Chinese,Chitu Community 1st Meetup,"分享 Chitu 大模型工业化部署：讲工具链提效案例，给可复用落地经验。​
",(N/A),Accept,[object Object],1757053678881,proposal-hangzhou-accepted,[object Object],(N/A)
177,Matt Carroll and Jesse Ezell,jezell@gmail.com,Join The Flock,Maintainers,"Matt is a Flutter developer, consultant, and educator. He worked on the Flutter team from 2018-2020. Today, Matt is dedicated to helping the world adopt Flutter.

Jesse is an active member of the Flutter community and has contributed to many flutter libraries as well as to the Flutter engine.",(N/A),(N/A),(N/A),https://github.com/join-the-flock/flock,(N/A),(N/A),Nest: Hatching New Flutters,English,Flutter Meetup,"Flutter is one of the most exciting cross-platform frameworks today—but anyone who has worked closely with it knows the pain of waiting for upstream fixes, struggling with forks, and maintaining patches. That’s why we created Nest: a toolkit for extending Flutter’s engine and framework without fracturing the ecosystem.

In this talk, we’ll share why Nest exists, how it works, and the challenges we’ve faced in building it. We’ll dig into the technical design, CI/CD pipelines, and the practical realities of hosting engine binaries for developers who need faster iteration than the Flutter team allows. 

Key Topics

Why we created Nest tools—and what problems they solve

How Nest integrates with Flutter’s engine and toolchain

The (hard) lessons of maintaining forks and patch files

Building and testing the engine on GitHub CI/CD

Hosting and distributing engine binaries at scale

How Flutter upstream changes break us—and how we recover
",(N/A),Accept,[object Object],1757053434558,proposal-hangzhou-accepted,[object Object],(N/A)
176,Runqing Zhang,zhangrq24@mails.tsinghua.edu.cn,Tsinghua University,Student,"2Year PhD Student @ Department of Computer Science and Technology, Tsinghua University",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Chitu and Optimizations and Parallel Inference of LLM,Chinese,Keynote Speaking,This talk is about parallel inference technologies and optimizations on LLM inference and optimization practices on Chitu inference system.,(N/A),Accept,[object Object],1757053714895,proposal-hangzhou-accepted,[object Object],(N/A)
175,贾志宾,jiazhibin@huawei.com,华为,昇腾生态技术专家,聚焦昇腾技术生态深化合作，致力打造三方生态昇腾竞争力。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),CANN开源开放分层解耦技术栈,Chinese,Chitu Community 1st Meetup,昇腾CANN开源开放策略及分层解耦技术栈分享,(N/A),Accept,[object Object],1757054121551,proposal-hangzhou-accepted,[object Object],(N/A)
174,唐适之,tangshizhi@qingcheng.ai,清程极智,联合创始人,唐适之，清华大学博士，清程极智联合创始人，负责清程极智训练推理框架、算子优化等各类技术研发。唐适之的主要学术研究领域包括面向 GPU 等加速器的编译优化，代表工作为 FreeTensor 编程框架。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),赤兔的前世今生和未来,Chinese,Chitu Community 1st Meetup,赤兔推理引擎是在开源社区活跃开发中的支持多元算力的大模型推理引擎。本报告介绍赤兔推理引擎的诞生历史、技术演进与未来构想。,(N/A),Accept,[object Object],1757053732818,proposal-hangzhou-accepted,[object Object],(N/A)
173,hugejile,hugejile@huawei.com,huawei,Advisory Operation Manager ,Potential developer of HarmonyOS,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),鸿蒙行业创新解决方案：构建更加智能的应用服务体验,Chinese,Apps & Agents,行业智能化需求升级、设备壁垒待破之际，本次分享聚焦鸿蒙行业创新解决方案：从其分布式技术、全场景协同能力切入，详解鸿蒙app的行业解决方案，助力企业开发降本增效。,(N/A),Accept,[object Object],1756918455479,proposal-hangzhou-accepted,[object Object],(N/A)
172,Abdallah ESSA,abdallah.essa@afnor.org,Afnor Group,Head of AI & NLP,"Abdallah is a senior data scientist specializing in artificial intelligence and natural language processing. With extensive experience in both academia and industry, he excels at leveraging AI to optimize business processes, leading NLP projects, and implementing MLOps and data governance.
He currently serves as Head of Data Science at the French Standardization Association, where since 2023 he has been leading the development of innovative AI systems such as conversational intelligent assistants, automated requirement detection for standards texts, as well as AI ethics and governance initiatives.",(N/A),(N/A),https://www.linkedin.com/in/essa-abdallah/?locale=fr_FR,(N/A),(N/A),(N/A),Information Retrieval Beyond Keywords: Unlocking Regulatory and Standards Knowledge at Scale,English,AI Next,"Industries worldwide depend on vast collections of regulatory texts, standards, and compliance documents—each often running hundreds of pages and continuously evolving. Navigating hundreds of thousands of these long, complex documents is a daily challenge for organizations seeking to stay compliant, innovate, and make informed decisions. Traditional keyword-based search tools often return overwhelming or irrelevant results, leaving users without the precise, context-aware information they need.
This talk explores modern Information Retrieval (IR) techniques tailored for regulatory and standards-driven domains. We will examine how passage-level retrieval, dense embeddings, and hybrid ranking models can improve both precision and usability when dealing with large-scale, domain-specific document collections. Real-world challenges such as document segmentation, preserving legal/technical context, evaluation in subjective domains, and integration with decision-support systems will be addressed.
By combining theoretical insights with deployment experience in standards and compliance contexts, this session provides researchers, practitioners, and decision-makers with a roadmap for building scalable retrieval systems that transform regulatory complexity into actionable knowledge.","Setting the Stage
The IR problem in domains like legal, regulatory, and technical standards.
User expectations: pinpointing obligations, requirements, or best practices rather than retrieving entire documents.
Challenges in Regulatory & Standards Retrieval
Document segmentation: breaking 300-page standards or directives into meaningful passages.
Indexing and scalability: efficient retrieval across hundreds of thousands of documents.
Context preservation: ensuring retrieved requirements aren’t misleading when removed from their surrounding clauses.
Evaluation: precision and recall in domains where “relevance” is subjective and high-stakes.
State-of-the-Art Approaches
Sparse retrieval (BM25 and variants) vs. dense retrieval (vector embeddings).
Hybrid models for balancing explainability (needed in regulated sectors) with performance.
Passage retrieval and transformer-based rerankers for regulatory texts.
Domain adaptation: tuning models on standards/regulations without large labeled datasets.
Deployment Lessons and Case Studies
Experiences from deploying retrieval pipelines in compliance and standardization ecosystems.
Trade-offs: accuracy vs. latency vs. cost in real regulatory environments.
Integration into downstream workflows: compliance checking, audits, or standards-based decision support.
Practical Takeaways
A framework for addressing IR challenges in long, high-stakes documents.
When and how to use sparse, dense, or hybrid methods.
Evaluation strategies beyond benchmark datasets, tuned for compliance contexts.
Design principles for scalable, domain-adapted IR systems in regulation and standards.",Accept,[object Object],1756859626929,proposal-hangzhou-accepted,[object Object],(N/A)
171,Weiqi Zhao,zhaoweiqi@gmail.com,Rokid,"Global Senior Director of Product, Engineering and Ecosystem","Weiqi Zhao is a serial entrepreneur and product leader with over a decade of experience in AI and AR. He has led the design and launch of award-winning AR glasses and intelligent hardware recognized by Red Dot and iF Design Awards. At Rokid, he has driven the development of AR Studio, AR Lite, and Rokid Glasses, expanding applications across industrial, education, retail, and cultural sectors. He also leads Rokid’s global developer ecosystem, fostering innovation in spatial computing and intelligent agents worldwide.",(N/A),(N/A),https://www.linkedin.com/in/weiqizhao/,(N/A),(N/A),(N/A),From Multimodal to Intelligent Agents: AI+AR Driving Human–Machine Symbiosis 从多模态到智能体：AI+AR驱动的人机共生,English,Apps & Agents,"This talk explores how AI and AR converge to transform human–computer interaction. With Rokid AR Studio, AR Lite, and Rokid Glasses, we showcase real-world practices in multimodal sensing, agent memory, and lightweight wearable design.","The convergence of AI and AR is transforming human–computer interaction from passive commands to proactive intelligence. In this session, we will share:
	1.	Trends & Opportunities – Why multimodal interaction and intelligent agents define the next era of computing.
	2.	Rokid Product Practices – How AR Studio enables industrial and educational spatial computing, how AR Lite makes AR accessible with lightweight design, and how Rokid Glasses embed AI agents into everyday life.
	3.	Agent Architecture – Short-term and long-term memory design for contextual, proactive, and personalized experiences.
	4.	Case Studies – From industrial inspection and retail engagement to global developer ecosystem co-creation.
	5.	Future Outlook – How lightweight AI wearables will empower immersive, natural, and personalized human–AI symbiosis.",Accept,[object Object],1756830748569,proposal-hangzhou-accepted,[object Object],(N/A)
170,王佳梁,956085592@qq.com,上海交大工业技术创新研究院,上海交大工研院 执行院长 超脑AI孵化器 发起人 纽交所上市触宝创始人 上海交大人工智能校友会副会长兼秘书长 云启资本 投资合伙人 达沃斯世界经济论坛 全球杰出青年,连续创业者,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),AI时代的创新教育,Chinese,AI Next,通用人工智能时代的到来，改变了教育的格局与范式。AI时代，教育面临着哪些新的挑战？可能的出路在哪里？超脑AI孵化器做了一系列的教育探索，探讨了AI时代教育的根本性变革，验证了教育的多种可能性。,"
AI时代对教育的根本性冲击
90%的白领工作将被AI取代：传统教育体系（以筛选为目标）面临失效，学历的筛选价值下降。
职业去中心化：未来99%的人可能成为自由职业者，“鸡娃”和名校竞争失去意义。
教育本质的转变：从“培养标准化执行者”转向“培养适应AI时代的超级个体”。
AI时代的教育目标
教育应培养三类核心能力：
AI原住民（AI Native）：熟练使用AI工具（如大语言模型、AI绘图、编程辅助）。具备批判性思维，能识别AI幻觉，进行信息验证。掌握人机协作的工作流拆分与优化能力。
未知探险家（VUCA Player）：终身学习能力，利用AI快速掌握新知识。问题发现与重构能力，从模糊需求中定义可解决的问题。敏捷实践与迭代能力（MVP思维、快速验证反馈）。
独特创造者（Unique Creator）：保持思维独立性，避免过度依赖AI。关注人文关怀，为特定人群或社会问题创造价值。强调多样性，认为“唯有你参与的创造才有意义”。
教育模式的创新实践
超脑AI孵化器的实验：
通过黑客松、文创营等非营利项目，验证“AI+教育”新范式。
案例：10后学生用AI工具7天开发游戏、阿尔茨海默症筛查应用等。
真实世界学习：打破学校围墙，解决真实问题（如老龄化、环保等）。
学生从“知识消费者”变为“价值创造者”。
生命影响生命：教育不仅是知识传递，更是导师的价值观、生命状态对学生的影响。
未来教育的核心驱动力
热爱与内驱力：AI时代物质丰裕，教育需从“恐惧驱动”转向“热爱驱动”。
情绪价值：AI无法替代人性温度，情感联结成为未来商业与教育的核心价值。
技术平权：AI降低创作门槛，未来差异在于“品味”与“愿力”（是否愿意长期投入热爱之事）。
对传统教育的颠覆性观点
“我的孩子不用上大学”：学历贬值，能力与创造力更重要。
引用Sam Altman的“万物摩尔定律”：教育成本将大幅降低，终身学习成为常态。
学习即创造：学生应直接参与商业闭环（如孵化创业项目分红），而非被动接受知识。

总结：AI时代的教育不再是筛选工具，而是培养“好奇、热爱、自驱”的超级个体。未来的赢家不是“做题家”，而是能驾驭AI、解决真实问题、并保持人性温度的创造者。教育必须打破围墙，回归本质——用生命影响生命，用热爱驱动创造。",Accept,[object Object],1756760307823,proposal-hangzhou-accepted,[object Object],(N/A)
169,王剑锋,1448376744@qq.com,杭州颉创科技有限公司,架构工程师,杭州颉创科技有限公司架构工程师，拥有近十年Web服务后端架构研发经验。长期深耕C#与ASP.NET Core技术生态，专注于构建高性能、高可用的服务体系，擅长处理复杂业务场景下的大规模数据统计与高性能SQL查询优化。目前专注于基于仓颉语言的现代化Web框架研发，作为核心开发者与仓颉官方团队合作，主导开发新一代轻量级、高性能的Spire（天擎）Web框架。该框架深度借鉴ASP.NET Core的设计哲学与先进理念，致力于为复杂企业级应用提供卓越的开发体验、极致的性能表现和高度的可扩展性。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Spire 天擎 Web框架介绍,Chinese,Cangjie Workshop,"Spire天擎，作为首个专为企业级应用设计的Web开发框架，它通过融合现代Web开发理念与仓颉语言特性，为开发者提供Web开发技术解决方案。
架构设计层面，天擎整体设计借鉴了ASP.NET Core的模块化设计思想，采用中间件管道、依赖注入等现代化模式，在保持轻量级内核的同时，实现了出色的性能表现与横向扩展能力。框架通过精心设计的API接口层，显著降低了仓颉语言开发者构建复杂Web应用的门槛。
技术实现部分，我们将通过实际代码案例演示，展示如何利用仓颉来构建一个Web API服务场景，体现仓颉Web开发场景下的实际开发体验。
最后，我们将探讨如何协同开发者社区共建Web开发生态，共同推动仓颉语言在Web领域的技术创新。",(N/A),Accept,[object Object],1756760329125,proposal-hangzhou-accepted,[object Object],(N/A)
168,丁心民,bding@dora-rs.org,dora-rs 社区,生态系统负责人,Dora-rs 社区生态系统负责人，专注于推动基于 Dora 的开源生态建设。他的工作涵盖具身智能（Embodied Intelligence）、社区协作以及生态激励机制等方向，致力于为开发者打造开放、可持续发展的技术与社区环境.,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),开放生态中的创新与共建- Dora-rs 社区的活动与展望,Chinese,Dora Workshop,"本次演讲将深入介绍Dora-rs作为新一代智能机器人高性能开发框架的技术特性与生态发展。演讲将重点展示Dora-rs在开源鸿蒙生态中的创新实践，包括与高校，开源鸿蒙社区，OpenLoong人形机器人的深度合作、以及面向社区提供开发软硬件工具链等。通过分享GOSIM黑客松、展会，社区培训课程等活动经验，展望Dora-rs如何通过开放协作模式，推动国产机器人技术自主可控发展，构建""AI优先""的机器人开发新范式。",(N/A),Accept,[object Object],1756760319155,proposal-hangzhou-accepted,[object Object],(N/A)
167,Yonghua Lin,yhlin@baai.ac.cn,Beijing Academy of Artificial Intelligence,VP of BAAI,"Yonghua Lin is the Vice President and Chief Engineer of Beijing Academy of Artificial Intelligence, responsible for AI System, and Large Model Foundation Technology research, industry and open-source ecosystem cooperation. She is formerly the Director of IBM China Research Lab and Distinguished Engineer at IBM, she led global AI system innovation within IBM. She has been engaged in research on system architecture, cloud computing, AI systems, computer vision, and other fields for more than 20 years. She holds over 50 global patents and has won the ACM/IEEE Best Paper awards. She was named one of the ""50 Leading Female Tech Leaders in China"" by Forbes in 2019. She is member of IEEE Women in Engineering Asia Pacific Leadership Team and the founder of IEEE Women in Engineering Beijing affinity.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),"Open Data, Open Compute and Open Evaluation for Embodied AI innovation",English,Keynote Speaking,"Embodied AI represents a significant innovation in the current development of artificial intelligence, especially large language models. Training data, cloud-edge computing, and evaluation will form the three cornerstones of Embodied Intelligence. However, these areas present even greater technological challenges than those faced by large models, making global collaboration essential for progress. In this speech, I will explore the new challenges (beyond those of large models) arising from the evolution of large models to Embodied Intelligence, particularly in data, cloud-edge computing, and evaluation. To address these challenges, I will introduce the Embodied Foundation—a platform jointly established by Beijing Academy of Artificial Intelligence (BAAI), Peking University, GOSIM, and other institutions. This foundation includes data, evaluation, and computational resources, and its capabilities will be made open-source and publicly available to foster global collaborative innovation in Embodied Intelligence.",(N/A),Accept,[object Object],1756784204551,proposal-hangzhou-accepted,[object Object],(N/A)
166,Boucherifi-Kornmann,alexboucherifi@yahoo.fr,Société de l'augmentisme ,"Artist, Founder of the augmented painting or augmentism, creator of the European Biennial of AI and augmentism","
ABK (Alexandra Boucherifi-Kornmann) is a French-Italian artist, curator, and researcher working at the intersection of art, science, and emerging technologies. For a decade, her practice has critically engaged with artificial intelligence and new creative tools, leading to the launch of a new painting movement called The Augmented Painting (or Augmentism) in 2019. This is a pictorial movement using tools such as AI, RA, mapping, to question and stimulate traditional painting.
As founder of the upcoming European Biennale of AI and Augmentism, ABK brings together artists, scientists, and technologists from across Europe and beyond to foster dialogue between engineering and the humanities. Curatorial work focuses on the ethical and aesthetic dimensions of technology, promoting cross-cultural exchanges.
As an artist, her artworks could be seen in museums, art fairs or groups shows (Centre Pompidou, Ars Electronica, Agnes b.’s…)
International exhibitions curated include the first art & fashion show first exhibition worldwide dealing with Lady Gaga, with artworks  and garments presented in venues such as Paris or Lane Crawford in China through her staff. In addition, ABK has led workshops on environmental issues and lectured at a large scale through institutions such as colleges, or geared towards various audiences.
Participating at the GOSIM AI Vision Forum, ABK contributes a European cultural perspective on AI and humanity, sharing insights from the upcoming European Biennial of AI and Augmentism to envision symbiotic relationships between humans and intelligent systems across Europe and Asia.",(N/A),(N/A),https://www.linkedin.com/in/alexandra-b-9b531b21/,(N/A),https://peinture-augmentee.com/en/home/,(N/A),Bridging Art and Artificial Intelligence : Augmenting Creativity ? ,English,AI Next,"Abstract : This presentation examines in part the evolving relationship between artistic creation and artificial intelligence in recent years. Drawing on our own artistic practice and research, as well as the work of colleagues, primarily in France, who have been engaging with the intersections of art and AI, some of the key creative strategies and conceptual frameworks that have emerged in this field will be outlined.
Within this context, The Augmented Painting (also called Augmentism), an artistic movement I initiated in 2019 I will be introduced. Situated within the lineage of European art history and modern painting movements, Augmentism proposes to expand and redefine the practice of painting through its encounter with new technologies, in particular, artificial intelligence.
Finally, will be presented the upcoming European Biennial of AI and Augmentism, an international initiative I am founding to foster dialogue between artistic and academic communities. Currently encompassing France, Greece, and Italy, the Biennial will launch in Thessaloniki (from January to March 2026), before extending to the other partner countries, with further international participation anticipated. Conceived as both an artistic platform and a space for scientific and general public exchanges, the Biennial aims to highlight pioneering practices while critically reflecting on the role of AI and emerging technologies in shaping the future of art.","In my presentation, I will begin by offering a brief overview of artistic creation with artificial intelligence over the past decade. This introduction will draw upon my own research and artistic practice, and also some work of fellow artists and researchers from mainly France who have been exploring the intersections between art and AI for the last years too.

Following this contextual background, I will introduce a new artistic movement in painting I created in 2019, known as The Augmented Painting, or Augmentism. This movement is conceived as part of the long tradition of European art history, particularly in relation to the evolution of modern painting movements. Augmentism seeks to explore how painting can be expanded and redefined through dialogue with recent technologies such as artificial intelligence.

Finally, I will present the upcoming European Biennial of AI and Augmentism, an international event that I am creating and that will bring together artistic and academic perspectives from multiple countries. At present, the Biennial includes France, Greece, and Italy, and it is scheduled to take place in 2026. The inaugural edition will be hosted in Thessaloniki, Greece, from January to March 2026 and will be followed by the two other countries. Some other countries should join in the future. 
This Biennial aims not only to showcase pioneering artistic practices but also to foster a deeper cultural and intellectual exchange around the role of AI and new technologies in shaping the future of art.",Accept,[object Object],1756686866753,proposal-hangzhou-accepted,[object Object],(N/A)
165,Yanzhi Wang,wangyanzhi0327@gmail.com,Northeastern University,Professor,"Yanzhi Wang is Professor in the Department of Electrical and Computer Engineering and Computer Science at Northeastern University, a senior member of IEEE. His research interests focus on real-time and energy-efficient deep learning and artificial intelligence systems, especially on efficient large language models and large-scale generative AI systems. His research works have been published broadly in (i) machine learning conferences such as AAAI, CVPR, NeurIPS, ICML, ICCV, ICLR, IJCAI, ECCV, KDD, ICRA, ACM MM, ICDM, etc., (ii) architecture and system conferences such as ASPLOS, ISCA, MICRO, HPCA, CCS, VLDB, PLDI, WWW, ICS, PACT, CGO, IPDPS, INFOCOM, ICDCS, DAC, ICCAD, FPGA, FCCM, ISSCC, CICC, RTAS, RTSS, etc., and (iii) IEEE and ACM transactions. His research works have been cited over 26,500 times. He has received six Best Paper Awards and another 12 Best Paper Nominations. His research work has been reported and cited by around 500 media. He has 15 academic descendents as tenure-track faculty members at University of Minnesota, University of Massachusetts Amherst, University of Arizona, Michigan State University, University of Georgia, etc.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),End-to-end AI chat and translation system on local devices,Chinese,Apps & Agents,"In this presentation, we present the recent progress of our end-to-end AI chat and translation system on local devices, such as laptop computer or local AI accelerators. Our end-to-end system has innovation in three tiers: the top tier supporting continuous processing, interruption, in-context learning, RAG, and MCP; the middle tier with our optimized end-to-end AI models with real-time capability and enhanced recognition/TTS capability; and the lower tier of hardware-aware accelerations. Our AI chat and translation system runs on local devices and gets comparable or even better performance than cloud server based systems. Our systems are open-source for testing and for agent-oriented integration.",(N/A),Accept,[object Object],1756790692100,proposal-hangzhou-accepted,[object Object],(N/A)
164,Yanzhi Wang,wangyanzhi0327@gmail.com,Northeastern University,Professor,"Yanzhi Wang is Professor in the Department of Electrical and Computer Engineering and Computer Science at Northeastern University, a senior member of IEEE. His research interests focus on real-time and energy-efficient deep learning and artificial intelligence systems, especially on efficient large language models and large-scale generative AI systems. His research works have been published broadly in (i) machine learning conferences such as AAAI, CVPR, NeurIPS, ICML, ICCV, ICLR, IJCAI, ECCV, KDD, ICRA, ACM MM, ICDM, etc., (ii) architecture and system conferences such as ASPLOS, ISCA, MICRO, HPCA, CCS, VLDB, PLDI, WWW, ICS, PACT, CGO, IPDPS, INFOCOM, ICDCS, DAC, ICCAD, FPGA, FCCM, ISSCC, CICC, RTAS, RTSS, etc., and (iii) IEEE and ACM transactions. His research works have been cited over 26,500 times. He has received six Best Paper Awards and another 12 Best Paper Nominations. His research work has been reported and cited by around 500 media. He has 15 academic descendents as tenure-track faculty members at University of Minnesota, University of Massachusetts Amherst, University of Arizona, Michigan State University, University of Georgia, etc.
",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Collaborative Compression for Large-Scale MoE Deployment on Edge,Chinese,Edge AI Workshop,"The Mixture of Experts (MoE) architecture is an important method for scaling Large Language Models (LLMs). It increases model capacity while keeping computation cost low. However, the latest ultra-large MoE models still have hundreds of billions of parameters. They require very large memory and storage, which makes deployment in edge or resource-limited environments difficult. Low-
bit quantization methods can reduce the size of model weights to hundreds of gigabytes. But for models with hundreds of billions of parameters, they often cause large accuracy loss or even make the model fail to generate valid outputs. We propose a compression framework for ultra-large MoE models. It combines expert pruning, MoE-specific mixed-precision quantization, and activation optimization. This framework reduces both the size of model weights and the memory used by activations. Under a 128 GB memory limit, it achieves, to the best of our knowledge, the first efficient deployment of a model as large as DeepSeek-V3. It performs better than uniform low-bit quantization under the same memory limit. We design an expert pruning strategy to reduce parameters and keep routing diversity. We also design a mixed-precision quantization method that uses hardware constraints and tensor sensitivity analysis to set bit widths. Finally, we apply activation optimization to lower peak memory use during inference. Experiments on multiple benchmarks show that our framework is effective and performs better than existing low-bit quantization methods.",(N/A),Accept,[object Object],1756610982541,proposal-hangzhou-accepted,[object Object],(N/A)
163,Weidong Shao,weidongshao@gmail.com,SciMigo,Manager,Veteran software and AI professional with 20+ years of industry experience. Tsinghua/Stanford gradudate. ,(N/A),(N/A),https://www.linkedin.com/in/weidong-shao-475405184/,https://github.com/thinkinginmath,https://scimigo.com,(N/A),"Deliver High Quality AI STEM Tutor to Everyone, Everywhere",English,AI4Education Workshop,"Access to high-quality tutoring remains out of reach for millions of students due to cost, geography, and limited availability of skilled teachers. This talk presents a vision for an affordable, AI-powered tutor designed to democratize education worldwide. Drawing on the Socratic method, the tutor guides students through step-by-step reasoning rather than providing answers directly, fostering deep understanding and critical thinking. Unlike traditional tutoring or existing AI tools, it integrates seamlessly into a student’s workflow, supports curriculum alignment, and provides measurable progress tracking for parents and educators. Available 24/7 across devices, it adapts to each learner’s pace and needs, lowering barriers to effective STEM education. The talk explores how this approach can scale globally, bridging gaps in access and empowering learners from all backgrounds to reach their full potential.","“Imagine a future where every student—regardless of background or location—has access to world-class tutoring anytime, anywhere. That’s the world we’re building: an AI-powered tutor designed to make top‑tier learning both affordable and accessible.”

The Problem: Education is Out of Reach for Many

The global tutoring market is massive—over $100 billion—yet high costs put quality tutoring out of reach for most families.


Many K‑12 students still struggle, especially in math and science. In fact, 70% of them fail to master these subjects.

Add to this the fact that most tutoring options aren't available when students need help most—outside school hours.
",Accept,[object Object],1756610998560,proposal-hangzhou-accepted,[object Object],(N/A)
162,董学勤,dxq@kandigroup.com,浙江康迪科技集团有限公司,康迪科技董事长,董学勤，同济大学车辆工程专业工学博士，2022年加入康迪集团，现任康迪科技集团董事会主席。在汽车行业拥有超过 20 年的经验，曾成功领导了多家公司。在车辆设计、工程，及创新产品的开发、制造和商业化方面拥有广泛的管理团队背景，有着丰富的实践经验和广博的专业知识。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),《从非公路车到机器人：康迪科技的“三海”突围之路》,Chinese,Embodied AI,基于电动非公路车构建的生产全球化与供应链全球化，销售网络全球化的基础。讲诉康迪科技如今作为智能机器人领域的集成者，锚定北美安放巡检以及高尔夫球童机器人，如何从制造出海，到智造出海，再到生态出海，成为中国技术摆渡人。,(N/A),Accept,[object Object],1756452021845,proposal-hangzhou-accepted,[object Object],(N/A)
161,陈毅俊,dreamchancn@qq.com,南方科技大学,学生,南方科技大学本科生，RoboMaster战队成员，2025 Dora-rs开源之夏成员,(N/A),(N/A),(N/A),drindr,(N/A),(N/A),Dora接入与统一启动流程,Chinese,Dora Workshop,结合开源之夏工作，分享各种外部生态接入Dora并围绕Dora构建统一启动流程的经验,(N/A),Accept,[object Object],1756452038740,proposal-hangzhou-accepted,[object Object],(N/A)
160,Evan Fannin,evan@cline.bot,Cline,Founding Engineer,Founding engineer @ Cline,(N/A),(N/A),https://www.linkedin.com/in/evan-fannin/,(N/A),(N/A),https://x.com/elephant_lumps,One Agent to Code Them All: Lessons from Building Cline’s Autonomous Coding Partner,English,Apps & Agents,"As AI moves from autocomplete to autonomous agents, we set out to build Cline—an open, model-agnostic coding partner capable of tackling long-horizon development tasks. This talk shares hard-earned lessons from a founding engineer on what worked, what failed, and why simplicity and simulation-driven planning proved essential.","This talk reflects on the evolving landscape of autonomous agents for software development. Drawing from our experience building Cline, I’ll explore themes like:

Why some approaches that look promising in theory—such as retrieval pipelines or networks of sub-agents—often fall short in practice.

How we do agent evaluations and what we look for in comparing models.

How context sharing and feedback-driven planning can help agents stay coherent over long horizons.

The balance between simplicity and capability, and why the most effective systems are often the least complicated.

Lessons on reliability, scalability, and developer trust that emerged as we moved from prototypes to production use.

Rather than prescribing one solution, the goal is to share principles and trade-offs that can inform the next generation of agent design—highlighting where we’ve been surprised, what we’ve chosen not to build, and how those decisions shaped the system.",Accept,[object Object],1756431749711,proposal-hangzhou-accepted,[object Object],(N/A)
159,Rik Arends,rik@n4.io,Makepad,Co-Founder,"With 20+ years’ experience as a C/C++, JavaScript and more recently Rust developer, I've always been excited by using computation for visuals and audio. For this to work you need performance, and a smooth workflow enabled by the right tooling. After having everything I wanted with C except stable code I moved to JavaScript and web technologies. However, this never got to the point of being able to make fast applications that use modern CPU and GPU power. Now with Rust we have a new chance. I've been an entrepreneur my entire life building VJ software in the 00's, then web UI technology and web IDEs with Cloud9, and am now reimagining the developer workflow in Rust with Makepad. And lately how to leverage AI to write Rust and UI code.",(N/A),(N/A),https://www.linkedin.com/in/arendsrik/,https://github.com/makepad/makepad,https://makepad.nl/,https://x.com/rikarends,How to Build Apps with Makepad,English,Makepad Workshop,"In this workshop, we will teach you how to build a simple app with Makepad, a modern GPU-based UI Framework for Rust that allows for writing fast and lightweight apps.

The app we are going to build is an image viewer, consisting of a slideshow and an image grid. Along the way, we will learn many of the concepts behind Makepad, such as how to define the layout and styling for your app, how to handle events, how to create animations, and how to use shaders to customize the styling of your app.",(N/A),Accept,[object Object],1756422680456,proposal-hangzhou-accepted,[object Object],(N/A)
158,Sizhe Cheng,anantheparty0@gmail.com,Elevatia Studio,Lead Programmer,"HUST graduate · Game Dev (3+ yrs, current)· CCF Elite Collegiate · ACM silver ×3 in Univ",(N/A),(N/A),(N/A),@anantheparty,(N/A),(N/A),基于LLM的辅助作战Agent在多单位即时战略游戏（RTS）中的可行性与实现,Chinese,Apps & Agents,探讨大型语言模型（LLM）在多单位即时战略游戏（RTS）中作为辅助作战 Agent 的可行性及其具体实现方式。不同于传统基于规则或启发式的 AI 系统，基于 LLM 的 Agent 能够通过自然语言理解解析玩家的高层次指令和抽象语言，并将其动态转化为可执行的游戏操作。我们分析了实现过程中的关键问题，包括 玩家语义理解 指令学习理解 游戏结构学习 游戏状态理解 执行内容输出 错误纠正，以及在实时性与游戏引擎集成方面的挑战。本文还展示了一个原型实现，验证了 LLM 在自动化建造、大规模调度等方面对玩家的增强作用，验证了复杂 RTS 环境下的人机协作体验与可玩性，提出了一种通过语言操控AI和AI同时游玩的新交互模式，并给出了进一步的设想和应用前景,探讨大型语言模型（LLM）在多单位即时战略游戏（RTS）中作为辅助作战 Agent 的可行性及其具体实现方式。不同于传统基于规则或启发式的 AI 系统，基于 LLM 的 Agent 能够通过自然语言理解解析玩家的高层次指令和抽象语言，并将其动态转化为可执行的游戏操作。我们分析了实现过程中的关键问题，包括 玩家语义理解 指令学习理解 游戏结构学习 游戏状态理解 执行内容输出 错误纠正，以及在实时性与游戏引擎集成方面的挑战。本文还展示了一个原型实现，验证了 LLM 在自动化建造、大规模调度等方面对玩家的增强作用，验证了复杂 RTS 环境下的人机协作体验与可玩性，提出了一种通过语言操控AI和AI同时游玩的新交互模式，并给出了进一步的设想和应用前景,Accept,[object Object],1756433911280,proposal-hangzhou-accepted,[object Object],(N/A)
157,Kai Du ,kai_du@tsinghua.edu.cn,清华大学,助理教授,"杜凯，清华大学助理教授

杜凯博士现任清华大学心理与认知科学系助理教授，长期从事神经科学与类脑智能交叉研究。他于2016年在瑞典卡罗琳斯卡医学院神经科学系获得博士学位，是欧盟“人脑计划”中“大脑仿真平台”瑞典团队的核心成员之一。2020年至2024年，任北京大学人工智能研究院助理研究员/副研究员。杜博士在大脑精细建模与类脑计算领域取得了一系列成果。他构建了首个针对基底核脑区的高精度神经元模型，为解析该脑区的功能机制奠定了重要基础；并自主开发了高性能计算框架DeepDendrite，大幅提升了复杂脑模型的模拟效率，并将树突计算原理与人工智能模型深度融合，推动了“树突神经AI”的发展。此外，他与北京智源人工智能研究院合作，构建了首个具备环境交互能力的精细线虫模型（Zhao et al., Nature Computational Science, 2025），为多尺度神经模拟与智能行为建模提供了新范式。截至目前，杜博士以第一作者或通讯作者身份在《Proceedings of the National Academy of Sciences（PNAS）》、《Nature Communications》等国际顶级期刊发表多篇研究论文。其当前研究聚焦于：脑的精细仿真与多尺度建模, 树突计算机制及其神经调控以及基于精细神经模型的新型人工智能理论与系统（Dendritic NeuroAI）。",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),迈向生物通用智能,Chinese,AI Next,"最新研究显示，ChatGPT通过其庞大的万亿参数网络展示了智能如何从复杂系统中自发涌现，进而激发了我们对生物大脑智能涌现机制的探讨。由于复杂的树突结构和离子通道，每个生物神经元实际上是一个具备深度学习网络计算能力的微型神经网络。
大脑精细模拟是唯一能够精确捕捉这种树突结构、离子通道和突触互动复杂性的数学方法。然而，这种模拟只是揭示生物智能的起点。基于大脑的精确还原，如何进一步探索智能本质，无论对计算还是实验神经科学而言，都是一片未知领域。
在本次报告中，我将介绍一种新的智能形态——生物通用智能，它基于精细的大脑模拟，能够适应并探索真实世界。我将通过介绍最新的高效大脑模拟框架DeepDendrite (Zhang, et.al., Nat. Commun. 2023)和可以与环境交互的精细线虫模型（Zhao, et.al., Nat. Comput. Sci, 2025）来探讨这种基于真实神经系统模拟的智能形式。",(N/A),Accept,[object Object],1756398641281,proposal-hangzhou-accepted,[object Object],(N/A)
156,Zhigang Sun,sunner@gmail.com,AI Shifu,"Founder, CEO","I am the Founder and CEO of AI Shifu. Previously, I served as Partner, Chief Product Officer, and CTO at an online education unicorn; Vice President of Dedao App, leading teaching, academic product affairs; Chief Product Architect, Strategy Director, and Head of Operations for NetEase Cloud Classroom; and Associate Professor at the School of Computer Science, Harbin Institute of Technology (HIT).
I also hold concurrent academic and industry positions, including Adjunct Professor at the HIT School of Software, Expert Committee Member of the Technical Standards Committee of the China Educational Technology Association, Vice Chairman of the Zhejiang Software Industry Association, and Executive Committee Member of the Hangzhou Chapter of the China Computer Federation.",N/A,N/A,https://www.linkedin.com/in/zhigang-sun-27667220/,https://github.com/sunner,https://sunner.cn,N/A,"MarkdownFlow, the next HTML",Chinese,Agentic Web,"MarkdownFlow extends standard Markdown with AI intelligence to create personalized, interactive pages. Its tagline is ""Write Once, Deliver Personally"".
All of humans, code and AIs can read and write MarkdownFlow document to present their core ideas and let agent to transform it to every person with personlized, rich and interactive UI. Therefore, it is the next HTML in AI era.","Sir/Madam,

I just got the link and can not prepare the details so quick. Really sorry for that. But I can present you the homepage https://markdownflow.ai .
MarkdownFlow is new and has great potential. I believe that you will not regret to approve my proposal.

Best regards",Accept,[object Object],1756363387626,proposal-hangzhou-accepted,[object Object],(N/A)
155,Wang Gege,doublege2021@163.com,Huawei Corporation,Dora Contributor,开源爱好者，Dora开源贡献者,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),分布式Dora的开发与探索,Chinese,Dora Workshop,这次分享是去年我在dora实习的体会，主要是关于dora的架构设计，以及如何将单机部署dora的架构改成分布式部署的架构，对此我们需要做的一系列尝试以及遇到的问题。,(N/A),Accept,[object Object],1756333040179,proposal-hangzhou-accepted,[object Object],(N/A)
154,Eddy Bruel,ejpbruel@gmail.com,Makepad,Cofounder,"I'm one of the cofounders of Makepad. I've been a Rust developer for the last 5 years. Before that, I was a C++ developer at Mozilla. I've worked on many different projects, such as JavaScript engines, Developer Tools, WebAssembly interpreters, etc.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),How to Build Apps with Makepad,English,Makepad Workshop,"In this workshop, we will teach you how to build a simple app with Makepad, a modern GPU-based UI Framework for Rust that allows for writing fast and lightweight apps.","The app we are going to build is an image viewer, consisting of a slideshow and an image grid. Along the way, we will learn many of the concepts behind Makepad, such as how to define the layout and styling for your app, how to handle events, how to create animations, and how to use shaders to customise the styling of your app.",Hold,[object Object],1756333052941,proposal-hangzhou-accepted,[object Object],(N/A)
153,翟季冬,chenmanman@chitu.ai,暂无,清华大学计算机系长聘教授，博士生导师。国家杰出青年科学基金获得者，清华大学计算机系高性能所所长。,"清华大学计算机系长聘教授，博士生导师。国家杰出青年科学基金获得者，清华大学计算机系高性能所所长。
主要从事并行计算、编程语言与编译器、性能评测等领域的研究工作。担任清华大学学生超算团队教练，指导的团队15次获得世界冠军。",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),2025大模型服务性能排行榜,Chinese,Apps & Agents,"在大模型应用快速迭代的当下，以MaaS为代表的大模型服务凭借其便捷的接入方式和较低的使用门槛，日益成为开发者调用大模型能力进行应用开发的核心方式之一。然而，面对市场上层出不穷、各具特色的大模型服务平台，开发者往往面临着较大的选择难题，如何找到性能稳定、高性价比的服务商成为重要课题。
本次演讲分享正是基于这样的市场需求和开发者面临的困境，清华大学联合中国软件评测中心，推出了《2025大模型服务性能排行榜》，该榜单从延迟、吞吐等性能指标维度，长周期、高频率、多时段评测了20余家大模型服务平台的数百个模型服务，为开发者提供真实、详细的数据参考，帮助开发者快速、便捷地选择符合自身需求的大模型服务。",(N/A),Accept,[object Object],1756431915669,proposal-hangzhou-accepted,[object Object],(N/A)
152,ZhangYiming,yiming_jz@hotmail.com,Nankai University,Student,南开大学软件工程硕士，开源爱好者，主要负责Adora机器人软件框架开发和算法移植。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Adora Robot和基于华为昇腾的dora数据平台,Chinese,Dora Workshop,分享 Adora 机器人在首届世界人形机器人运动会中的比赛经历和收获，以及 dora 数据平台在华为昇腾平台上的适配工作。,(N/A),Accept,[object Object],1756286061260,proposal-hangzhou-accepted,[object Object],(N/A)
151,汪锦想,jxwang@iflytek.com,科大讯飞,工程师,负责训练和推理框架建设,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),昇腾深度开发创新实践,Chinese,CANN Workshop,主要介绍讯飞星火大模型使用昇腾算力实践情况。重点报告在万卡昇腾集群下，星火大规模训练集群如何进行快速系统恢复；使用Ascend C研发高效融合算子。,(N/A),Accept,[object Object],1756276137439,proposal-hangzhou-accepted,[object Object],(N/A)
150,Jingdong Chen,jingdongchen.cjd@antgroup.com,Ant Group,Senior Algorithm Expert  ,"Senior Algorithm Expert at Ant Group, responsible for research and development of multimodal large model technologies. Led projects on OCR-based intelligent insurance claims  and remote sensing-based agricultural credit, which were awarded the Second Prize of CCF Science and Technology Progress Award in 2022 and 2023, respectively. Has published numerous papers in the fields of computer vision and machine learning, with over 5,500 citations. His work in speech recognition was selected as one of MIT Technology Review's 10 Breakthrough Technologies in 2016.
蚂蚁集团资深算法专家，负责多模态大模型技术研发。基于OCR的智能理赔和基于遥感的对农信贷的项目，分别荣获CCF 2022、2023科技进步二等奖。在计算机视觉、机器学习领域发表多篇论文，引用量5300+，语音识别技术成果入选2016年MIT全球技术突破Top10。",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),蚂蚁多模态大模型实践,Chinese,Apps & Agents,介绍蚂蚁在大模型领域Ming-Omni系列开源工作，分享在多模态大模型架构演进、跨模态融合、生成与理解统一等技术领域的实践与进展。通过模型架构、训练过程的联合设计与优化，致力于打造模型全模态能力，实现能看、能听、能说、能画的多模态基础模型。,(N/A),Accept,[object Object],1756432268065,proposal-hangzhou-accepted,[object Object],(N/A)
149,Jing Zhang,zhang_jing@buaa.edu.cn,Beihang University,Associate Professor,"Jing Zhang is an associate professor in School of Software, Beihang University, Beijing, China. Her recent research interests include artificial intelligence, machine learning and computer vision, with the special interests in transfer learning, multi-modality learning, and multi-modal LLM based web agent.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Prune4Web: DOM Tree Pruning Programming for Web Agent,English,Future Web Workshop,"Web automation uses intelligent agents to perform high-level tasks by mimicking human interactions with webpages. Despite recent advances in LLM-based web agents, efficiently navigating complex, real-world webpages remains challenging due to massive DOM structures. This talk will present Prune4Web, a paradigm that transforms DOM processing from LLM-based filtering to programmatic pruning. This approach eliminates the need for LLMs to process full DOMs, instead delegating traversal and scoring to lightweight, interpretable programs.",(N/A),Accept,[object Object],1756265370224,proposal-hangzhou-accepted,[object Object],(N/A)
148,Xiang Ying,yingxiang@mindverse.ai,Mindverse,CoFounder,Building Your AI 'Second Me' by Large Language Model,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Second Me：用你的观点、经历与记忆，训练你的个人大模型,Chinese,Apps & Agents,"Second Me 目标是训练一个由你的记忆塑造的个人大模型。它以你的观点与经历（以及你日常记录的思考）为核心语料，让 AI 不再只是知识库，而是能带着你的表达、偏好和界限。
我们将展示Second Me背后的思考，实践过程中的经验，Second Me在实际产品中的使用，以及一些待探讨的问题",(N/A),Accept,[object Object],1756224537303,proposal-hangzhou-accepted,[object Object],(N/A)
147,Michal Pierzchala,michal.pierzchala@callstack.com,Callstack,Principal Engineer,Principal Engineer at Callstack. Passionate about building mobile and web tooling and Open Source. Core React Native Community & Jest contributor. Space exploration enthusiast,(N/A),(N/A),thymikee,thymikee,(N/A),thymikee,Native apps without a build step,English,React Native Meetup,"React Native apps are bigger and more complex than ever. At Callstack, we’ve built Rock—open, modular, self-hosted, and incrementally adoptable framework for React Native—to help teams scale, migrate, and deliver faster.","React Native just turned 10, and its adoption has followed a familiar curve—from early startups to scale-ups, mainstream apps, and finally large enterprises making their move. At Callstack, we’ve seen the full spectrum: massive 8-year-old React Native codebases, hybrid native setups, teams juggling 10+ platforms, and organizations needing flexible tooling that scales with them.
The Community CLI has long been the backbone of this ecosystem, but as React Native evolved—embracing Expo, modularity, and framework-driven development—we realized the needs of today’s teams go far beyond what the CLI alone can offer. That’s why we’ve been building Rock: a modular, self-hosted, incrementally adoptable framework designed for the reality of large, diverse, and long-lived apps.
In this talk, I’ll share how we got here, why frameworks are the future of React Native, and how our new open-source framework can help teams—whether greenfield or brownfield—migrate smoothly, unify tooling, and accelerate delivery",Accept,[object Object],1756224453452,proposal-hangzhou-accepted,[object Object],(N/A)
146,Philippe Le Hegaret,angel@w3.org,World Wide Web Consortium （W3C）,"W3C Vice President, Strategy Lead ","Philippe Le Hegaret is the VP, Strategy Lead for W3C. Since 2023, as Strategy Lead, he is responsible for the technical mission of the Consortium and ensuring that W3C keeps moving the Web forward. As Project Lead since 2016, he is responsible for all of the standard groups at W3C. He is the current co-chair of the W3C Process Community Group, responsible for proposing improvements on how W3C produces Web standards. Until 2016, he was leading thaweie efforts on frontend Web technologies including HTML5, CSS3, SVG, WOFF, or Web APIs. In 2015, he helped create WICG, the incubator group for new browser proposals. In 2010, he started a project to work on testing the Web, which lead to the creation of the Web platform tests (WPT) project in 2013, the de-facto place to test browser engines. Prior to 2009, Philippe led the W3C Architecture Domain, which produced the W3C Core technologies in the area of XML, Web Services, and Internationalization. He is a former Chair of the Document Object Model (DOM) Working Group, and the original author of the CSS validator.",(N/A),(N/A),(N/A),https://github.com/plehegar,https://www.w3.org/People/LeHegaret/,(N/A),AI and Next Generation Web,English,Agentic Web,"W3C works with global Web community on analyzing the broad and evolving impact of AI systems on the Web, and examining the potential role of Web standardization in shaping and managing that impact. This talk shares the recent AI related activities and discussions in W3C such as AI in browser, AI Agents, Web ML, AI and accessibly, AI security and privacy, as well we some coming activities on the topic of Web and AI. ",(N/A),Accept,[object Object],1756224395091,proposal-hangzhou-accepted,[object Object],(N/A)
145,berry lv,berrylv@mail.ustc.edu.cn,USTC,Student,Student of USTC.,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Dora with isaacsim,Chinese,Dora Workshop,dora与仿真平台isaacsim的结合。,(N/A),Accept,[object Object],1756224409246,proposal-hangzhou-accepted,[object Object],(N/A)
144,Zhuo Wu,zhuo.wu@intel.com,Intel,AI Software Evangelist,Intel AI Software Evangelist,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Cognitive AI for the Future: Agentic Multimodal Models and RAG for Vision Language Applications with OpenVINO,Chinese,Apps & Agents,"Cognitive AI represents a transformative leap in how machines understand and interact with the world. Despite its potential, practical challenges remain in making these systems accessible and applicable across diverse domains. This talk addresses how multimodal models, combined with Retrieval-Augmented Generation (RAG) and agentic workflows, can enable cognitive AI systems to deliver personalized, context-aware solutions with OpenVINO. With applications ranging from educational tools to assistive technologies for the elderly and disabled, this talk focuses on practical strategies for optimizing, and deploying these models and pipelines, making them both scalable and accessible to researchers and practitioners.",(N/A),Accept,[object Object],1756225002403,proposal-hangzhou-accepted,[object Object],(N/A)
143,Jesse Ezell,jezell@gmail.com,TIMU,CTO,"Jesse Ezell has been a full stack developer since the full stack was assembly language. An active member of the Flutter community, he has contributed to the LiveKit Flutter SDK, Flutter WebRTC, SuperEditor, Quill, many essential Flutter packages, and some fixes for pesky Flutter web engine bugs. Currently Jesse runs an AI startup and spends his days, nights, and weekends helping customers build and deploy and scale AI agents.",(N/A),(N/A),(N/A),jezell,(N/A),jezell,"Conversations Without Boundaries: Building Voice Agents with Flutter, WebRTC, and LiveKit",English,Agentic Web,"We’re entering an era where apps don’t just respond to taps and swipes—they talk back. Imagine customer support that feels like a natural conversation, in-app copilots that guide you like a trusted colleague, or immersive experiences where voice replaces menus entirely.

In this session, we’ll explore how Flutter, WebRTC, and LiveKit are unlocking this future. You’ll see how a single Flutter codebase can deliver real-time, AI-powered voice interactions across mobile, desktop, and web. We’ll look at how WebRTC makes instant voice streaming possible, and how LiveKit provides the backbone for global, low-latency communication.

But beyond the tech, this talk is about vision: what it means when any app can listen, understand, and respond in real time. We’ll discuss design patterns for voice-first experiences, the new kinds of products voice agents make possible, and why this shift is as profound as the jump from command lines to GUIs.

If you’re curious about what the next generation of conversational interfaces looks like—and how you can be part of shaping it—this session will inspire and equip you to start building it today.",(N/A),Accept,[object Object],1756224959197,proposal-hangzhou-accepted,[object Object],(N/A)
142,Jingshi Shangguan,shangguanjingshi@huawei.com,Huawei,Software Engineer,Joined Huawei in 2017 and am currently involved in rendering work related to the Servo engine on OpenHarmony.,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Unified rendering of Servo on OpenHarmony,English,Future Web Workshop,The unified rendering approach of Servo on OpenHarmony and the roadmap ahead.,(N/A),Accept,[object Object],1756162523840,proposal-hangzhou-accepted,[object Object],(N/A)
141,李扬,echo_ai@foxmail.com,Dora社区,技术专家,"李扬 Dora技术专家，系统架构师。负责Dora机器人项目研发及解决方案。
十五年以上软件工程及解决方案交付经验，目前专注于具身智能需求分析与架构定义。",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),dora-rs用Rust赋能下一代机器人开发,Chinese,Dora Workshop,介绍dora的技术架构，基于dora开发的机器人案例以及dora中文社区的建设,(N/A),Accept,[object Object],1756137135108,proposal-hangzhou-accepted,[object Object],(N/A)
140,Xu Han,han-xu@tsinghua.edu.cn,Tsinghua University,Assistant Professor,https://thucsthanxu13.github.io/,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Efficient Computing Driven by Capacity Density for Large Language Models,English,CANN Workshop,"As the scale of large language models and their training data continues to expand, the bottleneck between model performance and resource consumption is becoming increasingly prominent. The traditional approach of simply stacking more parameters and data is no longer sustainable, creating an urgent need for more efficient LLM technologies. This report focuses on the goal of enhancing the capability density of large language models, aiming to achieve maximum model intelligence at a certain computational cost. To accomplish this, the report will explore three core technical directions: Refined Training Data Filtering, by creating a hierarchical quality filtering and synthesis process, we can eliminate inefficient and redundant data. This approach aims to boost model capability density by increasing the knowledge density of the data. Sparsification of Model Architecture, by reconstructing the attention and feed-forward layers with sparsification techniques, we can significantly reduce the computational and storage overhead of the model without a notable drop in performance. Algorithmic Optimization of Training and Inference Frameworks: By deep optimizing distributed training and inference algorithms, combined with underlying operator-level optimization, we can substantially improve the training and inference efficiency of the models.",(N/A),Accept,[object Object],1756104720970,proposal-hangzhou-accepted,[object Object],(N/A)
139,Martin Alvarez Espinar,martinalvarez.espinar.ext@huawei.com,W3C,"Chair, High-Performance Web Engines CG, W3C","Chair, High-Performance Web Engines CG, W3C",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),High-Performance Web Engines,English,Agentic Web,High-Performance Web Engines,(N/A),Accept,[object Object],1756087132827,proposal-hangzhou-accepted,[object Object],(N/A)
138,Sébastien Crozet,sebcrozet@dimforge.com,Dimforge,Founder,"Sébastien Crozet has been in love with the Rust programming language since its earliest days. He is the creator and maintainer of popular open-source libraries, including nalgebra and Rapier, for the Rust ecosystem that specialize in linear algebra, geometry, and physics. He is the founder of Dimforge where he focuses on contributing to the future of cross-platform scientific computing and AI.",(N/A),(N/A),(N/A),https://github.com/dimforge,(N/A),(N/A),Single-source cross-platform GPU LLM inference with Slang and Rust,English,Edge AI Workshop,"Leveraging Rust and Khronos’ emerging Slang initiative, we introduce our initial efforts toward a cross-platform GPU LLM inference ecosystem. With a single-source approach we aim to minimize backend-specific code and foster community participation.","This is the general breakdown of the talk:
- Why single-sources is important for maintainability, contributors accessibility, and future extension to more platform. Show how typical LLM frameworks (llama.cpp, candle) rely on per-platform kernel implementations which can be difficult too expand, read, and maintain.
- Quickly explain what is Slang (https://shader-slang.org/) the new initiative from Khronos.
- Describe our ecosystem using Slang in Rust for AI (`minislang`, `slang-hal`, `slinalg`, `slai`).
- Show practical code samples for building a LLM transformer with `slai` and the `slinalg` tensor library.
- Show code snippets to show how a single shader gets converted transparently to other backends. Show how easy it is to switch backend.
- Show the `derive(Shader)` proc-macro and how additional operators can be implemented (and interfaced with the Rust code).
- Demo with slml running segment-anything/llama LLM models.
- Describe next steps and call for contributors.",Accept,[object Object],1756083533472,proposal-hangzhou-accepted,[object Object],(N/A)
137,Xiaolei WANG,358027476@qq.com,Huawei,昇腾芯片产品总经理,"王晓雷，昇腾芯片及解决方案产品总经理，负责昇腾全系列芯片及解决方案的特性定义与竞争力设计。
十年以上AI算法及解决方案交付经验，目前专注于计算系统的需求分析与架构定义。",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),昇腾芯片产品总经理,Chinese,CANN Workshop,"1. 昇腾芯片演进历程回顾：合唱团还是蚁群战术
2. CANN演进历程回顾：从投入人工到享受智能
3. 从能用到好用：CANN特性介绍与开源开放计划
",(N/A),Accept,[object Object],1756083547066,proposal-hangzhou-accepted,[object Object],(N/A)
136,苏统华,thsu@hit.edu.cn,哈尔滨工业大学,软件学院副院长,苏统华，哈尔滨工业大学计算学部教授、博士生导师，软件学院副院长。主要研究领域包括深度学习与异构计算、图像生成与鉴别等。建立领域内首款手写中文库（HIT-MW库），为国内外200余家科研院所采用，获得2个国际手写汉字识别竞赛第一名，自主研发大规模深度学习训练和预测平台，成果转化到试卷全智能批改、手机手写输入法等工业级产品。承担国家重大科技攻关课题、国家重点研发课题等科研项目20余项，在 TNNLS、KBS、ICCV等顶刊顶会发表论文80余篇，出版专著和译著17本，获省科技进步二等奖1项。获聘首批华为昇腾领军人物（全国14人）、首批华为最具价值教师（全球18人），担任MindSpore技术治理委员会成员（全球14人），担任华为昇腾专家，连续4年评为全国最佳GPU教育工作者。,(N/A),(N/A),(N/A),(N/A),homepage.hit.edu.cn/tonghuasu,(N/A),AsNumpy：昇腾原生高效Python数学运算库,Chinese,CANN Workshop,当前爆发式的人工智能应用急需在兼顾性能的前提下提升开发的生产效率。本报告介绍的AsNumpy是哈工大联合华为打造的一款深度支持昇腾NPU并高度兼容Numpy接口的轻量级Python数学运算库。报告首先分析当前人工智能的计算模式，然后给出AsNumpy的设计方案和特点，最后结合实例展示了AsNumpy的易用性。,(N/A),Accept,[object Object],1755924145542,proposal-hangzhou-accepted,[object Object],(N/A)
135,李建忠,lijz@csdn.net,CSDN,奇点智能研究院院长，CSDN高级副总裁,现任奇点智能研究院院长，CSDN 高级副总裁，在人工智能、技术创新和产业生态领域拥有丰富见解与深入研究经验。于2016年发起创办全球机器学习技术大会（ML-Summit），是人工智能产业领域极具影响力的高端技术研讨与交流平台。近年来主要研究以⼤模型为主的⼈⼯智能范式，提出科技创新的“范式转换立方体 ParaShift Cube”系统框架，相关研究和演讲引起业界强烈关注。于2005年发起举办第一届全球C++及系统软件技术大会，是ISO-C++国际标准委员会委员。他创立了奇点智能研究院（Singularity Intelligence Research Institute），主要研究以⼤模型为主的⼈⼯智能范式，为包括世界五百强在内的多家企业提供人工智能与创新战略咨询。,(N/A),(N/A),(N/A),(N/A),https://singintelligence.com,(N/A),AI产业范式转变的若干个核心命题,Chinese,AI Next,大模型正在驱动AI全产业链的技术与生态范式转变。本次分享聚焦其中的若干个核心命题：AI时代的计算范式、开发范式和人机交互范式转变、 智能体应用生态、智能驱动的超级设备、语言模型与视觉模型、 强化学习带来的创新等。 通过这些核心命题的讨论，探索AI时代的技术架构路线，产业生态演进和业务创新战略。,(N/A),Accept,[object Object],1755880963469,proposal-hangzhou-accepted,[object Object],(N/A)
134,Robin Shang,mcpdirect.ai@gmail.com,iTunel Technology Ltd (Hong Kong),CTO,28年软件开发经验，25年网络开发经验，25年互联网工程经验，20年网络通信协议开发经验，5年区块链开发经验，2年AI应用开发经营。思科，联想，西门子系统开发合作伙伴。现在致力于AI网络的研究、开发。,(N/A),(N/A),(N/A),https://github.com/mcpdirect,(N/A),(N/A),开源MCP通用访问网关，解决Agent工具孤岛困境,Chinese,Agentic Web,"MCP 为 AI Agent 提供了强大的动力，但实际应用 MCP 面临诸多挑战。
* 如何无缝整合企业、家庭、移动局域网内MCP Server并全球使用
* 如何快速发布MCP Server的工具并投入使用
* 如何有效管理众多的MCP Server并灵活使用
* 如何按需设置MCP Server及工具访问权限并安全使用

MCPdirect  是一个来自中国香港创业团队的开源MCP通用访问网关项目。通过MCPdirect，我们创新性地解决了Agent工具孤岛困境 。只需要一个URL，一个授权的Key， 支持Agent 跨越互联网、企业和家庭局域网等复杂网络环境，按需访问所有Tools。","技术创新：
* URL复用
    * 一个URL覆盖所有MCP Server
* 可授权的Key
    * 为不同的用户场景创建不同的Key
    * 不同Key访问不同MCP Server组
* 原子化工具访问权限
    * 每个MCP Server的工具都可以单独访问
    * 每个MCP Server的工具都可以单独设置的访问权限
* 虚拟MCP Server
    * 重组已有MCP Server的Tools，创建新的虚拟MCP Server
    * 并且原始MCP Server及MCP Client无需任何改动
* MCP内网穿透技术
    * 允许MCP Server可以部署在私有环境
    * 任何授权的MCP Client都可以全球透明访问MCP Server

解决痛点：
* 从互联网直接访问内网部署
* 统一管理分散部署的MCP Server
* 统一管理MCP Server访问授权
* 统一管理MCP Server工具授权
* 根据不同业务场景，从已有MCP Server的工具中零代码创建新的MCP Server",Accept,[object Object],1755846813639,proposal-hangzhou-accepted,[object Object],(N/A)
133,Chen Yao,Mona@oymotion.com,"OYMotion Technologies Co., Ltd.",Chief Operating Officer (COO),"Distinguished alumnus of CEIBS (China Europe International Business School), possessing both a global perspective and hands-on local market expertise.Oversees overall strategic planning and operational management of the company’s dexterous hand product line, and leads overseas business expansion.Brings extensive multidisciplinary management experience from Fortune 500 companies, spanning financial investment, government collaboration, and cross-border operations.Has successfully led the execution of multiple cross-border initiatives and maintains an extensive network of resources across key markets in Europe, America, and Asia.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),ROHAND-Dexterous Robotic Hand,English,AI Next,"In logistics sorting, machine tending, and similar scenarios, humanoid robots face the hard performance benchmark of ""securely grasping and precisely releasing"" objects.OYMotion's flagship product ROHAND has become the critical component determining humanoid robots' operational viability.Building on existing technology.The plans to further address complex task requirements. ",(N/A),New,[object Object],(N/A),(N/A),(N/A),(N/A)
132,史忠植,support+shi@gosim.org,国际信息研究科学院,院士,"人工智能和智能科学专家。中国科学院计算技术研究所研究员、博士生导师。国际信息研究科学院(IAIS)院士, 中国人工智能学会会士，中国计算机学会会士。长期从事智能科学、人工智能等方面的研究。曾负责完成多项国家973、863、国家自然科学基金重点项目。曾荣获国家和部门科技奖项6项。2013年获得中国人工智能学会吴文俊人工智能科学技术成就奖。发表著作20多本。发表学术论文500多篇。曾担任中国计算机学会秘书长，中国人工智能学会副理事长, IFIP 人工智能机器学习和数据挖掘组主席",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),智能时代协同创新 Collaborative Innovation in the Intelligence Era,Chinese,AI Next,"2024年诺贝尔物理学奖授予霍普菲尔德(J. J. Hopfield)和 欣顿（G.E. Hinton），以表彰他们“通过人工神经网络实现机器学习的基础性发现和发明”。 2024 年诺贝尔化学奖颁发给大卫·贝克（D. Baker）、哈萨比斯 (D. Hassabis) 和约翰·迈克尔·江珀 (J.M. Jumper)，以表彰其在蛋白质设计和预测方面的贡献，这些重大事件，标志着人类智能时代的到来。本报告主要介绍智能科学的发展和基于大模型的人工智能智能体，展望智能科学技术未来的发展趋势。
",(N/A),Accept,[object Object],1755800012791,proposal-hangzhou-accepted,[object Object],(N/A)
131,Jennie Shi,jieshi@google.com,Google Cloud,AI Specialist,Google Cloud AI 专家，专注用前沿 AI 技术解决企业实际难题。在欧美科技圈打拼十余年，曾作为 AWS EMEA 区域的 AI 与大数据顾问，助力众多世界 500 强企业完成数字化转型，见证并参与了从传统 AI 到生成式 AI 的技术革新。背靠哈佛商学院 MBA 访问学者和德国柏林洪堡大学经济信息学硕士的双重学术背景，用国际化视角助力中国企业驾驭 Google 最新 AI 技术，让创新应用从构想变为现实，陪伴企业在全球化征程中一路“狂飙”。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Agent is all you need：使用 ADK、A2A、MCP 和 Agent Engine 构建智能体,Chinese,Agentic Web,解锁 AI 智能体的无限潜能！本场专题演讲将深入探讨如何借助 ADK、A2A、MCP 和 Agent Engine 构建 AI 智能体。了解如何利用 Google 最新的 AI 技术打造协作性强、高效、可扩展的多智能体系统。探索智能体开发的未来，了解智能体将如何革新我们与科技的互动方式。,(N/A),Accept,[object Object],1755800026727,proposal-hangzhou-accepted,[object Object],(N/A)
130,Zhenghao Chen,chris.zhenghaochen@gmail.com,The University of Newcastle,Assistant Professor,"Dr. Zhenghao Chen is a Faculty Member at The University of Newcastle. He obtained B.Eng. H1 and Ph.D. at the University of Sydney in 2017 and 2022, respectively.  He was a Research Engineer at TikTok, a Postdoctoral Research Fellow at the University of Sydney and a Visiting Research Scientist at Microsoft Research and Disney Research. He has been awarded Google Australia Prize, Australia RTP International Fellowship,  ACM SIGMM Outstanding Thesis Award, and Microsoft Research StrarTrack Fellowship for his academic merit. 

Dr. Chen's general research interests encompass Computer Vision, Natural Language Processing, and Machine Learning. He is particularly renowned for his expertise in Generative AI, applying his research in both academic and industrial contexts. Dr. Chen has published extensively in flagship AI conferences and journals such as CVPR, ICCV, ECCV, MM, AAAI, ICLR and journals asuch as T-PAMI, T-IP, T-MI, and holds several patents. Additionally, he serves on the Conference Program Committee (PC) for CVPR, ECCV, ICCV, SIGGRAPH, AAAI, IJCAI, MICCAI, MM, KDD and organizes workshops in MM and ICCV. He also acts as a journal reviewer for IJCV, T-IP, T-MI, T-CSVT, PR, and a Guest Editor for MDPI-Algorithms and Frontier-in-AI. ",(N/A),(N/A),https://www.linkedin.com/in/zhenghao-chen-38554a96/,(N/A),https://www.newcastle.edu.au/profile/zhenghao-chen,https://x.com/DrZhenghaoChen,AI-Driven Model & Data Compression for Next-Generation Gaming ,Chinese,AI Next,"As gaming continues to evolve toward richer, more immersive experiences—including real-time rendering, volumetric environments, and AI-driven interactivity—efficient compression of both neural models and game assets is becoming increasingly critical. This talk presents a unified perspective on AI-driven model and data compression strategies designed for next-generation gaming. We begin with visual data compression, spanning digital video, stereo and multi-view video, and 3D scene representations, which form the foundation for future immersive gaming environments such as VR and AR. The discussion then turns to model compression, focusing on emerging Generative AI techniques including Video Large Language Models (V-LLMs), Video Generation Models (VGMs), and embodied AI systems, highlighting approaches for reducing their computational and memory footprints without compromising performance. Finally, the talk outlines a cohesive roadmap for adaptive, lightweight, AI-enabled compression, enabling next-generation gaming to deliver higher-quality graphics, lower bandwidth consumption, and faster inference across diverse hardware platforms.",(N/A),Accept,[object Object],1755666320959,proposal-hangzhou-accepted,[object Object],(N/A)
129,Chen Zicong,jesseincomparable@hotmail.com,"Huawei Technologies Co., Ltd.",Huawei Cloud R&D Engineer,"Volcano reviewer, lws contributor, currently focus on scheduling and inference",(N/A),(N/A),(N/A),https://github.com/JesseStutler,(N/A),(N/A),Empowering Cloud-Native Inference: Solving Large-Scale LLM Deployment Challenges with the Volcano Scheduler,Chinese,AI Models & Infra,"The ever-growing scale of Large Language Models(LLMs) has pushed single-node deployments to their limits, making multi-node distributed inference a necessity. To manage these new distributed topologies on Kubernetes, orchestration tools like LeaderWorkerSet were created. However, a critical challenge arises when using the default scheduler: its inability to handle group scheduling often leads to resource deadlocks, where only a portion of the pods start, leaving the entire service non-operational. This talk introduces the Volcano scheduler as the solution. Integrating with Volcano not only solves the deadlock issue with gang scheduling, but also unlocks powerful capabilities through its queueing system, such as quotas, preemption, and priority. In this session, we will demonstrate the gang scheduling solution through two practical open-source examples: a foundational deployment using LeaderWorkerSet, and a prefill-decode disaggregation deployment example using the OME framework. Finally, we will offer a glimpse into Volcano's advanced performance optimizations, showcasing its existing network topology-awareness scheduling feature and discussing the ongoing development of more granular, subgroup-level topology aware scheduling.","This presentation will guide the audience through the challenges and solutions for deploying large-scale distributed LLM inference services on Kubernetes. We will begin by establishing the necessary context: the rise of multi-node distributed inference and the motivation for application orchestrators like LeaderWorkerSet . We will then immediately dive into the critical issue at hand—the current scheduling state when using LWS with the default Kubernetes scheduler, illustrating the common resource deadlock problem where services fail to become operational.

Having established the problem, the session will introduce the core solution, detailing how LeaderWorkerSet integrates with the Volcano scheduler to leverage its powerful gang scheduling capabilities. This solution will be demonstrated through two hands-on examples: a standard distributed model deployment, and a more complex prefill-decode disaggregation example using the OME framework, showcasing the flexibility of the combined platform.

Finally, we will look to the future. The talk will explore Volcano's advanced features like network topology-aware scheduling and the ongoing work of subgroup-level granularity topology-aware scheduling. We will conclude with a brief overview of the vision for Volcano's native distributed Inference API, providing the audience with a complete picture from current best practices to future innovations.",Accept,[object Object],(N/A),(N/A),(N/A),(N/A)
128,Gregory Terzian,gregory.terzian@gmail.com,FOSS(Shanghai) Technology Consulting,Founder,Servo browser engine maintainer,(N/A),(N/A),(N/A),https://github.com/gterzian,(N/A),(N/A),Embedding Servo For Fun and Profit,English,Future Web Workshop,"Servo is a web engine without a browser. In this workshop we will try to remedy this by embedding Servo in various browser-like applications, and showcase various potential use cases(maybe even the AI browser from the future). ",(N/A),Accept,[object Object],1755623879527,proposal-hangzhou-accepted,[object Object],(N/A)
127,Richard Lin 林旅强,qiang.open@gmail.com,OpenQ Consultation,Co-founder,"林旅强（Richard），全球开发者生态战略专家，OPENQ Consultation 创始人。深耕开源及开发者生态16年，曾任华为云AI开发者生态总监、零一万物AI大模型开源负责人；联合创始了 “开源社”——中国首个加入国际开源组织 OSI 的社区，并担任 RTE 开发者社区联合主理人和多个开发者社区的顾问。

作为《开源项目成功之道》、《开发者关系：方法与实践》两本专书的译者，林旅强在理论与实践结合上有着独特优势。他是国内最早布局开源出海的实践者，从技术开源到开发者生态构建再到商业变现全程见证，对软件项目全球化有着深刻洞察。

目前 OPENQ Consultation 服务美股、港股、台股上市企业及国内AI软硬件公司，并已成功指导多个项目完成全球开源生态布局。",(N/A),(N/A),https://www.linkedin.com/in/richardllin/,(N/A),(N/A),https://x.com/richardllin,开源AI出海战略：如何打造全球化的开源项目,Chinese,Open Source Globalization Workshop,很多中国开源/AI项目在国内小有名气，却难以走向全球。本演讲将揭示开源出海的四大误区，解析2025全球主战场与趋势，并结合真实案例，分享如何通过社区运营与战略布局，让你的项目在国际开发者中脱颖而出。,"本演讲面向中国开源项目作者与团队，核心目标是帮助他们理解并掌握「从国内走向全球」的战略路径。主要内容：
	1.	常见误区：只靠代码开源、忽视海外文化差异、轻视开发者生态、过度依赖单一渠道。
	2.	2025主战场：北美、欧洲、东南亚等市场的特征与机会。
	3.	三大策略：单打独斗、与本地伙伴结盟、生态共建的优劣对比。
	4.	社区运营方法论：如何在海外建立核心用户群与开发者网络。
	5.	案例拆解：
	•	初创开源项目如何用开源打开海外市场
	•	AI独角兽如何快速搭建国际开发者生态
	•	传统软件如何通过开源实现转型与价值重塑
	6.	未来趋势：AI原生开源、云边协同、开源+硬件结合的新玩法。",Accept,[object Object],1756137419100,proposal-hangzhou-accepted,[object Object],(N/A)
126,翟季冬,chenmanman@chitu.ai,后填,清华大学计算机系长聘教授，清华大学计算机系高性能所所长,"翟季冬，清华大学计算机系长聘教授，博士生导师。国家杰出青年科学基金获得者，清华大学计算机系高性能所所长。
主要从事并行计算、编程语言与编译器、性能评测等领域的研究工作。担任清华大学学生超算团队教练，指导的团队15次获得世界冠军。",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),稍后提供,Chinese,Select a Track (or Be Assigned),稍后提供,为保证嘉宾的个人形象展示效果，如若照片的尺寸或清晰度存在问题可及时联系我修正，非常感谢!   先花  18611578981,New,[object Object],(N/A),(N/A),(N/A),(N/A)
125,翟季冬,chenmanman@chitu.ai,后填,清华大学计算机系长聘教授，清华大学计算机系高性能所所长,"翟季冬，清华大学计算机系长聘教授，博士生导师。国家杰出青年科学基金获得者，清华大学计算机系高性能所所长。
主要从事并行计算、编程语言与编译器、性能评测等领域的研究工作。担任清华大学学生超算团队教练，指导的团队15次获得世界冠军。",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),稍后提供,English,AI Models & Infra,稍后提供,为保证嘉宾的个人形象展示效果，如若照片的尺寸或清晰度存在问题可及时联系我修正，非常感谢!   先花  18611578981,Accept,[object Object],1755624073646,proposal-hangzhou-accepted,[object Object],(N/A)
124,Hu He,hehu@tsinghua.edu.cn,"School of Integrated Circuits, Tsinghua University",Associate professor,"Associate professor of School of Integrated Circuits, Tsinghua University",(N/A),(N/A),(N/A),hehu-tsinghua,(N/A),(N/A),Overview of Ventus OpenGPGPU Project,English,AI Next,"Overview of Ventus OpenGPGPU Project

By Professor Hu He, Tsinghua University 

Ventus is a high-performance open-source GPGPU based on RISC-V and its vector Extension to deliver a scalable, fully open SIMT architecture for the AI and HPC era.
The key mission of creating this project two years ago, was to promote open-source corporative development in the area of GPU instruction set and architecture, and to use the project for the purpose of building upstream and downstream of technology, innovation and standards eco-chain. In addition, the open-source project will help speed up the development of GPU industry and its wide adoption in various social economic area.

This short presentation will give an overview on Ventus OpenGPGPU project – its mission, scope, its community, as well as benefits to global open standards and open-source community, and to the GPU and RISC-V industry.


Some technical Highlights of Ventus architecture:

•	Open GPGPU ISA: Features a public ISA with custom extensions for warp control, synchronization, and memory management, innovatively repurposing the 16-bit compressed instruction space for GPU operations.

•	Advanced Microarchitecture: Implemented in Chisel HDL, it includes a dual-issue pipeline, a hardware reconvergence stack to efficiently manage branch divergence, a novel Release-Consistency-Directed Coherence (RCC) protocol, and an integrated tensor core to accelerate FP16 GEMM workloads.

•	Complete Software Ecosystem: Supported by an end-to-end toolchain, including an LLVM compiler, a PoCL-based OpenCL 2.0 runtime, and a multi-backend framework for simulation (Verilator, Spike) and FPGA deployment.

•	Proven Performance: Validated as the highest-performing open-source RISC-V GPGPU, demonstrating an 83.9% reduction in dynamic instructions and an 87.4% lower CPI compared to the Vortex GPGPU on Rodinia benchmarks, while passing OpenCL conformance tests.
Fully open-sourced on GitHub and detailed in publications at IEEE ICCD and TVLSI, Ventus provides a robust and transparent platform for next-generation accelerator research and development.",(N/A),Accept,[object Object],1756486211255,proposal-hangzhou-accepted,[object Object],(N/A)
123,Chen Zicong,jesseincomparable@hotmail.com,"Huawei Technologies Co., Ltd.",Huawei Cloud R&D engineer,"Volcano reviewer, LeaderWorkerSet contributor, Huawei Cloud R&D engineer, with 2 years developing experience in Cloud Native",(N/A),(N/A),(N/A),https://github.com/JesseStutler,(N/A),(N/A),Empowering Cloud-Native Inference: Solving Large-Scale LLM Deployment Challenges with the Volcano Scheduler,Chinese,AI Models & Infra,"The ever-growing scale of Large Language Models (LLMs) has pushed single-node deployments to their limits, making multi-node distributed inference a necessity. To manage these new distributed topologies on Kubernetes, orchestration tools like LeaderWorkerSet were created. However, a critical challenge arises when using the default scheduler: its inability to handle group scheduling often leads to resource deadlocks, where only a portion of the pods start, leaving the entire service non-operational. This talk introduces the Volcano scheduler as the solution. Integrating with Volcano not only solves the deadlock issue with gang scheduling, but also unlocks powerful capabilities through its queueing system, such as quotas, preemption, and priority. In this session, we will demonstrate the gang scheduling solution through two practical open-source examples: a foundational deployment using LeaderWorkerSet, and a Prefill-Decode Disaggregation example using the OME framework. Finally, we will offer a glimpse into Volcano's advanced performance optimizations, showcasing its existing network topology-awareness and discussing the ongoing development of more granular, subgroup-level topology aware scheduling.","This presentation will guide the audience through the challenges and solutions for deploying large-scale distributed LLM inference services on Kubernetes. We will begin by establishing the necessary context: the rise of multi-node distributed inference and the motivation for application orchestrators like LeaderWorkerSet . We will then immediately dive into the critical issue at hand—the current scheduling state when using LWS with the default Kubernetes scheduler, illustrating the common resource deadlock problem where services fail to become operational.

Having established the problem, the session will introduce the core solution, detailing how LeaderWorkerSet integrates with the Volcano scheduler to leverage its powerful gang scheduling capabilities. This solution will be demonstrated through two hands-on examples: a standard distributed model deployment, and a more complex Prefill-Decode Disaggregation architecture using the OME framework, showcasing the flexibility of the combined platform.

Finally, we will look to the future. The talk will explore Volcano's advanced features like network topology-aware scheduling and the ongoing work of subgroup-level granularity topology-aware scheduling. We will also conclude with a brief overview of the vision for Volcano's native Distributed Inference API, providing the audience with a complete picture from current best practices to future innovations.",Accept,[object Object],1756085278324,proposal-hangzhou-accepted,[object Object],(N/A)
122,Yongsen Mao,sammaoys@outlook.com,Manycore Tech Inc.,Research engineer,"I am Yongsen Mao, a Research Engineer from Manycore Tech Inc. I completed my thesis-based Master’s degree at Simon Fraser University (SFU), specializing in the fields of 3D Computer Vision and Graphics. I am fortunate to be supervised by Professors Manolis Savva and mentored by Angel Xuan Chang in the GrUVi Lab. Prior to this, I received B.Eng. from ZJU (Zhejiang University) and SFU.
My research interests  lies in bridging synthetic and real-world 3D scene data to enable downstream applications in computer vision and robotics.",(N/A),(N/A),(N/A),https://github.com/SamMaoYS,https://sammaoys.github.io/,(N/A),SpatialLM: Training Large Language Models for Structured Indoor Modeling,Chinese,Embodied AI,"SpatialLM is a large language model designed to process 3D point cloud data and generate structured 3D scene understanding outputs. These outputs include architectural elements like walls, doors, windows, and oriented object boxes with their semantic categories. Unlike previous methods which exploit task-specific network designs, our model adheres to the standard multimodal LLM architecture and is fine-tuned directly from open-source LLMs.
To train SpatialLM, we collect a large-scale, high-quality synthetic dataset consisting of the point clouds of 12,328 indoor scenes (54,778 rooms) with ground-truth 3D annotations, and conduct a careful study on various modeling and training decisions. On public benchmarks, our model gives state-of-the-art performance in layout estimation and competitive results in 3D object detection. With that, we show a feasible path for enhancing the spatial understanding capabilities of modern LLMs for applications in augmented reality, embodied robotics, and more.",(N/A),Accept,[object Object],1755575754918,proposal-hangzhou-accepted,[object Object],(N/A)
121,Nicolas Flores Herr,nicolas.flores-herr@iais.fraunhofer.de,Fraunhofer IAIS,Team Lead Foundation Models & GenAI Systems,"Executive Leadership in Foundation Models & GenAI Systems 

I am the Site Lead of Fraunhofer IAIS in Dresden, where I head an interdisciplinary team working since 2022 on the development and application of large language models (LLMs) and generative AI. Our expertise spans the full lifecycle: from dataset creation, pretraining and continued pretraining to fine-tuning and instruction tuning. We carry out this work in European flagship projects such as OpenGPT-X, TrustLLM, OpenEuroLLM and Eurolingua.

In my leadership role, I combine scientific excellence with strategic impact. My team develops bespoke GenAI solutions for industry partners across diverse sectors, including scalable enterprise chatbots and specialised tools for semantic search and knowledge access.",(N/A),(N/A),https://www.linkedin.com/in/floresherr/,https://github.com/Modalities,https://www.iais.fraunhofer.de,(N/A),Sovereign AI at Scale: Data Pipelines and Research Infrastructures for European Foundation Models,English,AI Next,"An upcoming initiative is building an open ensemble of large language models (LLMs), large reasoning models (LRMs), and agent-based systems to secure Europe’s digital sovereignty. But the real innovation lies not just in model architectures, but in the data pipelines and evaluation frameworks that make these models reproducible, efficient, and adaptable.

This talk gives a research deep-dive into the technical foundations of the project:
- Data curation & processing pipelines for multilingual and domain-specific corpora (8+ trillion tokens), integrating public, synthetic, and proprietary data while ensuring bias control and reproducibility.
- Pretraining and evaluation at scale
- Reasoning extensions via reinforcement learning and test-time compute, enabling the transition from LLMs to LRMs.
- Efficient deployment strategies, including distillation, quantization, and new architectures.
In this talk I will highlight how research-heavy data pipelines and transparent evaluation are not peripheral, but central to building sovereign, open, and scalable AI infrastructures that rival global players while remaining open to the community.","Speaker: Dr. Nicolas Flores Herr, Fraunhofer IAIS

Session Type: Research Talk

Target Audience: AI/ML researchers, data pipeline engineers, infra architects, open-source developers

Keywords: Data pipelines · Foundation models · Multilingual benchmarks · Reasoning models · Distributed training · Edge inference

Takeaways:
- How to design scalable data pipelines for training and maintaining sovereign foundation models.
- Research advances in evaluation science for multilinguality and reasoning.
- Pathways to make 100B+ parameter models efficient, reproducible, and deployable in cloud-edge infrastructures.",Accept,[object Object],1755575793209,proposal-hangzhou-accepted,[object Object],(N/A)
120,Adina Yakefu,adina@hf.co,Hugging Face,EA / AI researcher,Working at Hugging Face | Advocate for diversity & open-source AI.,(N/A),(N/A),(N/A),(N/A),(N/A),https://x.com/AdinaYakup,AI 开源生态的协作与责任,Chinese,AI Next,开源让 AI 发展得更快、更开放，但同时也带来了责任挑战，比如模型偏见和合规风险。在这次分享中，我会谈谈开源社区如何协作，以及我们该如何在开放与责任之间找到平衡。,(N/A),Accept,[object Object],1755579135378,proposal-hangzhou-accepted,[object Object],(N/A)
119,Nicolas Flores Herr,nicolas.flores-herr@iais.fraunhofer.de,Fraunhofer IAIS,Team Lead Foundation Models & Gen AI Systems,"Nicolas Flores Herr is Site Lead at Fraunhofer IAIS in Dresden, where he leads a team specialising in large language models and generative AI. He is responsible for projects such as OpenGPT-X, TrustLLM and Eurolingua, and develops bespoke GenAI solutions for industry and business applications.

With a PhD in physics and more than ten years of research in neuroscience, he combines scientific depth with practical innovation. In keynotes and panel discussions, he speaks about the strategic role of foundation models, digital sovereignty, and the responsible deployment of AI in Europe.",(N/A),(N/A),https://www.linkedin.com/in/floresherr/,https://www.linkedin.com/in/floresherr/,https://www.iais.fraunhofer.de/de/branchen-themen/themen/generative-ki/opengpt-x.html,(N/A),From Data to Commons: Building AI as a Global Digital Public Good,English,Open for SDG,"Open Foundation Models, Data Pipelines, and the Path to Shared Sovereignty in AI
AI is becoming a critical layer of global infrastructure yet its future hinges on whether it is developed as a commons or as a closed utility. To fully realize AI as a Global Digital Public Good, we must rethink not only the role of models, but also the ecosystems of data, pipelines, and governance that sustain them.

At Fraunhofer IAIS, we are advancing this vision by building multilingual and domain-specific open foundation models such as Teuken, and by designing specialized data pipelines that ensure transparency, reproducibility, and sovereignty. The true advantage in AI does not lie solely in the size of the model, but in the ability to build trusted, high-quality data resources and make them openly available for innovation across regions and industries.","This keynote will explore:
Why data pipelines and open datasets are the foundation of trustworthy AI.
How open-source AI can strengthen regional digital sovereignty while fueling global collaboration.
Pathways for transforming AI from a competitive moat into a shared digital commons that drives both innovation and equity.
By reframing AI as a public good, we can align technological progress with societal benefit, ensuring that open-source communities, enterprises, and governments together shape a future where AI remains accessible, transparent, and beneficial for all.",Accept,[object Object],1755576029084,proposal-hangzhou-accepted,[object Object],(N/A)
118,Markus Sabadello,markus@danubetech.com,Danube Tech,CEO,"Markus Sabadello has been a pioneer and leader in the field of digital identity for many years and has contributed to cutting-edge technologies that have emerged in this space. He is co-editor of the Decentralized Identifiers standard at W3C, and member of the Steering Committee at the Decentralized Identity Foundation. Markus has spoken at dozens of conferences and published papers about both the politics and technologies of digital identity. He is founder of Danube Tech, a consulting and development company that works on decentralized identity infrastructure.",(N/A),(N/A),(N/A),https://github.com/danubetech/,https://danubetech.com/,(N/A),Decentralized Identifiers (DIDs) for the Agentic Web,English,Agentic Web,"The Agentic Web needs digital identity that is independent of central authorities and intermediaries. This talk will present the technology, current activities, and the community of Decentralized Identifiers (DIDs), a foundational standard from the W3C.","I will give an overview of the technological background, the community, and current developments around Decentralized Identifiers (DIDs). DIDs are used as a basis for many other digital identity building blocks, such as Verifiable Credentials (VCs), DIDComm, OID4VC, Decentralized Web Nodes, etc. In the talk, I can also give an overview of popular DID ""methods"", which are how DIDs are implemented in a concrete way (e.g. blockchain based, web-based, fully decentralized, etc.). I can talk about which DID methods may be ideally suited for Agentic Web use. I will collaborate with Wenjing Chu, Drummond Reed, and others in the preparation of this talk. There are many interesting intersections and synergies between the fields of AI and digital identity. For example, there is a new AI working group at the Decentralized Identity Foundation (DIF). And there is the First Person Project, which is getting a lot of attention. Decentralized Identifiers (DIDs) are an ideal basis for connecting AI, Agentic Web, and digital identity. I look forward to exploring these synergies and opportunities in my talk, and at the conference with other participants.",Accept,[object Object],1755539660092,proposal-hangzhou-accepted,[object Object],(N/A)
117,Yue Bao,baoyue2@huawei.com,Huawei,Senior Engineering,"Yue Bao serves as a software engineer of Huawei Cloud. She is now working 100% on open source, focusing on lightweight edge and edge api-server for KubeEdge. She is now the KubeEdge mainatiner. Before that, Yue worked on Huawei Cloud Intelligent EdgeFabric Service and participated in multiple edge engineering projects. Yue graduated from Chu Kochen Honors College of Zhejiang University, majoring in information science and electronic engineering.",(N/A),(N/A),(N/A),https://github.com/Shelley-BaoYue,(N/A),(N/A),AI for Edge: Exploring the possibilities and value with KubeEdge,Chinese,Edge AI Workshop,"Edge AI enables real-time, low-latency inference by processing data locally, unlocking transformative applications across industries. With advancements in cloud-native technologies, Edge AI is evolving into a powerful cloud-edge collaborative paradigm, allowing dynamic AI workload orchestration between edge and cloud to optimize performance, accuracy, and privacy.
KubeEdge’s distributed edge-cloud AI framework, Sedna, empowers seamless deployment of AI models across edge and cloud environments. In this talk, we’ll explore how KubeEdge leverages Sedna to enable efficient inference and automation at the Edge.",(N/A),Accept,[object Object],1755575994546,proposal-hangzhou-accepted,[object Object],(N/A)
116,Zhizhen Ye,yezhizhenjiakang@gmail.com,Huawei,Software Engineer,"Zhizhen (Euclid) joined Huawei on December 2024, and started his adventure with Servo browser engine in February 2025. Over the past half year, he's become a core contributor to various parts, but most significantly Embedder and WebDriver. He's recently nominated, then elected as a maintainer of Servo project.",(N/A),(N/A),(N/A),https://github.com/yezhizhen,(N/A),(N/A),"WebDriver with Servo, Automated test & OpenHarmony",English,Future Web Workshop,"Servo is ported to OpenHarmony in 2024, as presented in [GOSIM 2024](https://china2024.gosim.org/schedules/porting-servo-to-openharmony). In this talk, I will show the significant progress made for WebDriver in Desktop version of Servo over the last four months, how we seamlessly ported it to OpenHarmony recently, the motivation and challenges.",(N/A),Accept,[object Object],1755534752165,proposal-hangzhou-accepted,[object Object],(N/A)
115,Qian Zheng,qianzheng@zju.edu.cn,Zhejiang University,Assistant Professor,郑乾，浙江大学计算机科学与技术学院、脑机智能全国重点实验室“百人计划”研究员，博士生导师，国家海外高层次青年人才（2021），VALSE EACC副主席委员。研究方向主要为类脑视觉，发表论文70余篇，包括T-PAMI，CVPR，ICCV，NeurIPS，ICML等，获2024 ACM杭州分会“新星奖”，主持国家自然科学基金面上项目，是国家自然科学基金重点项目、国家科技重大专项课题负责人，担任国际期刊T-CDS、Neurocomputing编委，多个CCF-A类会议、期刊审稿人。更多的信息请参考: https://q-zh.github.io/,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),脉冲计算：挑战和机遇,Chinese,AI Next,"本报告主要介绍脉冲计算这一新兴类脑计算范式的核心挑战与关键机遇。脉冲计算以事件驱动和异步信息传递为特征，区别于传统连续同步计算。报告首先聚焦核心挑战：非连续性计算模型的构建难题，探讨如何建立高效、可用的算法框架，随后阐述脉冲计算在模型算法、感知器件融合、神经拟态硬件应用三个方面的潜在应用潜力及前景。
",(N/A),Accept,[object Object],1755534800476,proposal-hangzhou-accepted,[object Object],(N/A)
114,吕国立,wangdan@ft.tech,非凸科技,Senior Software Engineer,非凸科技软件开发高级工程师，Rust开源项目maybe-async维护者。从业以来，专注低延迟量化交易系统和量化投研平台领域，在量化行业的业务系统中持续应用并探索Rust语言实践。,(N/A),(N/A),(N/A),https://github.com/fMeow,(N/A),(N/A),用Polars和LLM agent赋能——下一代AI量化回测平台的实践,Chinese,AI Next,本次演讲将揭示我们如何构建一个基于Rust构建的面向未来的AI量化回测平台，它采用 Polars 来加速数据处理与回测结果的统计，确保了基础性能的高效。然而，真正的突破在于我们引入的LLM智能体。我们通过设计独特的 MCP接口，让LLM能够像资深交易员一样，理解复杂的市场数据、自主进行策略分析与构建，甚至自动优化参数。这种智能体的融入，极大地降低了策略开发的门槛，使得非专业用户也能利用AI的力量进行高效的量化研究。,本次演讲展示了一个 Rust + Polars 驱动的高性能 AI 量化回测平台。其核心创新是引入 LLM 智能体（通过 MCP 接口），使 AI 能像交易员般自主分析市场、构建并优化策略。这显著降低了量化研究的门槛，赋能非专业用户利用 AI 进行高效策略开发。演示过程中主要展示截图或者录屏。,Reject,[object Object],(N/A),(N/A),(N/A),(N/A)
113,Xinwei Hu,huxinwei@huawei.com,openEuler Community,openEuler 社区技术委员会主席（Chair of the openEuler Community Technical Committee））,"2011年加入华为，现为 ICT 操作系统首席专家，中央软件院架构与设计管理部部长；2020 年起任 openEuler社区技术委员会主席；2021年度CCF杰出工程师奖。曾在 SuSE Linux 等公司担任研发负责人，具有长期的操作系统、高可用软件、底层软件等领域工作经验和技术积累；对处理器、体系架构、OS、容器等具有广阔的技术视野。
（Joined Huawei in 2011, currently serving as the Chief Expert of ICT Operating Systems and Director of Architecture and Design Management at the Central Software Institute; has been the Chairman of the openEuler Community Technical Committee since 2020; recipient of the 2021 CCF Outstanding Engineer Award. Previously held R&D leadership positions at companies such as SuSE Linux, with extensive experience and technical expertise in operating systems, high-availability software, and low-level software; possesses a broad technical perspective on processors, architectures, OS, and containers.）",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Intelligence BooM AI开源基础软件使能生态共建（Intelligence BooM AI Open-Source Foundational Software Enables Collaborative Ecosystem Building）,Chinese,Open for SDG,"最初的Linux 发行版从集成 LAMP开始，推动了技术的普及和平民化，进而促成了互联网产业的成功和繁荣。在AI时代，需要快速发起和推动一个面向应用的全栈开源解决方案，促成 AI 技术的普及和普惠，因为开源是推动技术普及，促成产业繁荣的可行路径。
   Intelligence BooM AI开源基础软件栈是openEuler社区联合23家社区/伙伴成员一起打造的大模型全栈开源解决方案，包含异构融合平台，智能应用平台，运行加速平台，数据管理平台，任务管理平台及全栈安全平台6大平台，3大发布件归档于openEuler社区，同时包含多个开源组件。首版本提供3种交付件形态，满足不同伙伴需求，本次发布技术点包含智能体应用一健部署，异构资源极致融合，算子开发极低门槛，强化操作系统原生智能，系统全链路安全等，本次的技术发布，伙伴可以基于参考实现进行商业场景应用，参与社区代码开发，技术及Agent应用创新等。
方案的愿景是：
1.打破技术壁垒：通过全栈开源加速大模型推理技术普惠化
2.赋能行业转型：共建智能化应用平台支撑产业智能化升级
3.推动生态协同：联合社区、高校与企业统一技术标准并增强生态兼容

The initial Linux distributions, starting with the integration of LAMP, propelled the popularization and democratization of technology, thereby contributing to the success and prosperity of the internet industry. In the era of AI, there is a need to rapidly initiate and promote a full-stack open-source solution oriented towards applications, to facilitate the popularization and inclusiveness of AI technology, as open-source is a viable path to drive technological popularization and industrial prosperity.
The Intelligence BooM AI open-source software stack is a comprehensive open-source solution for large models, developed in collaboration with 23 community/partner members. It includes six major platforms: a heterogeneous fusion platform, an intelligent application platform, a runtime acceleration platform, a data management platform, a task management platform, and a full-stack security platform. Three major releases are archived in the openEuler community, along with multiple open-source components. The first version offers three forms of deliverables to meet the needs of different partners. The technical highlights of this release include one-click deployment of intelligent agent applications, extreme fusion of heterogeneous resources, extremely low barriers to operator development, enhanced native intelligence of the operating system, and full-chain system security. With this technical release, partners can apply the reference implementation in commercial scenarios, participate in community code development, and innovate in technology and Agent applications.
The vision of the solution is:
1. Breaking down technical barriers: Accelerating the popularization of large model inference technology through full-stack open-source.
2. Empowering industry transformation: Co-building intelligent application platforms to support industrial intelligent upgrading.
3. Promoting ecosystem collaboration: Uniting communities, universities, and enterprises to unify technical standards and enhance ecosystem compatibility.",(N/A),Accept,[object Object],1755576015306,proposal-hangzhou-accepted,[object Object],(N/A)
112,Xiang Yang,Ryu-Yang@qq.com,BAAI,Algorithm Engineer,"Xiang Yang is an Algorithm Engineer at BAAI, where he focuses on developing unified frameworks for embodied intelligence, constructing embodied intelligence models, and implementing advanced data augmentation techniques. He also maintains a strong interest in neuroscience, cognitive intelligence, and physics.",(N/A),(N/A),(N/A),http://github.com/Ryu-Yang,(N/A),(N/A),"DoRobot — A Containerized Embodied Intelligence Operating System Seamlessly Integrating Dora, ROS, and LeRobot",Chinese,Dora Workshop,"DoRobot is a Rust-based, highly modular, containerized, distributed, and decentralized operating system for embodied intelligence. It seamlessly integrates Dora, ROS, and LeRobot frameworks through a dual-domain architecture.
D- Components (Implementation Domain) provide foundational building blocks: D-Container (Dockerized environments), D-Node (hardware/software processing units), D-Link (auto-discovery, QoS-aware data links), D-Com (communication abstraction), and D-Core (system management).
DR- Components (Functional Domain) represent high-level capabilities (e.g., DR-DataCollect), flexibly implemented by composing D- components (e.g., multiple D-Containers + D-Nodes).
This decoupling of functional requirements (DR-) from technical implementation (D-) enables modular, scalable, and resilient development of complex embodied AI systems.",(N/A),Accept,[object Object],1755462951243,proposal-hangzhou-accepted,[object Object],(N/A)
111,王冬,dowang@nvidia.com,NVIDIA,GPU 计算专家,王冬，博士，GPU 计算专家。当前主要从事大语言模型训练与推理过程的通讯优化。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),大规模混合专家模型（MoE）中的All2All通信优化研究,Chinese,SGLang Workshop,针对万亿级参数规模的混合专家（MoE）模型，其分布式训练与推理长期面临跨节点通信瓶颈的制约。为此，业内提出了专门面向 MoE 与专家并行（EP）的高性能通信库 DeepEP，该库通过提供高吞吐量、低延迟的全对全（All2All）GPU 内核以及低精度通信支持。我们基于底层高性能的RDMA通信库，针对非对称域带宽转发模型进行了进一步优化，例如在NVLink 域引入多机流水线机制大大减少了SM资源的使用，对RDMA域的高性能底层接口进行了融合和优化，从而在端到端的All2ALL通信中大大降低了计算资源占用的，同时显著提升有效带宽，并原生支持 FP8、BF16 等多精度计算，以及FP4的低精度通信，覆盖训练与推理全场景，为后续超大规模人工智能基础设施提供模块化通信范式。,(N/A),Accept,[object Object],1755587717641,proposal-hangzhou-accepted,[object Object],(N/A)
110,Hu YouHao,starlitxiling@gmail.com,Dora-rs,Student,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),How to switch the project from ROS to Dora,English,Dora Workshop,"ROS is a traditional robotics operating system that is widely used in the robotics field, but it also has many flaws. Dora provides more options for people in these fields and offers a better user experience than ROS. However, for many traditional ROS-based applications, how should we migrate to Dora?","about dora api , communicate middleware",Accept,[object Object],1755462974860,proposal-hangzhou-accepted,[object Object],(N/A)
109,Xiaolei Zhang,zhangxiaolei.666@bytedance.com,Bytedance,AI Performance Optimization Expert,"With over 10 years of in-depth experience in the field of AI model & infrastructure, I have accumulated full-link practical expertise spanning from AI-on-chip algorithm hardware adaptation, participation in high-performance AI chip research and development, to building efficient and scalable AI infrastructure. Currently, I am focusing on AI performance optimization at Volcano Engine, working to break through bottlenecks through synergy among models, algorithms, chips, and infrastructure, and continuously empowering efficient AI services.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Deploying models with PD Disaggregation and Expert Parallelism on compute-constrained GPUs,Chinese,SGLang Workshop,"In resource-constrained computing GPUs, focus on PD+EP deployment practices. Analyze hardware characteristics and core kernel performance: different shapes affect GQA and MLA performance, EP outperforms TP in specific scenarios with increased benefits at scale, and attention should also be paid to DeepEP communication and the ratio of computation to communication. In the prefill phase, improve tensorcore utilization, fuse computation and communication to reduce communication impact, and utilize sparse attention. In the decode phase, different parallelization methods are applied based on module characteristics. MOE still uses EP parallelization, combined with high-performance hardware to reduce communication overhead, and considers speculative decoding optimization.",(N/A),Accept,[object Object],1755579402286,proposal-hangzhou-accepted,[object Object],(N/A)
108,Xiaolei Zhang ,zhangxiaolei.666@bytedance.com,ByteDance,AI Performance Optimization Expert,"With over 10 years of in-depth experience in the field of AI model & infrastructure, I have accumulated full-link practical expertise spanning from AI-on-chip algorithm hardware adaptation, participation in high-performance AI chip research and development, to building efficient and scalable AI infrastructure. Currently, I am focusing on AI performance optimization at Volcano Engine, working to break through bottlenecks through synergy among models, algorithms, chips, and infrastructure, and continuously empowering efficient AI services.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Deploying models with PD Disaggregation and Expert Parallelism on compute-constrained GPUs,Chinese,AI Models & Infra,"In resource-constrained computing GPUs, focus on PD+EP deployment practices. Analyze hardware characteristics and core kernel performance: different shapes affect GQA and MLA performance, EP outperforms TP in specific scenarios with increased benefits at scale, and attention should also be paid to DeepEP communication and the ratio of computation to communication. In the prefill phase, improve tensorcore utilization, fuse computation and communication to reduce communication impact, and utilize sparse attention. In the decode phase, different parallelization methods are applied based on module characteristics. MOE still uses EP parallelization, combined with high-performance hardware to reduce communication overhead, and considers speculative decoding optimization.",(N/A),New,[object Object],(N/A),(N/A),(N/A),(N/A)
107,Chunhui Mo,mochunhui@huawei.com,"Huawei Technologies Co., Ltd.",Web Frontend Framework Technology Expert,"Member of the W3C Machine Learning Community Group, with contributions to proposals in the field of Web AI. Currently working at Huawei, focusing on Web frontend development frameworks and leading the product R&D of OpenTiny NEXT — an intelligent frontend solution.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Exploring and Practicing Agentic Web App Development,Chinese,Agentic Web,"Generative UI and MCP services represent the evolutionary direction of web standards in the AI era. The two core functions of browsers—serving as channels for information retrieval and interfaces for web applications—are undergoing a paradigm shift, with both information and interactions increasingly migrating to AI-driven workflows. Generative UI dynamically deconstructs and reconstructs web interfaces into adaptive, context-aware interactions. MCP services enable direct invocation by AI Agents, bypassing traditional user-facing layers. In developing Agent-centric applications, we must prioritize: 
Generative UI technologies to enable fluid, AI-native interfaces. MCP-enabled web applications to empower Agent interoperability. Our goal is to align current web applications with the Agent-dominated AI landscape anticipated within the next 3–5 years.",(N/A),Accept,[object Object],1755464354928,proposal-hangzhou-accepted,[object Object],(N/A)
106,Guangzhen Li,liguangzhen2@huawei.com,Huawei,Web Core Expert，HUAWEI,Web Core Expert，HUAWEI,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),OpenHarmony ArkWeb进展及AI探索,Chinese,Agentic Web,OpenHarmony ArkWeb进展及AI探索,(N/A),Accept,[object Object],1755463081620,proposal-hangzhou-accepted,[object Object],(N/A)
105,Chunhui Mo,mochunhui@huawei.com,Huawei,"Chunhui Mo, Cloud Technology Experts, Huawei Corp.","Chunhui Mo, Cloud Technology Experts, Huawei Corp.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Exploring and Practicing Agentic WebApp Development,Chinese,Agentic Web,Exploring and Practicing Agentic WebApp Development,(N/A),New,[object Object],(N/A),(N/A),(N/A),(N/A)
104,ZHANG RENWEI,zhangrenwei1@huawei.com,HUAWEI,AI Compiler Expert,Maintainer of MindSpore AKG Community.,-,-,-,-,-,-,AIKG: AI Driven Kernel Generator,Chinese,AI Models & Infra,"Operator kernel development is a critical for large model training and inference. Improving kernel development efficiency remains a key focus in both industry and academia. To address this, we open-sourced ​​AIKG​​—an LLM based Kernel auto generator tool. AIKG enables developers to directly generate ​​Triton DSL​​ from Numpy/PyTorch APIs by Multi agent design, currently supporting multiple backends including ​​GPU and Ascend NPU​​.","Operator kernel development is a critical for large model training and inference. Improving kernel development efficiency remains a key focus in both industry and academia. To address this, we open-sourced ​​AIKG​​—an LLM based Kernel auto generator tool. AIKG enables developers to directly generate ​​Triton DSL​​ from Numpy/PyTorch APIs by Multi agent design, currently supporting multiple backends including ​​GPU and Ascend NPU​​.",Accept,[object Object],1755464429579,proposal-hangzhou-accepted,[object Object],(N/A)
103,Vincent Caldeira,vincent.caldeira@redhat.com,Red Hat APAC,CTO,"Vincent Caldeira, CTO of Red Hat in APAC, is responsible for technology strategy and emerging
technology engineering. Named a Top 10 CTO in APAC by Technology Magazine in 2023, he
has more than 20 years in IT, excelling in technology transformation in finance. An authority in
open source, cloud computing, and digital transformation, Vincent frequently speaks on data
analytics, AI/ML including AI Safety, digital sovereignty, and IT sustainability. He is a Technical
Advisor to Linux Foundation OS-Climate, a member of the GSF Green AI Committee, a
Technical Oversight Committee Member at FinTech Open Source Foundation (FINOS), a
member of LF AI & Data GenAI Commons and leads several CNCF AI Initiatives.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Unleashing GenAI Inference at Scale: A Deep Dive into the llm-d Project,English,AI Models & Infra,"The rapid evolution of Generative AI has created a critical bottleneck for enterprises: deploying
Large Language Models (LLMs) reliably and affordably at scale. Traditional cloud-native
infrastructures struggle with the unique demands of LLM inference, leading to prohibitive costs
and performance issues that hinder widespread adoption. To overcome this shared
industry-wide challenge, a growing community of leaders is building an open, Kubernetes-native
standard to make production AI practical for everyone. This initiative aims to establish a new
paradigm for AI workloads, much like Kubernetes did for container orchestration.
This session introduces the llm-d project, an open-source platform designed to democratize
GenAI by dramatically reducing operational costs and complexity. Initiated by founding members
including Google Cloud, Red Hat, IBM, and NVIDIA, llm-d provides a shared platform for
running inference workloads with competitive performance across diverse hardware. Early
results demonstrate its potential, achieving up to 3x lower Time To First Token (TTFT) and 2x
higher throughput while meeting strict service level objectives. We will explore how this
community-driven approach is engineered to bridge the gap between traditional applications
and sophisticated, cloud-native AI.
More than a technical overview, this session is an exploration of the principles behind building
the future of open, distributed AI inference. We will focus on the 'why' behind llm-d's design for
optimizing the unique, resource-intensive nature of LLM workloads. This talk serves as an open
invitation to AI engineers, MLOps practitioners, and researchers to influence the trajectory of
production GenAI. Come discover how you can contribute to and benefit from this emerging
open standard, helping shape the next generation of scalable AI infrastructure.","This session provides a structured and in-depth overview of the llm-d project
(https://github.com/llm-d/llm-d), addressing the critical challenges and innovative solutions in
scaling Generative AI (GenAI) inference. We will begin by setting the stage, highlighting the
central problem facing the industry today: while Large Language Models (LLMs) and emerging
agentic AI workflows are transformative, their deployment at scale is often hindered by immense
operational costs and infrastructure complexity. These challenges can lead to a degraded user
experience and create a significant barrier to entry, preventing many from leveraging the full
power of modern AI.
To address this, we introduce llm-d, an open-source project leveraging Kubernetes and other
cloud-native technologies to democratize GenAI inference. The project's core mission is to
dramatically reduce operational costs, provide the fastest time-to-value, and deliver competitive
performance per dollar for a wide range of models across diverse hardware. This talk will
demonstrate how llm-d serves as a shared, standardized platform for running sophisticated AI
workloads efficiently and reliably.
A significant portion of this presentation will be dedicated to a breakdown of llm-d’s robust,
layered architecture. At its foundation, the vLLM Layer acts as the core execution engine,
leveraging key innovations like paged attention and continuous batching for high-throughput,
low-latency performance. Built upon this, the Kubernetes Layer serves as the essential
orchestration backbone, providing the scalability, fault tolerance, and dynamic resource
management necessary for production environments through containerized workloads,
Horizontal Pod Autoscalers (HPA), and Custom Resource Definitions (CRDs). Tying it all
together, the Inference Gateway Layer provides an intelligent control plane for traffic
management, security, and observability, extending the standard Kubernetes Gateway API with
AI-native routing capabilities tailored for LLM workloads.
Beyond the architecture, we will then delve into the critical innovations that give llm-d its
performance edge. We will cover various concepts including vLLM Optimized Inference
Scheduler, which uses prefix-cache-aware and load-aware routing to intelligently direct requests
and minimize latency, Disaggregated Serving, where the compute-bound prefill and
memory-bandwidth-bound decode phases of inference are separated onto independent,
purpose-built instances for granular optimization and scaling, and the concept of Multi-Tier KV
Cache management for improving response times.
This project is fundamentally a community effort. The talk will conclude by emphasizing the
open-source collaboration at the heart of llm-d, highlighting the contributions of founding
members like Google, Red Hat, IBM, and NVIDIA. We will extend an open invitation to AI
engineers, MLOps practitioners, and researchers based in China to join us in shaping the future
of distributed LLM inference.",Accept,[object Object],1755464456712,proposal-hangzhou-accepted,[object Object],(N/A)
102,Wenjing Chu,wchu@futurewei.com,"Futurewei Technologies, Inc.",Senior Director of Technology Strategy,"Wenjing is the Sr. Director of Technology Strategy on Trust of AI Agents & Agentic Internet at Futurewei. He is a long time leader of open source communities currently serving in the Technical Advisory Councils of the OpenWallet Foundation and the Linux Foundation Decentralized Trust, and was a founding member of the OpenWallet Governing Board. He chairs the AI and Human Trust (AIM) Working Group in Trust over IP (ToIP) where the specification of TMCP/TA2A (running MCP and A2A over TSP)
Is being developed. He is the co-author of the Trust Spanning Protocol (TSP) specification and is a core contributor to the Linux Foundation First Person Identity Project.
",(N/A),(N/A),https://www.linkedin.com/in/wenjingchu/,(N/A),(N/A),(N/A),TMCP/TA2A: Running MCP and A2A over TSP,English,Agentic Web,"AI model (e.g. LLM) based agent protocols—MCP and A2A—are converging on a common wire model (JSON‑RPC over stdio/HTTP/SSE) and borrowing web‑service security (TLS + OAuth/OIDC) to get adoption fast. That’s a rational starting point—but it leaves trust tied to domain‑ and account‑centric identities issued by whichever authorization server happens to front the service today.
The problem? Agents are not websites! They are long‑lived principals that cross administrative boundaries, migrate between hosts, and exchange signed artifacts and delegations with other agents.
Our proposal is to specify a scheme to run MCP and A2A over the Trust Spanning Protocol (TSP). TSP introduces long‑term, self‑administered, public‑key–based identifiers with verifiable trust roots and a message‑oriented envelope that provides identity authenticity, content integrity, confidentiality, and metadata‑privacy controls. In effect, TSP gives agent protocols a first‑class identity and object‑security layer that survives host/IdP moves  and composes across administrative domains.
We call such methods TMCP and TA2A respectively. They fully comply with MCP and A2A specifications, fix the trust and security gaps found in the traditional web stack, and enable stronger trust signals for truly autonomous AI agent based applications.",(N/A),Accept,[object Object],1755311622357,proposal-hangzhou-accepted,[object Object],(N/A)
101,Satya Mallick,spmallick@opencv.org,OpenCV.org,CEO,"Dr. Satya Mallick is the CEO of OpenCV.org - the non-profit that maintains the largest computer vision library in the world. He is an entrepreneur in Artificial Intelligence, Computer Vision, and Machine Learning. Before starting his AI consulting company, Big Vision LLC, he co-founded Sight Commerce Inc (formerly Taaz Inc.), where he built AI products that reached over 100M users. His work has been covered in publications like TechCrunch, Huffington Post, NYTimes, and WSJ. Dr. Mallick is also the creator of some of the most popular online computer vision and AI courses. In 2017, IBM's AI Blog named Dr. Mallick as one of the top 20 people in AI to follow on Twitter. ",(N/A),(N/A),https://www.linkedin.com/in/satyamallick/,https://github.com/spmallick/learnopencv,(N/A),https://x.com/LearnOpenCV,OpenCV 5: The Struggles & Triumph of Open Source Software,English,Embodied AI,"In a world where massive AI projects are closed-source, and a handful of companies are set to control the future of AI, people are rightfully asking, ""Where is OpenCV 5?"" Join us to learn about the past, present, and future of the open-source computer vision library we all use and love. We will discuss what is new and improved in OpenCV 5 and what is deprecated. Finally, we will discuss OpenCV's future roadmap. ",(N/A),Accept,[object Object],1755275436177,proposal-hangzhou-accepted,[object Object],(N/A)
100,嘉欣,690734561@qq.com,广东广信君达律师事务所,律师,擅长科技初创企业股权纠纷的律师,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),让每1%股权都有战斗力,Chinese,Select a Track (or Be Assigned),当技术合伙人的20%股权被稀释到8.7%，当对赌失败让创始人负债2.3亿，当离婚分割将公司控制权拱手让人——股权战争的硝烟从未熄灭。我将为大家揭秘：动态股权武装系统：用算法将1%股权转化为反收购利刃； 控制权护城河：12%股权掌握71%投票权的信托攻防术。,"去年我见证一位AI公司CEO，用技术换回35%股权。却在B轮融资后发现他的投票权只剩8.7%，而条款陷阱藏在《股东协议》的细节里。  
股权战争没有硝烟，但尸骨无存者从不会少。
       真实血案 ：1.合伙人暗雷。技术大牛代持股权被稀释，反目后带走核心代码 ，公司估值暴跌60%。2.资本绞索。对赌协议触发回购，创始人个人负债2.3亿，家庭房产遭法拍。3.婚姻核爆。离婚分割未设防股权，控制权易主竞争对手 ，苦心经营7年的公司改名换姓 。
当1%股权失去战斗力，它就成了敌人刺向你咽喉的刀。
战略：激活股权战斗力。第一式：动态股权武装系统。某无人机公司用“贡献值权重算法”，将技术合伙人股权从20%升至34%，反制资本恶意收购。核心武器：1.关键决策一票否决权。2.漏斗式退出机制（离职股权自动回笼） 。第二式：控制权护城河。生物医药创始人通过双层股权信托，用12%股权掌握71%投票权。 核心武器：1.配偶放弃股权声明公证 ；2继承权限制条款（防子女内斗）。我曾为挽回0.5%股权，陪客户在证监会档案库奋战三天三夜。  
因为我知道这0.5%背后，是47名员工的饭碗，是一项改变医疗的革命性专利。股权不是数字，是你带领团队冲锋的战旗！
",Reject,[object Object],(N/A),(N/A),(N/A),(N/A)
99,Changjian Gao,gcj@juicedata.io,Juicedata,Solutions Architect,"With a decade of experience in the internet industry, have served as an architect in multiple teams at Zhihu, Jike, and Xiaohongshu, focusing on technical research in distributed systems, big data, and AI fields.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Scaling AI Workloads with JuiceFS: A Distributed File System Built on Object Storage,Chinese,AI Models & Infra,"Modern AI workloads, including model training and large-scale inference, demand high throughput, low latency, and elastic scaling. While object storage offers a cost-effective solution for managing large volumes of data, it often encounters performance limitations, especially when handling high metadata volume and small-file I/O.

JuiceFS is a distributed file system designed to run on object storage, addressing these performance challenges. It ensures POSIX compatibility for seamless integration with existing systems and utilizes multi-level caching to enhance read/write performance. Additionally, JuiceFS integrates natively with Kubernetes, supporting cloud-native environments that require scalability and flexibility.

Since being open-sourced in 2021, JuiceFS has been adopted in production environments to meet the storage needs of large-scale AI workloads. This presentation will examine the storage challenges in AI applications, the limitations of both object storage and traditional storage systems, and provide an overview of JuiceFS's architecture, supported by case studies from production environments.","Outline:
- Storage Challenges in Three Typical AI Scenarios: AI inference, training dataset loading, and checkpoint persistence.
- Comparison of Object Storage and Traditional Parallel File Systems in AI Workloads: Strengths and limitations in scalability, cost, performance, and manageability.
- Overview of JuiceFS Architecture: How a user-space file system bridges the performance gap of object storage with POSIX semantics and caching layers.
- Use Cases:
  - Generative AI – High-throughput training and model delivery.
  - Autonomous Driving – Multi-modal sensor data ingestion and large-scale simulation.
  - Protein Discovery – Millions of small files and long-running GPU workloads.",New,[object Object],(N/A),(N/A),(N/A),(N/A)
98,Jingbin Zhang,zhangjingbin2@huawei.com,Huawei,Senior Principal Architect & Technical Manager,"Zhang Jingbin is a Senior Principal Architect and Technical Manager of AI Infrastructure, Data Storage Product Line, Huawei, Shenzhen, China. He has led the design and implementation of multiple large-model inference-acceleration features for Huawei OceanStor A800, which have been widely deployed across finance, healthcare, and government sectors in China. He has authored numerous papers and patents on inference-oriented storage and related technologies. His research interests include large-scale AI system architecture, high-performance storage for deep-learning workloads, and intelligent acceleration technologies and their applications.", , , , ,(N/A), ,UCM面向稀疏化注意力加速的推理架构设计分享,English,AI Next,随着大模型参数与上下文窗口同步膨胀，稠密注意力计算已成为线上推理的绝对瓶颈——显存占用呈二次曲线、延迟随序列长度线性飙升。业界普遍采用KVCache+投机解码来缓解，但在超长序列的极限场景下仍捉襟见肘。本次分享聚焦「稀疏注意力」这一新范式，从算法、插件化设计到软件实现，首次系统性公开我们自研UCM推理记忆数据管理器的稀疏化推理栈的架构设计思路与落地经验。, ,Accept,[object Object],1756110578430,proposal-hangzhou-accepted,[object Object],(N/A)
97,Drummond Reed,drummond.reed@gmail.com,First Person Project,Founder,"Drummond has spent over a quarter-century in Internet identity, security, privacy, and trust infrastructure. He is currently founder and lead organizer for the First Person Project. From 2021 to 2025, he was Director of Trust Services at Gen (formerly Avast) after their acquisition of Evernym, where he was Chief Trust Officer. He is co-author of the book, Self-Sovereign Identity (Manning Publications, 2021), and co-editor of the W3C Decentralized Identifiers (DID) 1.0 specification. He currently serves as Governance Lead for the Ayra Association. He is founding board member of the OpenWallet Foundation and Trust Over IP (ToIP), where he serves as co-chair of the Technology Stack Working Group and the Concepts and Terminology Working Group. In 2002 he received the Digital Identity Pioneer Award from Digital ID World, and in 2013 he was cited as an OASIS Distinguished Contributor.",@drummondreed.bsky.social,(N/A),http://www.linkedin.com/in/drummondreed,https://github.com/talltree,http://equalsdrummond.name/,http://twitter.com/drummondreed,The First Person Project: Establishing Trust in Personal AI Agents,English,Agentic Web,"Personal AI agents are one of the most exciting areas in AI. They have the potential to assist individuals in thousands of personal tasks, projects, and decisions. But for personal AI agents to take action on behalf of their owners—ordering products, making appointments, managing budgets, storing personal records—they need to be trusted. How can a business, community, or government be sure a personal AI agent is authorized to act on behalf of a particular individual? What if something goes wrong? Will that evidence hold up in court? This session will explain how the First Person Project, in partnership with Linux Foundation Decentralized Trust, Trust Over IP (ToIP), Decentralized Identity Foundation (DIF), OpenWallet Foundation, and Ayra Association, can answer these questions. It will cover the work of the new ToIP Decentralized Trust Graph Working Group on privacy-preserving proof of personhood based on open standards and open source code for decentralized identifiers (DIDs), verifiable credentials (VCs), the Trust Spanning Protocol (TSP), and the Trust Registry Query Protocol (TRQP).",This talk will include details of how the First Person Project is implementing Personhood Credentials (as described in this seminal paper: https://arxiv.org/pdf/2408.07892) and verifiable relationship credentials (VRCs) starting with the Linux Kernel project (kernel.org) at the Linux Foundation. It will also highlight the launch in September of the Decentralized Trust Graph Working Group at Trust Over IP (ToIP) project (part of LF Decentralized Trust) and invite attendees to participate in this new WG.,Accept,[object Object],1755238412095,proposal-hangzhou-accepted,[object Object],(N/A)
96,Yuyuan Yuan,yu-yuan.yuan@zettascale.tech,ZettaScale Technology,Senior Software Engineer,"A Rustacean working in ZettaScale Technology. Developing Zenoh, an open-source protocol designed to enable efficient and scalable distributed systems for applications such as autonomous systems, drones, and robotics. Always exploring new technologies!
",(N/A),(N/A),www.linkedin.com/in/yuyuan-yuan-9a5607155,https://github.com/YuanYuYuan/,https://github.com/eclipse-zenoh/zenoh,https://x.com/az6980522,"Powering the Future of ROS 2 with Zenoh: Fast, Scalable, and Resilient Communication for Robotics and Autonomy",English,Embodied AI,"Modern robotics, V2V, and autonomous systems need fast, scalable, and resilient communication. Zenoh unifies pub/sub, queries, and storage, offering low latency, Tier-1 ROS 2 middleware rmw_zenoh, and ros-z, a new Rust framework for ergonomic ROS 2 development.
","### Audience

ROS 2 developers, robotics engineers, system architects, and engineers building distributed or real-time systems in robotics, autonomy, or V2V networks.

### Goals

- Show how Zenoh meets the communication challenges of robotics and autonomous systems.
- Highlight rmw_zenoh’s Tier-1 ROS 2 middleware status.
- Introduce ros-z as the next-generation Rust development experience for ROS 2.

### Outline

1. The Problem Space
   - Bandwidth constraints, latency sensitivity, and heterogeneous network environments.
   - Limitations of existing protocols like DDS and MQTT for robotics.

2. Zenoh Architecture
   - Unified model: pub/sub, queries, and distributed storage under a single abstraction.
   - Decentralized design and topology-aware routing.
   - Peer-to-peer, brokered, and hybrid deployments.

3. Performance & Resilience
   - Benchmarks: throughput and latency.
   - Ultra-low latency using shared memory (SHM) transport.
   - Rich plugin system enabling extensibility and custom processing.
   - Communications encryption for security.
   - Native support for embedded devices.

4. ROS 2 Integration
   - rmw_zenoh Tier-1 middleware: production-ready and officially supported.
   - Deployment patterns in ROS 2 and Autoware.

5. ros-z Project Preview
   - A full-Rust ROS 2 stack with ergonomic, idiomatic APIs, while maintaining interoperability with existing rmw_zenoh.
   - Seamless integration with C++ and Python ROS packages through the RCL layer, enabling mixed-language development.
   - Modern tooling and performance-tuned ROS 2 integration.

6. Real-World Use Cases
   - Robotics, V2V, and autonomous vehicle deployments.
   - Lessons learned, practical tips, and common pitfalls.

Key Messages

- Zenoh provides ultra-low latency, secure, and resilient communication across diverse network topologies.
- Tier-1 rmw_zenoh makes Zenoh a production-ready ROS 2 middleware.
- ros-z will deliver a high-performance, developer-friendly Rust experience for ROS 2.

Project Links

- zenoh: https://github.com/eclipse-zenoh/zenoh
- rmw_zenoh: https://github.com/ros2/rmw_zenoh
- ros-z:  https://github.com/ZettaScaleLabs/ros-z
",Accept,[object Object],1755192556098,proposal-hangzhou-accepted,[object Object],(N/A)
95,Wei Wang（王伟）,wwang@dase.ecnu.edu.cn,华东师范大学,奇点智能研究院开源技术委员会主任,王伟，奇点智能研究院开源技术委员会主任，工业和信息化部电子标准院开源治理标准总体组组长，联合国咨商开源创新专委会秘书长，华东师范大学教授，CCF杰出会员。牵头制定中国首套开源治理系列标准，研究聚焦开源治理与开源评价。在ICSE、WWW、ACL等顶会期刊发表论文百余篇，入选国家级创新人才项目、获国家级教学成果二等奖、上海开源创新卓越成果奖特等奖。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),"Open Source Empowers a Sustainable Future: Vision Outlook of the ""2025 Global Open Source Development Report""（开源赋能可持续未来：《2025全球开源发展报告》愿景展望）",English,Open for SDG,"Today, as digitalization and sustainable development become increasingly intertwined, open source has emerged as a core driver of global innovation. This report previews the ""2025 Global Open Source Development Report,"" introducing the vision of ""Open Source Development Goals"" (OSDGs), which closely aligns the development of open source ecosystems with the United Nations Sustainable Development Goals and ESG principles. Through data insights and illustrative case studies, it highlights the pivotal role of open source in green technologies, inclusive AI, and open governance. Looking ahead, this report calls for leveraging open source collaboration to accelerate sustainable innovation and build a shared digital future that is open, inclusive, and resilient.

在数字化与可持续发展深度融合的今天，开源正成为全球创新的核心驱动力。本报告通过预览《2025全球开源发展报告》，提出“开源发展目标”（OSDGs）愿景，将开源生态建设与联合国可持续目标及ESG紧密联动。通过数据洞察与典型案例，展现开源在绿色技术、普惠AI与开放治理中的关键作用。面向未来，呼吁以开源协作加速可持续创新，共建开放、包容、韧性的数字未来。",(N/A),Reject,[object Object],(N/A),(N/A),(N/A),(N/A)
94,Wei Wang（王伟）,wwang@dase.ecnu.edu.cn,华东师范大学,奇点智能研究院开源技术委员会主任,王伟，奇点智能研究院开源技术委员会主任，工业和信息化部电子标准院开源治理标准总体组组长，联合国咨商开源创新专委会秘书长，华东师范大学教授，CCF杰出会员。牵头制定中国首套开源治理系列标准，研究聚焦开源治理与开源评价。在ICSE、WWW、ACL等顶会期刊发表论文百余篇，入选国家级创新人才项目、获国家级教学成果二等奖、上海开源创新卓越成果奖特等奖。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),迈向可信与可复现：大模型开源开放分级体系构建,Chinese,AI Next,随着人工智能大模型的快速发展，其透明性、合规性与可复现性成为产业关注的核心议题。本报告基于《人工智能 关键基础技术 大模型技术体系开源开放分级评估规范》，提出一套系统化的开源开放分级框架，从“完整性”与“开放性”双维度定义L1至L4递进等级，覆盖从模型部署到全链复现的能力要求。该体系为开发者、企业、研究机构与监管方提供统一的评估基准，助力识别模型开放程度、管控合规风险、推动负责任创新。面向未来，标准化的分级评估将成为构建可信、可持续大模型生态的关键基石。,(N/A),Accept,[object Object],1755192139133,proposal-hangzhou-accepted,[object Object],(N/A)
93,丁益斌,dingyibin1@huawei.com,HUAWEI,Dr.,浙江大学计算数学博士，就职于华为2012实验室中央研究院理论研究部，主要关注并行计算、图计算、LLM推理、RAG等领域。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),昇腾高吞吐投机推理框架 Omni-Infer,Chinese,AI Models & Infra,EAGLE/MTP为代表的高接受率的投机推理方案，正推动着投机推理的落地。投机推理一次推理计算多个token，能够充分发挥昇腾高计算密度带宽比的特点。为此，我们开发适配了高性能推理框架 omniinfer，来充分发挥昇腾的性能。针对eagle、mtp等投机推理方案模型结构上的特点，我们优化投机推理的调度框架，降低昇腾的空闲时间，并对采样方式进行优化，维持模型精度、提升接受率。当然，针对昇腾硬件的特点，我们也对MLA算子进行优化，提升这类attention结构在decode阶段一次计算多个token时的性能。,(N/A),Accept,[object Object],1755192388473,proposal-hangzhou-accepted,[object Object],(N/A)
92,MaShengYue马生悦,support_msy@unitree.com,Unitree Robotics,Robot Engineer / Technical Director / Unitree,"ShengYue Ma is currently serving as a Technical Director at Unitree Robotics, focusing on robotic control systems, perception, and intelligent mobility. He graduated from Sun Yatsen University with a degree in Artificial Intelligence, and has rich experience in algorithm development, system integration, and real-world deployment. With a deep understanding of ROS, Mujoco, Isaac Gym and Linux system internals, he has led multiple projects involving navigation, autonomous control, and reinforcement learning on legged robots like Unitree GO2 and H1. ShengYue has published open-source projects and is passionate about combining cutting-edge AI with robotics hardware to push the boundary of autonomous mobility.",(N/A),(N/A),www.linkedin.com/in/shengyue-ma-a8a199324/,(N/A),(N/A),https://github.com/Msy-yy,Human-Agent Interaction in Business: Autonomy vs. Human Control,English,Embodied AI,"This panel explores the evolving dynamics of human-agent interaction in business environments, focusing on the balance between AI autonomy and human oversight. Drawing on practical insights from Unitree’s deployment of intelligent quadruped and humanoid robots in industries such as smart manufacturing, we examine how autonomy levels are defined, when to delegate tasks to AI agents, and how to ensure safe and transparent collaboration. Real-world examples, such as our logistics automation project with Geely, illustrate the transition from robotic tools to adaptive teammates. The discussion further addresses strategies for building trust with human operators and promoting responsible innovation in human-robot systems. Through structured autonomy, real-time intervention mechanisms, and co-design with frontline users, Unitree aims to deliver robust, safe, and trustworthy intelligent agents across industrial, security, and research domains.","As intelligent agents—particularly AI-powered robots—become increasingly embedded in physical business operations, the need to balance autonomy with human oversight grows more urgent. In this talk, Jim Ma draws on real-world deployment experience from Unitree’s 
collaborations with global industry leaders, including Geely and Exeeta, to examine how robotic autonomy can enhance efficiency without compromising safety or control.
The discussion outlines a five-level autonomy spectrum and explores when to delegate control to intelligent agents versus when to intervene. It also introduces Unitree’s design approach to collaborative robotics, focusing on sensor integration, real-time intervention 
capabilities, and explainable behavior policies.
Special attention is given to the concept of “adaptive teammates”—robots that work alongside humans, not as tools, but as decision-aware, safety-compliant collaborators. The talk also covers how to build trust with human operators and ensure responsible innovation 
during deployment, drawing examples from manufacturing, logistics, and R&D environments.
Key Takeaways:
Understanding the autonomy spectrum for industrial robots
Real-life cases of human-robot collaboration
Technical strategies for balancing autonomy and safety
Designing for trust, transparency, and long-term adoption",Accept,[object Object],1755192108818,proposal-hangzhou-accepted,[object Object],(N/A)
91,Dmitrii Desiatkin,desiatkin.dmitrii1@huawei.com,Huawei,System Engineer,"Just a guy who loves music, games, microcontrollers and programming.",(N/A),(N/A),https://linkedin.com/in/dmitrii-desiatkin-687268199,(N/A),(N/A),(N/A),Fonts on world wide web ,English,Future Web Workshop,"General information about how we work with fonts in web browser.
Common font stack libraries their hierarchy and interconnection.
Latest advancements in font technologies.
Some forgotten (patented techniques).","I would like to summarize my experience that I gain in Huawei during my work on various font problems inside web engines designed for mobile devices.
Give some short summary of digital fonts evolution. Bitmap fonts -> Outline fonts -> Composite fonts.
Hardware font rendering.
Provide my vision on general approaches to how we can work with font stack libraries.
Provide some architectural overview. 
Summarize and present information about font layout and rendering techniques and challenges.
Give information about Mitsubishi Electric Research patents that will expire relatively soon.
Show some cool techniques that we will gain if we will start to use shaping engines with web assembly support (spread Behdad Esfahbod ideas of fully programmable fonts).
",Accept,[object Object],1755118237996,proposal-hangzhou-accepted,[object Object],(N/A)
90,Michael Tyler Slaton,tyler@copilotkit.ai,CopilotKit,Founding Engineer,"I'm Tyler, an open-source engineer focused on the evolving boundary between humans and AI agents. I'm currently part of the founding team at CopilotKit, the company behind AG-UI, where we're working to standardize how users interact with AI agents across applications. Previously, I've worked at companies like Red Hat and Oracle, as well as various startups, giving me perspective on both enterprise-scale challenges and the rapid iteration needed in emerging technologies. Through the process of building AG-UI, I've had a front-row seat to the practical challenges of creating truly intuitive agent-user interfaces.",@tylerslaton.bsky.social,(N/A),https://www.linkedin.com/in/michael-t-slaton/,https://github.com/tylerslaton,https://www.tylerslaton.dev/,(N/A),Agentic UX: How the AG-UI Protocol Is Redefining AI-Driven User Experience!,English,Agentic Web,"AI agents are reshaping how users interact with software. This talk explores Agentic UX through AG-UI, an open protocol that standardizes agent-to-user interactions, enabling intuitive, real-time, and collaborative AI experiences.","As AI agents move from isolated tools into everyday applications, traditional UI patterns fall short. 'Agentic UX' reframes existing interfaces around continuous, real-time collaboration between humans and AI.

In this session, I'll share lessons learned from building AG-UI, an open, event-based protocol that standardizes agent-to-user communication.

Attendees will learn:
- How Agentic UX differs from conventional design paradigms
- The AG-UI event model, from streaming messages to tool calls and shared state
- Patterns for building intuitive, AI-native interfaces
- How vendor-neutral messaging enables interoperability across frameworks like LangGraph, CrewAI, and Mastra
- Real-world examples of AG-UI powering multi-agent, human-in-the-loop workflows

You'll walk away with a clear mental model for designing AI-first user experiences, practical guidelines for integrating agents into your applications, and an understanding of how standardized protocols can accelerate the agentic web.",Hold,[object Object],1755061425473,proposal-hangzhou-accepted,[object Object],(N/A)
89,Xiaoming Bao,3190792@qq.com,Huawei,Architect,"Distributed Computing, AI Inference",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),sglang on ascend 大模型推理的高效实践,Chinese,SGLang Workshop,"华为昇腾架构相比NV GPU架构存在较多不同点，包含芯片的架构、互联、软件栈、编程体系、算子库等, 也为sglang on ascend的适配与支持带来诸多挑战。本议题介绍昇腾的体系结构，以及sglang on ascend适配的心路历程与高效实践。",(N/A),Accept,[object Object],1755587468609,proposal-hangzhou-accepted,[object Object],(N/A)
88,何万青,wanqing.he@icloud.com,北京清程极智科技有限公司,"VP,  CIO",何万青 博士 清程极智VP，原英特尔首席工程师，阿里云高性能计算负责人，何博士是业内著名高性能计算和 AI 领域资深专家，在并行计算、云计算与 AI 领域有 20 年的从业经验，在英特尔时专注于并行优化、异构计算和并行文件系统，负责天河 2 号超级计算机核心>异构众核MIC 集成开发、从零到一研发阿里云弹性高性能计算EHPC 与 SCC超级计算集群产品，领导疫情期间阿里云对全球的 COVID-19科技抗疫支持。在燧原科技和清程极智，负责国产 AI 算力应用优化和开箱即用技术生态建设。何博士是十余年 CCF 资深志愿者、荣誉委员，历任 CCF YOCSEF 总部副主席，高专委执委和青工委等诸多位置上服务 CCF， CCF 杰出讲者，近年主要负责CNCC，YEF ，CED等组委。2025 年开始主持 CCF Talk-show，热心科技科普，近三年与家人出版 6 部科普作品，有公众号《四维碎片》。,(N/A),(N/A),https://www.linkedin.com/in/wanqing-warren-he-017bb347/,(N/A), 【四维碎片】微信公众号,(N/A),面向国产智能算力的大模型训推优化平台,Chinese,AI Models & Infra,"本讲介绍清程极智以国产智能算力提升为核心应用场景，设计开发面向国产大模型的训推优化平台，采用自研赤兔推理引擎，设计训练及微调统一框架、提出混合精度和低比特量化优化方案，在保持计算精度及通用问题求解能力的同时，大幅度提升模型的计算速度、>降低计算资源消耗的工程和产品实践。通过拆解大模型推理引擎的挑战和优化技术，展示国产推理引擎与国产智能算力适配的性能优势，以及在此基础之上，如何通过推理引擎的系统优化，达到E2E业务应用 Benchmark 优化的目的。

","- 大模型推理的挑战与技术因应
- 八卦炉大模型训练系统
- 训推优化套件
- 业务如何选择 Benchmark以及指标
- 实现 E2E 系统优化的“大模型户型”",Accept,[object Object],1755061471431,proposal-hangzhou-accepted,[object Object],(N/A)
87,韩虹莹,han_hongying@163.com,杭州半个宇宙科技有限公司,杭州半个宇宙技术研究员,现杭州半个宇宙科技有限公司技术研究员，深耕AI技术研发与企业级应用落地。前网易/阿里研发工程师、架构师。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),kOS：下一代自主智能系统,English,Apps & Agents,本次演讲围绕kOS Agentic System的演进历程，探讨下一代自主智能系统的发展方向与实现路径。,(N/A),Accept,[object Object],1755061463004,proposal-hangzhou-accepted,[object Object],(N/A)
86,王新盟,409903500@qq.com,字节跳动,扣子罗盘技术负责人,王新盟，十余年互联网研发及管理经验，现任字节跳动扣子罗盘技术负责人。从 0 到 1 主导落地了字节 AI 应用开发调优平台，助力字节内Flow、抖音、懂车帝、电商等业务孵化 AI 应用。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),扣子 ，用 Agent 重塑生产力,Chinese,Apps & Agents,Agent 正面临全面爆发的一年，本次演讲将围绕 Agent 全生命周期，探讨从开发、评测、观测、调优和企业级应用等几方面，如何更好的帮助 Agent 开发者快速将 Agent 从 idea 到 demo、从 demo 到生产。,(N/A),Accept,[object Object],(N/A),(N/A),[object Object],(N/A)
85,DANDJINOU Charbel,dachamos95@gmail.com,Exel industries | EXXACT robotics ,ai research & mlops engineer ,"charbel dandjinou is an ai research & mlops engineer at exxact robotics, leading generative ai and rag initiatives across the company. he also founded iroko ai to advance frugal, inclusive, open-source ai for emerging regions. his work spans enterprise AI deployment, computer vision , robotics, and multilingual models.",(N/A),(N/A), /in/charbel-d-9569ba199,(N/A),(N/A),(N/A),"Context engineering that sticks: drop the reranker, add memory, one architecture from rag search to robot action",English,Apps & Agents,"we show how a custom rag without rerankers hit strong internal mrr and powers our agents. then we turn the same context-engineering into robot memory: short-term buffers, episodic logs, and long-term stores that let robots act, remember, and stay safe.","why this talk
We built a sovereign AI stack with open-source LLMs running fully on-prem (no external API calls) so data stays private and compliant. In practice, classic full RAG pipelines with rerankers added compute and latency without consistently improving quality.

what’s new
During R&D we redesigned retrieval so the reranker was unnecessary—and results improved:
• Dynamic context-window chunking that adapts segment size to the question, entity density, and token budget.
• Hybrid recall (sparse + dense) with lightweight metadata filters.
• LLM-as-judge pre-generation filtering: a fast gating pass ranks candidate chunks for direct relevance and answerability, dropping irrelevant context before the model generates.
• Small deterministic rules (recency, source trust) instead of heavy cross-encoders.

results
On our internal evaluation set we observed MRR = 1.00 (100%) alongside lower p50/p95 latency and reduced token usage. The simpler pipeline also lowered operational complexity. We’ll share the evaluation protocol and dataset characteristics in the talk.

from context to memory
We turned the same principles into agent memory:
• Short-term buffer: rolling scratchpad and KV/cache control trimmed by salience and recency.
• Episodic memory: time-stamped action/outcome logs capturing “what actually happened.”
• Semantic graph memory: past conversations and notes are chunked, indexed, and linked (entities ↔ tasks ↔ tools ↔ locations).
• Two-step recall (human-like): quick salient recall first, then focused graph walks to recover fine-grained details on demand.
• Policies: TTL/decay, summarization to canonical notes, and safety constraints woven into prompts and tools.

from rag to robots
We adapted memory to an embodied loop—planner (LLM) ↔ memory manager ↔ VLA/controller (ROS 2)—behind a safety gate. The robot can recall multi-step procedures across sessions (episodic), reuse parameters and locations via the graph, and maintain transient context without drift (short-term). We observed higher task completion, fewer operator interventions, and stable latency thanks to adaptive summarization and pre-generation filtering.

evaluation & ops
Fully sovereign deployment; offline-first persistence on device with periodic edge sync. We’ll present retrieval dashboards (MRR/Hit@K, token usage), latency breakdowns (recall vs judge vs generation), and ablations (reranker on/off, memory on/off).

what attendees will learn
	1.	How to build lean, sovereign RAG that outperforms without a reranker using dynamic chunking and LLM-as-judge filtering.
	2.	A practical, graph-based memory blueprint (buffer + episodic + vector/graph + two-step recall) that transfers from search to action.
	3.	Concrete evaluation methods and guardrails to prevent memory drift and stale context.",Accept,[object Object],1755061447902,proposal-hangzhou-accepted,[object Object],(N/A)
84,朱德江,doujiang24@gmail.com,蚂蚁集团,Mooncake Core Member / Envoy Golang maintainer,朱德江，蚂蚁集团网络团队技术专家，十多年深耕网络领域，对语言编译器也有一些研究，Envoy Golang maintainer，也是 Mooncake 的一员。,(N/A),(N/A),(N/A),https://github.com/doujiang24,(N/A),(N/A),蚂蚁 AI 网关 - 大规模在线推理服务集群性能优化实战,Chinese,AI Models & Infra,"随着大模型应用加速落地，大模型推理服务的规模亦呈爆发式增长态势，推理集群也越过了万卡规模。如何有效提升大规模集群的资源利用率，并为业务提供高性能的推理服务，已成为当前亟待解决的关键性课题。
大模型推理请求与传统服务请求存在显著差异：单个推理请求计算开销巨大，不同推理请求计算开销差异悬殊，长短请求相差几十上百倍也很常见，同时，跨请求的缓存语义也存在巨大差异，导致传统的负载均衡策略已经不再适用，亟需一种针对大模型推理的智能路由方案，具备 Load-aware与 KVCache-aware 能力，以实现高效的流量调度。
在蚂蚁内部 MaaS 服务中，AI 网关作为 AIDC 推理服务的流量入口，为大规模推理服务提供请求调度能力。通过 AI 网关的全局路由与引擎内 scheduler 配合，让整个大集群像一台“超级 GPU”般高效运转。
我将深入分享蚂蚁 AI 网关在大规模集群落地过程中的实战经验，从依赖引擎 metrics 的简单队列数均衡，到弱依赖引擎的多因子综合决策算法，再到基于单机性能建模的预测算法，完整的演进历程。此外，还将介绍如何实现高效的推理引擎负载感知，如何与 Mooncake Store 实现 KVCache-aware 的方案，以及未来即将开源的规划。","大纲：
一。大规模推理集群的挑战
1. 推理请求的计算特征
2. 在线服务混合流量特征
二。蚂蚁 AI 网关的演进历程
1. V1 请求队列数均衡：依赖引擎 metrics
2. V2 多因子综合决策算法：负载 & Prefix-cache 综合决策
3. V3 基于单机性能建模的预测算法：化繁为简 & QoS 路由
三。开源 & 未来规划
1. 即将开源
2. 未来规划",Accept,[object Object],(N/A),(N/A),[object Object],(N/A)
83,王天策,tiancew@qq.com,华为,软件架构师,2015年获美国普林斯顿大学博士学位，曾在美国高盛银行和医疗人工智能企业Siuvo Inc. 任职。曾作为联合创始人，在珠海普林芯驰担任算法研发主管，研究端侧语音识别、降噪等算法及RISC-V芯片上的算法部署。现任华为技术专家、软件架构师，负责基于MindSpore的大语言模型推理开发和SGLang等开源生态的对接。,(N/A),(N/A),(N/A),https://github.com/wangtiance,(N/A),(N/A),SGLang接入MindSpore框架方案,Chinese,AI Models & Infra,目前，SGLang唯一支持的AI框架是PyTorch，并通过torch_npu插件得以在昇腾NPU上运行。我们设计了PyTorch和MindSpore双框架协同运行的方案，充分考虑了跨框架的资源复用，并尽量简化接口，发挥MindSpore在昇腾NPU上的性能优势。开发者能够轻松地将MindSpore模型接入SGLang，而用户的使用流程无任何变化。MindSpore的接入方案也为后续其他框架的接入提供了参考。,"1、MindSpore在昇腾硬件平台的优势
2、通过DLPack实现跨框架的Tensor零拷贝互转
3、跨框架的通信组复用
4、MindSpore的模型接口
5、结果和性能展示
6、路线图和社区协作的方式",Accept,[object Object],1756083458290,proposal-hangzhou-accepted,[object Object],null
82,Huixin Xue/Jixun Yao,m15158088351@vip.163.com,Shanghai Conservatory of Music/Northwestern Polytechnical University,Ph.D. Candidate at Shanghai Conservatory of Music/Ph.D. Candidate at Northwestern Polytechnical University,"Huixin Xue is a Chinese composer, music producer and Music AI researcher. She is a Ph.D. candidate in Music AI at Shanghai Conservatory of Music under the supervision of Professor Liu Hao, a visiting scholar at the Hamburg University of Music and Theatre, and a member of SHCM's Key Laboratory of Artificial Intelligence Music Therapy. She graduated from the Music Engineering Department of Shanghai Conservatory of Music both for her bachelor's and master's degrees both as the top of her major. Xue’s pieces won numerous awards, including The top Prize of the 2024 OPUS ARTIS Paris International Composition Competition, the Honorable Mention of the 2024 Sound Chain International Electronic Music Composition Competition (the only Chinese winner among the 6 winners worldwide), the second place of the 2024 Hangzhou International Electronic Music Composition Competition. As a Music AI researcher, she strives to explore the possibility of AI technology enabling music creation, including AI music generation model training and evaluation and AI timbre synthesis. 

Jixun Yao is a Ph.D. candidate in Computer Science at Northwestern Polytechnical University, under the supervision of Professor Lei Xie. His research centers on speech generation and privacy, with a focus on expressive and zero-shot speech synthesis and music generation. His academic work has been recognized at major conferences including ICLR, AAAI, ACL, and ICASSP, and he has achieved top rankings in the VoicePrivacy 2022 and 2024 challenges. His work aims to bridge academic innovation with real-world impact across multilingual and emotionally rich speech applications.",(N/A),(N/A),(N/A),https://github.com/ASLP-lab/SongEval,(N/A),(N/A),SongEval: A Benchmark Dataset for Song Aesthetics  Evaluation,English,AI Next,"Aesthetics serve as an implicit and important criterion in song generation tasksthat reflect human perception beyond objective metrics. However, evaluatingthe aesthetics of generated songs remains a fundamental challenge, as the appreciation of music is highly subjective. Existing evaluation metrics, such asembedding-based distances, are limited in reflecting the subjective and perceptual aspects that define musical appeal. To address this issue, we introduceSongEval, the first open-source, large-scale benchmark dataset for evaluatingSongEval includes over 2,399 songs inthe aesthetics of full-length songs.full length, summing up to more than 140 hours, with aesthetic ratings from16 professional annotators with musical backgrounds. Each song is evaluatedacross five key dimensions: overall coherence, memorability, naturalness of vocabreathing and phrasing, clarity of song structure, and overall musicality. Thedataset covers both English and Chinese songs, spanning nine mainstream gen-res. Moreover, to assess the effectiveness of song aesthetic evaluation, we con-duct experiments using SongEval to predict aesthetic scores and demonstratebetter performance than existing objective evaluation metrics in predicting human.perceived musical quality, We provide the dataset and toolkit for song aestheticevaluation athttps://huggingface.co/datasets/ASLP-lab/SongEval and https://github.com/ASLP-lab/SongEval.","Clarification:
Our paper “SongEval: A Benchmark Dataset for Song Aesthetics Evaluation” will be delivered as a joint presentation by two speakers:
Huixin Xue, a PhD candidate in Music AI at the Shanghai Conservatory of Music (expert in music theory and aesthetics), and
Jixun Yao, a PhD researcher in Computer Science and Technology at Northwestern Polytechnical University (expert in AI and evaluation methodologies).
We will divide the presentation to leverage our respective expertise—Huixin Xue will cover the musical aspects (dataset design, aesthetic criteria), while Jixun Yao will focus on the AI framework and benchmarking. This approach ensures both depth and clarity, offering attendees a comprehensive yet accessible understanding of our work.

Structure:
1 Introduction
Song generation lies at the intersection of structured pattern learning and human aesthetics. With 
the advancement of deep learning-based generative models, current approaches can now compose 
melodies, harmonies, and full musical pieces that closely resemble human-created songs [1, 2, 3, 4, 5]. 
This progress has enabled a wide range of applications, including personalized music and song 
generation for games, film scoring, music education tools, and therapeutic settings. As a universal 
medium of expression and communication, song generation increasingly aims to produce songs that 
are both aesthetically pleasing and emotionally resonant. However, evaluating the aesthetic quality of 
generated songs remains an open and underexplored challenge, primarily due to the subjective and 
multi-dimensional nature of musical aesthetics. 
A typical song consists of two main components: the singing voice and the instrumental accom
paniment. As shown in Figure 1, these components work together to convey the musical message,
where vocals deliver melody, lyrics, and emotional expression and the accompaniment provides 
rhythmic and stylistic support. Most previous studies only focus on single-component generation, 
such as singing voice synthesis [6, 7, 8, 9, 10] or text-to-music generation [11, 12, 13, 14, 15]. As a 
result, there remains a gap in generating full-length songs that seamlessly integrate both vocals and 
accompaniment in a coherent and aesthetically pleasing way. Recently, some studies [16, 17, 18, 19] 
have scaled up model parameters and training corpora to directly generate full-length songs that 
combine vocals and accompaniment with greater coherence and aesthetic quality. These approaches 
have attracted significant interest from both industry and academia.
To facilitate aesthetic evaluation in song generation, we introduce SongEval, a large-scale, open
source dataset containing over 140 hours of professionally annotated songs with human aesthetic 
ratings. The annotations are provided by 16 expert raters with formal musical education, ensuring high 
reliability and perceptual consistency rooted in professional musical understanding. Each song in the 
dataset is evaluated across five complementary aesthetic dimensions: overall coherence, memorability, 
naturalness of vocal breathing and phrasing, clarity of song structure, and overall musicality. These 
dimensions are carefully selected to reflect the preferences and evaluative standards of professionally 
trained musicians, aligning the metric with academic and industry-level expectations. It is important 
to note that our definition of aesthetic quality is not intended to represent personalized taste. Rather, it 
approximates the consensus of expert musicians, providing a reliable, authoritative evaluation dataset 
for assessing song generative models. While no single metric can fully capture the complexity of 
musical aesthetics due to its inherently subjective nature, our goal is not to define a perfect metric but 
to establish one that is more explainable and professionally aligned than previous alternatives. By 
providing high-quality, multi-dimensional aesthetic annotations at scale, SongEval establishes a new 
paradigm for benchmarking generative models based on professionally informed musical evaluation, 
offering a valuable resource for improving and comparing song generation systems.

2 Related Work
3 SongEval Dataset
3.1 Data Collection
3.2 Aesthetic Annotation
3.3 Dataset Statistics
4 Experimental Setup 
4.1 Datasets
4.2 Models
4.3 Evaluation Metrics
5 Experimental Results 
5.1 Aesthetic Evaluation
5.2 Comparison with Other Objective Metrics

6 Conclusion
In this study, we present SongEval, the first benchmark dataset dedicated to musical aesthetics 
evaluation. The dataset contains 2,399 full-length songs totaling over 140 hours, annotated by 
16 professional annotators across five carefully defined aesthetic dimensions: overall coherence, 
memorability, vocal phrasing naturalness, structural clarity, and musicality. The songs span both 
English and Chinese languages and cover nine common musical genres, ensuring linguistic and 
stylistic diversity. All annotations are rated on a 1–5 scale and are based on rigorous guidelines 
to ensure consistency and reliability. Experimental results demonstrate that models trained on 
the SongEval outperform existing objective audio metrics in predicting human-perceived musical 
aesthetics. We expect SongEval to serve as a strong foundation for future work in controllable music 
generation, quality assessment, and style transfer.

7 Limitations and Future Work 
While the SongEval dataset establishes a foundation for song aesthetic evaluation, some limitations 
warrant further exploration. One key limitation lies in the potential correlation and overlap among the 
five defined aesthetic dimensions. For instance, dimensions such as overall coherence and structural 
clarity, or musicality and memorability, may exhibit high interdependence in practice. This is partially 
due to the holistic nature of song perception, where multiple musical aspects often influence a 
listener’s judgment simultaneously. Despite our efforts to provide clear annotation guidelines and 
expert training to distinguish these dimensions, subjective perception inherently involves cognitive 
and emotional entanglement, making absolute separation between factors challenging. Nevertheless, 
we argue that this limitation reflects a psychologically grounded view of how listeners experience 
song and does not undermine the value of the dataset. 
For future work, our primary goal is to develop more robust and fine-grained tools for automatic 
aesthetic evaluation based on the proposed SongEval dataset. Design advanced predictive models that 
better capture subjective aesthetic signals and generalize across musical styles, genres, and languages.

References

A Supplementary Material 
In the supplemental material: 
• A.1 We provide the characteristic details of the song generated by different systems. 
• A.2. We describe the filter process of generated songs. 
• A.3. We provide details of the annotation process.",Accept,[object Object],(N/A),(N/A),[object Object],(N/A)
81,Krzysztof Ociepa,karol@szkolapromptowania.com,Bielik.AI,Core Team Member,"Co-founder and chief architect at Azurro S.C., where he designs and builds solutions in Machine Learning and Big Data. He conducts R&D projects focused on creating solutions based on LLMs and develops and trains language models based on his proprietary ALLaMo framework. He is a co-creator of the Polish large language model Bielik.",(N/A),(N/A),https://www.linkedin.com/in/krzysztof-ociepa/,(N/A),https://azurro.pl/,(N/A),The Engine and the Forge: Building a Custom PyTorch Framework on a Supercomputer,English,AI Models & Infra,"This is a deep-dive for the builders, architects, and infrastructure experts. We will take the audience on a technical journey into the heart of the Bielik.AI project. We start with the ""engine"": our custom-built training framework, ""Allamo."" We’ll explain why we chose to build our own solution with pure PyTorch for maximum control, sharing the engineering challenges, architectural decisions, and performance optimizations that pushed the framework to its limits.","Speakers: Krzysztof Ociepa & Szymon Mazurek

Description: This is a deep-dive for the builders, architects, and infrastructure experts. We will take the audience on a technical journey into the heart of the Bielik.AI project. We start with the ""engine"": our custom-built training framework, ""Allamo."" We’ll explain why we chose to build our own solution with pure PyTorch for maximum control, sharing the engineering challenges, architectural decisions, and performance optimizations that pushed the framework to its limits.

Next, we move to the ""forge"": one of Europe’s most powerful supercomputers, Helios. We will provide an inside look at how we tamed this beast, harnessing the incredible power of NVIDIA GH200 GPUs to train our model at a massive scale. This is a story of raw power, engineering precision, and the complex logistics of large-scale model training—a perfect case study on bridging cutting-edge software with world-class hardware.

Krzysztof Ociepa:
Co-founder and chief architect at Azurro S.C., where he designs and builds solutions in Machine Learning and Big Data. He conducts R&D projects focused on creating solutions based on LLMs and develops and trains language models based on his proprietary ALLaMo framework. He is a co-creator of the Polish large language model Bielik.

Szymon Mazurek:
Deep Learning Engineer at ACC Cyfronet AGH, experienced in developing AI-based solutions, distributed AI performance optimization, and backend engineering. He is actively involved in research, pursuing a PhD in spiking neural networks and neuromorphic computing. His work was critical in adapting and scaling the training process on the Helios supercomputer.
",Accept,[object Object],(N/A),(N/A),[object Object],(N/A)
80,Karol Stryja,kstryja@gmail.com,99 Faces of AI Podcast / Bielik.AI,Founder,"Known as the ""godfather of Polish podcasting,"" Karol Stryja has always been ahead of the technology wave. His global contributions to promoting voice interfaces and Smart Speakers earned him the ""Leader in Voice"" award from voicebot.ai. Today, he is an influential AI Ecosystem Architect and a frequent conference speaker on the future of artificial intelligence. Through his top-rated podcast, ""99 Faces of AI,"" he demystifies AI by interviewing leading experts and translates complex technology into concrete strategies and actions for brands like Lenovo, Samsung, Meta, IBM. More info: www.99twarzyAI.pl",(N/A),(N/A),(N/A),(N/A),www.99twarzyAI.pl,(N/A),From a Community Spark to National Impact: The Story and Power of Bielik.AI,English,AI Next,"This presentation tells the complete story of Bielik.AI, from its grassroots origins to its real-world impact. We begin with the ""why"": how a passionate open-source community identified a critical need for a sovereign Polish language model and built a movement from scratch to democratize AI. This is a story about people, vision, and mobilizing a nation around a shared goal.","This joint presentation tells the complete story of Bielik.AI, from its grassroots origins to its real-world impact. We begin with the ""why"": how a passionate open-source community identified a critical need for a sovereign Polish language model and built a movement from scratch to democratize AI. This is a story about people, vision, and mobilizing a nation around a shared goal.

In the second part, we present the ""proof"". We will showcase hard data, honest benchmark results comparing Bielik to global competitors, and demonstrate its unique understanding of Polish language and culture. Through live demos and real-world case studies from business and the public sector, we will prove the tangible value of open-source, sovereign AI. Aligned with the spirit of the ""Open for SDG"" event, we will also discuss how our open datasets for the Polish language could be a blueprint for other nations and contribute to global initiatives like the UN AI platform.

Presentation will be held by the duo:

Karol Stryja:
Known as the ""godfather of Polish podcasting,"" Karol Stryja has always been ahead of the technology wave. His global contributions to promoting voice interfaces and Smart Speakers earned him the ""Leader in Voice"" award from voicebot.ai. Today, he is an influential AI Ecosystem Architect and a frequent conference speaker on the future of artificial intelligence. Through his top-rated podcast, ""99 Faces of AI,"" he demystifies AI by interviewing leading experts and translates complex technology into concrete strategies and actions for brands like Lenovo, Samsung, Meta, IBM. More info: www.99twarzyAI.pl


Katarzyna Starosławska:
A seasoned expert in data and artificial intelligence with over two decades of experience. As a Board Advisor at SpeakLeash Foundation and the Bielik.ai model, she specializes in transforming data into actionable insights and long-term value. Katarzyna advises leadership teams, government bodies, and EU institutions on building digital capabilities and applying AI ethically and effectively. She actively contributes to shaping the European and national AI landscapes as an Expert in the AI Working Groups (GRAI) under the Polish Ministry of Digital Affairs and at the European Commission.

",Accept,[object Object],(N/A),(N/A),[object Object],(N/A)
79,Martin Robinson,mrobinson@igalia.com,Igalia,Software Engineer,"Martin is a software engineer at Igalia. He has been working on web browsers for over a decade. Recently, he's been active in the Servo project helping to implement modern CSS layout and rendering. ",(N/A),(N/A),(N/A),mrobinson,(N/A),(N/A),A Dive Into the Servo Layout System,English,Future Web Workshop,"Servo is a new web rendering engine written in Rust. This workshop will be an in-depth look at Servo's one-of-a-kind layout system, which uses Rust's fearless concurrency to add parallelism to layout.","Servo, one of the most active Linux Foundation Europe projects, is a modern web rendering engine written in Rust. Built for safety, modularity, and performance, Servo brings memory safety and concurrency to the forefront of browser engine innovation. In this workshop we’ll explore Servo’s layout engine to understand how it works. We’ll drive deep into the technical details, explaining the architecture of a modern CSS layout engine, look at how CSS features are implemented, and describe the different phases and data structures involved.

One recent development on the layout engine is the addition of the incremental layout feature, which avoids unnecessary work when only some parts of a page have changed. This is a fundamental feature for a performant layout engine. During the workshop we’ll explain the different bits related to the implementation of this feature. In addition, Servo is the only layout engine using parallelism to render web content, so we’ll look into how that works and the benefits it can bring to complex websites.

Finally, the workshop will include a practical session showing how to implement a CSS feature in Servo.

People participating in the workshop will gain a much better understanding of how web browsers lay out page contents, how the different pieces fit together, and the different optimizations that Servo employs to speed up this process.",Accept,[object Object],(N/A),(N/A),[object Object],(N/A)
78,Martino Russi,martino@huggingface.co,Hugging Face,Embodied AI Engineer,"I'm a robotics engineer and AI researcher working at the intersection of embodied intelligence and open-source hardware. I'm passionate about making cutting-edge robotics accessible, combining mechanical design, embedded systems, and machine learning to push the boundaries of human-machine interaction.",(N/A),(N/A),https://www.linkedin.com/in/martino-russi-a822081bb/,https://github.com/nepyope,(N/A),https://x.com/NepYope,HopeJr: A $500 Open-Source Humanoid Arm for Everyone,English,Embodied AI,"An overview of a $500 open-source humanoid arm and glove system enabling real-time learning and teleoperation. We’ll explore how AI, robotics, and embedded systems merge to empower individual creators and reshape human–machine interfaces.","This talk will introduce a novel low-cost open-source humanoid robot arm designed for dexterous manipulation and real-time teleoperation using a wearable glove. I’ll cover the system’s mechanical design, embedded architecture and a control pipeline that enables real-time learning from human input. The goal is to democratize robotics and make embodiment technologies accessible without requiring large teams or industrial labs. I’ll also discuss challenges in open-sourcing hardware, developing intuitive teleoperation systems, and integrating machine learning into the stack. ",Accept,[object Object],(N/A),(N/A),[object Object],(N/A)
77,Manuel Rego,rego@igalia.com,Igalia,Software engineer,"Manuel Rego is a free software developer working on the Web Platform at Igalia. Over the past few years, he has been working on the implementation of different web platform features in Chromium/Blink and WebKit for which he is an owner and reviewer, respectively. Manuel is also a member of the CSS Working Group since 2017, Blink API owner since 2020 to 2024 and Servo Technical Steering Committee chair since 2023.
",@rego.bsky.social‬,https://mastodon.social/@regocas,https://www.linkedin.com/in/manuelrego/,https://github.com/mrego/,https://blogs.igalia.com/mrego/,(N/A),Servo: A new web engine written in Rust,English,Agentic Web,"Servo is a modern open source web rendering engine written in Rust. Built for safety, modularity, and performance, Servo brings memory safety and concurrency to the forefront of browser engine innovation.

Servo development has been reactivated in 2023 since Igalia took over the maintenance of the project, the project community has been constantly growing since then.

In this talk we’ll talk about the last few years working on the project, the main features implemented and an the overall evolution of Servo. We’ll highlight the new platform additions like Android and OpenHarmony, together with the multiple optimizations that have been developed to make Servo a viable alternative to other web engines.

Last we’ll review the plans for the project and the next developments that will happen to make Servo easier to use for applications that want to embedded it.
","The goal of this talk is to give an overview about the Servo web rendering engine and its evolution on the last years since Igalia took over the maintenance of the project back in 2023. The project and community have grown a lot during this period, and there have been many developments, like new features support, new mobile platforms like Android and OpenHarmony, and lots of optimization work.",Accept,[object Object],(N/A),(N/A),[object Object],(N/A)
76,赵东,z-zhaodong@sharingmail.cn,360,360 纳米AI搜索鸿蒙端技术组长,"360 纳米AI搜索鸿蒙端技术组长
",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),仓颉在鸿蒙应用：纳米AI搜索的应用开发实践,Chinese,Cangjie Workshop,"仓颉在鸿蒙应用：纳米AI搜索的应用开发实践
",(N/A),Accept,[object Object],(N/A),(N/A),[object Object],(N/A)
75,Weiyu Xie,ervinxie@foxmail.com,Tsinghua University,PH.D. Candidate,"Weiyu Xie is a fifth-year Ph.D. student in the Institute for High Performance Computing, Department of Computer Science and Technology, Tsinghua University. His research interests include computer systems, large language model (LLM) inference, graph computing, and databases.",(N/A),(N/A),(N/A),https://github.com/ErvinXie,(N/A),(N/A),KTransformers: 单卡大模型的极致推理,Chinese,Edge AI Workshop,KTransformers 是 CPU GPU 异构的推理框架，能够使用一张卡进行 DeepSeekR1 KimiK2 等主流大模型的推理。它通过把 MoE 层放到 CPU，MLA 放到 GPU 实现了不同计算的分离，充分利用了不同硬件的资源。此外 ktransformers 还采用了最新研发的 Expert Defer 技术，能够充分利用CPU GPU 异构架构的优势，较大提升性能。ktransformers 还在不同的硬件平台上做了广泛的尝试，均取得了不错的成果。,(N/A),Accept,[object Object],(N/A),(N/A),[object Object],(N/A)
74,Markus Tavenrath,matavenrath@nvidia.com,NVIDIA,Principal Engineer Developer Technology,"Markus Tavenrath studied computer science with a focus on computer graphics at RWTH Aachen University. This academic background provided a solid foundation for his career in the technology industry.

In 2008, Markus joined NVIDIA, where he began working on real-time ray tracing on GPUs. Over the years, he has contributed to performance optimization for ray tracing, scene graphs, OpenGL, WebGL, Vulkan, and AI. His work has played a role in advancing these technologies.

Markus is also a co-founder of the Vulkan-Hpp project, which has been beneficial to the Vulkan community. His efforts have helped improve the use and implementation of Vulkan.

Recently, Markus was elected as the Chair of the ML Council at Khronos. In this role, he helps coordinate and support AI and machine learning initiatives within the Khronos group. His election to this position reflects his expertise and leadership qualities.

Markus Tavenrath is a dedicated professional whose contributions have positively impacted the technological landscape at NVIDIA and beyond.",(N/A),(N/A),https://www.linkedin.com/in/markus-tavenrath/,(N/A),(N/A),(N/A),Khronos's Role in Standardizing AI Acceleration: Findings from the AI Ecosystem Research Project,English,AI Models & Infra,"This presentation will reveal the key findings of the Khronos Group's comprehensive AI Ecosystem Research Project, a major initiative undertaken to gain a data-driven understanding of the rapidly evolving AI landscape. The research methodology, designed to capture a holistic view of the market, involved extensive interviews and surveys with a wide range of stakeholders, including AI model experts, product builders, hardware makers, and developers of AI compilers and tools, as well as the broader community.

The core of our findings confirms the presence of significant market fragmentation, which presents a key challenge for developers seeking to build performant and interoperable AI solutions. This research provides a unique, multi-faceted perspective on the needs and pain points facing the AI community. The second half of the talk will focus on the strategic implications of this research, detailing how these findings are directly informing Khronos's future direction. We will outline new initiatives in a general sense, discussing how Khronos is leveraging this market data to shape a more open and cohesive future for the AI ecosystem.",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
73,吴其力,fochive00@gmail.com,ImitationGameLabs,Founder,年轻，激情，Geek。从前的 Web3 Dreamer，现在的 Web3 Builder，未来的 Web3 Leader。2025年七月份开始全职投入在 web3 行业开源项目中，致力于实现一个由激励驱动的 web3 代码托管平台，为托管的项目提供抗审查和持久生命力，推动 web3 的进程。喜欢思考计算机科学、数学、哲学、经济学，对加密、AI、游戏引擎等领域都很感兴趣，摄影、骑行爱好者。,(N/A),(N/A),(N/A),https://github.com/simplexforce,(N/A),http://x.com/SimplexForce,激励在 web3 项目中的角色 - 根治开源项目的可持续性问题的关键,Chinese,Agentic Web,大多 web3 项目都会用这样一堆词堆砌： 去中心，抗审查，数据主权，隐私，透明性，groundbreaking 等等。却很少说激励是怎么设计的。我在这里直言，这是很多 web3 项目的病根之一。我将分享激励是什么，为何是 Web3 项目的命脉，什么样的激励才算优秀，示例说明如何通过激励的设计缓解开源项目的可持续性难题，以及谈谈 AI 在其中扮演的关键角色。,"## 简单的故事
前段时间，有位朋友找到我，询问我一起做项目的意愿。他告诉我他在瑞士苏黎世参加了一个线下会议，并且跟很多人聊到 web3 的 github 项目，跟他聊的人都很期待这样一个项目面世。 他找到了我，因为我在几个月前在一些社交媒体上发表过相关的内容。我跟他聊了一些，聊到他的想法、计划。他告诉我他没有想过 tokenomic，只是想做一个抗审查的 git server。

后面又邀请我一起参加一个 web3 world computer 的 hackaphon。然后其中项目评分的其中一条是 market/mobetization strategy 的设计，我问了他的看法，我说我有过很多思考但还没有正式整理。他这时候跟我说，他猜这一点并不是很重要，因为过度关注这个会影响一些创新的出现。他觉得不管怎么样，他做的是一个核心组件，迟早要做。这是 web3 行业的很多 builder 的共性，忽视激励的重要性。我五分理解三分震撼两分担忧。我担忧的是，如果没有激励设计，一个项目可能难以吸引持续的贡献者，最终沦为无人问津的空壳。

你认为一个没有激励设计的项目能走多远？ 
## 激励关键性的印证

### 比特币白皮书中的激励
bitcoin whitepaper 中，专门单独一个章节讲述 激励。
挖矿的奖励，早期加入收益，都是激励。激励使节点持续支持bitcoin网络，激励使节点遵守规则，因为 bitcoin 的底层通过对激励的设计，遵守规则收益更高。工作量证明作为共识算法，它的关键性通常不会有人怀疑，但是从前面提到的可以看到，这个共识的安全性同时也依赖于激励。

这种激励设计不仅支撑了比特币的成功，也为 Web3 项目提供了值得借鉴的模板。
### 区块链经济设计原则中的激励
“数字经济之父” Don Tapscott 在《区块链革命》这本书中提到的区块链经济七大设计原则：
网络诚信化，分布式权力，把价值作为激励，安全性，隐私，权利保护，包容性。
其它几个原则，大多项目都会注意到，但把价值作为激励，却大多没有做好。所以很多都发展得不好。

实际上这本书在 16 年出版的时候，已经描绘了各行各业经过区块链革命之后的美丽图景，每一个都直指问题的关键、解决的关键。现在过了将近十年，加密行业又发展了那么多年，web3 依旧没有走向大众，项目依然以泡沫为主。

同时，《区块链革命》这本书提到，他们将区块链定义为价值互联网，与现在的信息互联网区别。价值跟踪是透明性，价值的流动是生态活力，价值的分散体现去中心，而价值的合理分配体现正义和公平。其中价值的量化正是 token，而激励则基于价值。

Web3 若想成为真正的价值互联网，就必须通过激励实现价值的合理分配，而这正是许多项目欠缺的。

### 齐国政治改良中的激励
邹忌讽齐王纳谏中
齐王下令：群臣吏民能面刺寡人之过者，受上赏；上书谏寡人者，受中赏；能谤讥于市朝，闻寡人之耳者，受下赏。
令初下，群臣进谏，门庭若市；数月之后，时时而间进；期年之后，虽欲言，无可进者。燕、赵、韩、魏闻之，皆朝于齐。
对谏言的激励，让齐国能够战胜于朝廷。

## 大自然中的激励
有一部非常值得看的纪录片 《绿色星球》。
在森林中，植物结出果实，动物受到果实的营养和美味吸引，同时传播种子。
物种多样是它的去中心的特点，大自然的各种协同和相互依赖，各种价值激励，驱动着生态系统的演进，维持着其中的动态平衡。
我们人的创造，实际上是一种模仿游戏 The Imitation Game （此处致敬一下图灵）。

大自然的激励机制启发我们，Web3 项目也需要类似的生态平衡来驱动协作。
## Vitalik Buterin 对激励的深刻理解
Vitalik Buterin 在 2014 年1月10日 Bitcoin Magazine  中发布了 Markets, Institutions and Currencies – A New Method of Social Incentivization  这一篇文章( https://bitcoinmagazine.com/markets/markets-institutions-currencies-new-method-social-incentivization-1389412608 )。
标题中聚焦了 ”一种新的社会激励方法“。这篇文章收录在了 Vitalik Buterin  的书 《Proof Of Stake> 中，作为第一篇。

在2020年1月3日，Vitalik 在 nakamoto.com 中又发布了一篇 Credible Neutrality As A Guiding Principle。提到什么是机制？机制就是算法加激励。激励的设计是机制的设计。

Proof Of Stake 书中中详细阐述了 PoS 机制如何通过经济激励保障区块链网络的安全与去中心化。奖励与惩罚并存，分散权力，吸引更多人参与决策，关注激励的长期平衡。

## 失控
Kevin Kelly 在 Out of Control 中探讨了复杂系统中的自组织和去中心化，强调激励如何驱动系统的稳定与创新，激励不仅是个体行为的驱动力，也是去中心化系统整体优化的关键。

激励是复杂系统自组织的关键，Web3 项目若忽视这一点，就难以实现真正的去中心化创新。

## 什么样的激励是一个好的激励
到底什么样的激励是一个好的激励？ 好的激励，体现出来的是社区的 “正义“。
激励去做好事，是积极的风气。做好事得到激励，是理所应当的。

春秋时期，鲁国有一道法律，凡是在他国见到沦为奴隶的鲁国人，可以先垫钱赎回，回国报销。这是一项激励救助同胞的善政。子贡赎回鲁国人，却拒绝了补偿，孔子严厉批评了他。

破坏了规则与公平，打击了大多数人的积极性，损害了社会正义。

如果一件事情对社区有价值，但消耗个体的时间精力，却没有激励，这样一个社区是正义的吗？白吃白喝的、甚至黑客攻击，获得的收益远比做有益的事情要多，凭什么社区会能够持续更好发展？

好的激励应公平、透明、可持续，既奖励善行，又维护社区的长期正义。
## 激励到底是什么，意味着什么

如果将一个社区、一个网络，整个系统看作是一个拥有群体智能的个体。群体智能是指个体通过协作展现出超越个体的智慧，而激励机制正是塑造这种智慧的关键，决定了一个社区的行为风格和价值取向。激励在这里或许是代表着这个体的个性 Personality。激励驱动行为，即个体做事的风格，正义的理解，善恶的标尺，影响着对社区或网络中发生的所有活动的看法。

## 示例：为什么我想要做一个 web3 github，以及怎么根治开源项目的可持续问题。
从问题出发，现在的开源项目经常会面临可持续不足、缺少生命力的问题。
开源项目的仓库，通常会有一个 owner、maintainer，这其实可以理解为一种中心化，即使 owner 是善良的，但是怎么保证不会单点故障？ 我这个月搞一个开源项目，下个月出车祸人走了，谁维护下去？ 我对这个项目兴趣淡了、被其它项目吸引了兴趣，谁又继续下去？所以很多项目很容易就 ""死"" 去。

我曾有过很多开源项目，我觉得 idea 都挺好，因为各种原因，最后的 ”死“ 了。

所以这一个 web3 github 是我给出的答案。激励，Token-Driven。
1.  应该激励别人提 issue，无论是 roadmap 讨论、bug 反馈、提需求，都是一个对项目有益的行为，项目方不应该白嫖，而且这样被动等待反馈也没有积极性也没有效率。需要像齐王下令激励进谏一样。
2.  处理 bug 会获得激励。我举个例子，很多没人维护的项目，却可能会有很多项目依赖它，然后issue 遍地 open 没有人解决。这里应该要有一个类似奖池累积的机制。但是又要小心谨慎，因为如果这个累积机制促成了开发者刻意放任等待累积，这里就会出现一个“恶“的激励。
3. Idea 提出，白皮书编写，商业计划补充，开发路线制定，代码 review, 为项目宣传，融资，等等，甚至作为用户的使用行为，都看作是一种对项目的贡献，都应该受到激励。
4. 由于 Token-Driven，实现更高的自动化程度。价值以 token 形式显式流动体现透明性。
5. 自举：这个 web3 github 的第一个里程碑将会是这个项目托管在它本身这个平台。同时这样让项目方本身又作为这个项目的用户，还能促进对用户体验的关注。
6. 托管在这个 web3 github 上的项目，将会获得这个 web3 github 的 token，根据项目活跃度、影响力进行分配。同时促进去中心程度。同时平台又分得一部分项目的 token，类似于风投，也是一部分收益来源。

## AI 在其中会扮演什么角色
激励数值的评定是其中最困难的问题之一。
AI 可以从中充当一个更加客观无情的调解者。当然也需要遵循 Human in the loop 的原则，当人还是有异议最终还要能够提出复审，这里面可能又会上升到更大范围的 DAO 决策。

可能的方向：AI与人类开发者平等地作为社区的一员，组成团队，形成跨人与AI的复杂协作网络。",Reject,[object Object],(N/A),(N/A),"[object Object],[object Object]",(N/A)
72,Yizhong Cao 曹逸中,caoyizhong.cyz@alibaba-inc.com,Alibaba,Engineer,Qwen - Inference Team,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Qwen团队在大模型推理中算法-系统联合优化实践,Chinese,SGLang Workshop,"1. KV Cache Reuse 实践
2.长序列推理优化实践
3.SGLang离线推理优化实践",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
71,yicuan yue,miaojun955@qq.com,capital normal university,artist,"I graduated with a bachelor's and master's degree from the Central Academy of Fine Arts, and a doctoral degree from the School of Fine Arts, Capital Normal University. I am an artist",(N/A),(N/A),(N/A),(N/A),https://www.xiaohongshu.com/user/profile/5e2c419300000000010055bf?xsec_token=YBqLl2Ej_No_5lwWIgZpFYRlRkFpDiPb1m1fXHLuwYr1I%3D&xsec_source=app_share&xhsshare=CopyLink&appuid=5e2c419300000000010055bf&apptime=1754270391&share_id=a61e9597ab124f738215f8638469922d&share_channel=copy_link,(N/A), How to integrate artificial intelligence technology into the future art field,Chinese,AI Vision Forum,"By listing case studies of artificial intelligence technology in the field of art, analyze the possibility of future development of artificial intelligence art and the responsibilities of artists.",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
70,tao li,litao@kaihong.com,"Shenzhen Kaihong Digital Industry Development Co., Ltd.",Software Engineer,"I'm a software engineer at Shenkaihong. Currently, I serve as the main developer for the OpenHarmony open-source robotics system project.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Development Practices with Dora on OpenHarmony,Chinese,Dora Workshop,"This session shares common challenges and practical recommendations for Dora development on OpenHarmony. Key topics include:
* Obtaining OpenHarmony system images
* Utilizing OpenHarmony development boards
* Working with OpenHarmony build tools
* Migrating Dora-based robotics applications to OpenHarmony",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
69,Zhongjin,luzhongjin365@gmail.com,Dora-rs,Developer(Intern),Student@SEU,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Dataflow-Oriented Robotic Architecture,Chinese,Dora Workshop,Dataflow-Oriented Robotic Architecture usage on humanoid ,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
68,Jinwei Gu,gujinwei@gmail.com,NVIDIA,Principal Research Scientist and Tech Lead,"Dr. Jinwei Gu is currently a Principal Research Scientist at NVIDIA and an Adjunct Associate Professor at the Chinese University of Hong Kong, working on generative AI, world models, and the general fields of computer vision, computer graphics, and machine learning.  He received his Ph.D. in Computer Science from Columbia University in 2010, and B.S. and M.S. from Tsinghua University in 2002 and 2005, respectively. At NVIDIA, Dr. Gu is one of tech leads in cosmos model development – a family of multimodality world foundation models, with a focus on enabling real-world applications in robotics, autonomous driving, and generative AI. Prior to joining NVIDIA, he worked at SenseBrain as a R&D Executive Director, focusing on mobile computational photography with novel image sensors and imaging systems. He has published extensively in top-tier conferences and journals, and serves as an Associate Editor for IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) and IEEE Transactions on Computational Imaging (TCI) (2018-2023), an Area Chair for CVPR, NeurIPS, ICCV, ICCP, and ECCV, and organizing chairs for several workshops (MIPI, RichMediaGAI).  He is an IEEE senior member since 2018. His research work has been successfully transferred to many products such as NVIDIA-Cosmos, NVIDIA-CoPilot SDK, NVIDIA-DriveIX SDK, as well as Super Resolution, Super Night, Portrait Restoration, RGBW solution which are widely used in many flagship mobile phones.",(N/A),(N/A),(N/A),(N/A),www.gujinwei.org,(N/A),Cosmos World Foundation Models for Physical AI,English,Embodied AI,"NVIDIA Cosmos is a family of World Foundation Models specifically designed for physical AI. It includes three main components: Cosmos-Predict, Cosmos-Transfer, and Cosmos-Reason. In this talk, I will give an overview of Cosmos models, its development journey, benchmarking and evaluation, and various types of post-training of Cosmos models specifically targeting at applications to robotics and autonomous driving. I will demonstrate the effectiveness of using Cosmos World Foundation Models for Synthetic Data Generation (SDG), embodied AI, and other downstream tasks. ",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
67,白婷,baiting@bupt.edu.cn,北京邮电大学,副教授,"白婷，北京邮电大学计算机学院副教授，专注于个性化推荐、大模型研究及应用，以第一或者通讯作者发表高水平学术论文40余篇，包括4篇最佳论文/最佳论文候选奖，相关研究成果应用于腾讯、小米等头部互联网公司。获得2020年中国中文信息学会""优秀博士学位论文奖""，2023年中国电子学会""科技进步一等奖""，2023年百度首届""全球AI 华人女性青年学者"", 2024年中国科协青年托举人才。",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),AI个性化记忆操作系统的构建,Chinese,Apps & Agents,构建个性化智能体服务时，需适配垂域特性、保障交互个性化及内容可信合规。但传统通用智能体存在明显短板：难以精准贴合垂域知识体系，长交互中记忆易断裂，内容生成追溯困难。对此，我们构建了 “垂域适配 - 记忆管理 - 可信生成” 的个性化体系。核心模块 MemoryOS 作为首个开源记忆操作系统框架，深度融入知识与记忆管理环节，通过关联垂域知识图谱实现精准检索，可有效解决垂域智能体知识检索不精准、交互连贯性不足及个性化欠缺等问题。通过多模块协同，在确保内容可追溯、合规的基础上，借助优化记忆与知识管理，为垂域个性化AI应用提供了一套完整可复用的技术实践路径。,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
66,王超 （lukecwang）,sleepcoo@gmail.com,美团（meituan）,SGlang Committer,https://github.com/sleepcoo,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),SpecForge: Accelerating Speculative Decoding Training for SGLang,Chinese,SGLang Workshop,"Speculative decoding is a powerful technique for accelerating Large Language Model (LLM) inference. In this blog post, we are excited to announce the open-sourcing of SpecForge, our new training framework for Eagle3-based speculative decoding. SpecForge is designed for ease of use and is tightly integrated with the SGLang inference engine, enabling a seamless transition from training to deployment.",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
65,张拳石,zqs1022@sjtu.edu.cn,上海交通大学,副教授,"张拳石，上海交通大学电院计算机科学与工程系长聘副教授，博士生导师，入选国家级海外高层次人才引进计划，获ACM China新星奖。他于2014年获得日本东京大学博士学位，于2014-2018年在加州大学洛杉矶分校（UCLA）从事博士后研究。张拳石在神经网络可解释性方向取得了多项具有国际影响力的创新性成果。张拳石承担了TMLR的责任编辑，CCF-A类会议NeurIPS 2024的领域主席，IJCAI 2020和IJCAI 2021的可解释性方向的Tutorial，并先后担任了AAAI 2019, CVPR 2019, ICML 2021大会可解释性方向的分论坛主席。",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),神经网络是否可以被严谨地解释清楚？Scaling Law是否会成为大模型永远的桎梏,Chinese,AI Next,“模型可解释性的不足”和“Scaling Law的桎梏”是深度学习领域中两大瓶颈性问题，但是从内在机理层面却殊途同归地指向同一根因——对模型表征能力缺少根本性解释与建模。目前大部分可解释性研究依然停留在工程技术层面，无法在机理层面直接解释模型表征能力。张拳石团队所提出的基于等效交互可解释性理论体系，从机理层面部分解决了上述问题，证明了神经网络内在复杂表征逻辑可以被严谨且全面地概括为稀疏的交互概念，并基于交互概念可以充分解释神经网络的性能根因，从而跳出黑盒训练范式，有针对性地实时监控并修复模型表征缺陷，提升训练和测试效率，摆脱Scaling Law的桎梏。,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
64,潘万坤,panwankun@qiyi.com,爱奇艺,助理研究员,助理研究员,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),仓颉在鸿蒙应用：爱奇艺的应用开发实践,Chinese,Cangjie Workshop,本次分享将围绕仓颉语言在爱奇艺鸿蒙版应用中的实际落地展开，重点介绍如何利用仓颉语言的高性能特性构建高效的图片加载模块。通过剖析关键实现细节，包括互操作调用、内存管理、异步解码等优化手段，展示仓颉语言在提升系统响应速度与用户体验方面的价值，为鸿蒙开发提供新的实践思路。,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
63,Alexy Khrabrov ,alexy@chiefscientist.org,Neo4j,AI Community Architect ,"Alexy Khrabrov is the AI Community Architect at Neo4j, the category-defining Graph database company. Alexy is the founding Chair of Open-Source Science at NumFOCUS, and a cofounder of the AI Alliance. Alexy was the founding Chair of the Generative AI Commons at the Linux Foundation for AI and Data (LFAI) and now represents Neo4j at LFAI.  Alexy is the founder and organizer of Bay Area AI and AI Agent SF meetups, as well as the Scale/Data/AI By the Bay conferences, the independent OSS AI conference running since 2013.",@chiefscientist.org,(N/A),https://linkedin.com/in/chiefscientist,https://github.com/alexy,https://chiefscientist.org,@chiefscientist,OAKS ASKG: Agent-Server Knowledge Graph,English,Apps & Agents,"Oaks is the Open Agentic Knowledge Stack, an OSS AI project developed in collaboration with the AI Alliance partners.  It seeks to connect OSS components centered on Knowledge Graphs, including retrievers, RAG stores, and GraphRAG patterns.  OAKS collaborations are realized through developer relations, and partners include LangChain, LlamaIndex, Koyeb and others.

ASKG is an OAKS project developed by Neo4j and IBM collaborators.  The idea is to create a definitive knowledge graph of MCP servers with a derived ontology, that could be used by both humans and AIs to build data pipelines and applications.

ASKG consists of a data scraper that collects MCP servers definitions from registries like MCP.so and glama.ai.  It has an exploratory UI and sits on top of a Neo4j instance.  The dataset is modeled as a Pydantic schema that is loaded into Neo4j.  We support both local and cloud Neo4j instances.  

The project is now actively under active development in Bay Area AI and AWS hackathons, and we welcome both users and contributors.  ",(N/A),Accept,[object Object],1755711056867,proposal-hangzhou-accepted,"[object Object],[object Object],[object Object]",(N/A)
62,yanboyang,ybyang7@iflytek.com,SGlang,Committer,Responsible for the research and development of the Maas platform.,(N/A),(N/A),(N/A),whybeyoung,(N/A),(N/A),讯飞MaaS平台大模型高性能推理实践,Chinese,SGLang Workshop,讯飞基于开源引擎结合自身推理服务框架在PD分离上的相关技术介绍,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
61,Junrong Lin,ocss.lin@gmail.com,"Qwen Team, Alibaba Group",Member of Technical Staff,SGLang committer,(N/A),(N/A),(N/A),https://github.com/ocss884,(N/A),(N/A),Reasoning with SGLang: Powering Training in the Reinforcement Learning Era,Chinese,SGLang Workshop,"Enabling LLMs to improve their outputs with reinforcement learning and test-time scaling (TTS) is now a trendency, which leads to the adoption and unprecedented importance of inference engine in model training. In this presentation, we will go through the recent progress and community adoption in SGLang under RL scenerio.",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
60,Yuxuan Zhang,Yuxuan.Zhang@zhipuai.cn,ZhipuAI,技术布道师,智谱AI技术布道师,(N/A),(N/A),https://www.linkedin.com/in/yuxuan-zhang-86a124282/,https://github.com/zRzRzRzRzRzRzR,(N/A),(N/A),智谱AI模型介绍与开源生态,Chinese,AI Models & Infra,本次介绍将陈述2025年来智谱开源的模型，包括 GLM-4.5系列，GLM-4.1V系列，以及陈述智谱AI在模型开源上的工程与算法适配，社区合作模式。通过系统性阐述智谱AI开源模型的流程，让开发者熟悉大模型开源过程中的工程和算法难题，解决方案和工作方法。,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
59,Richard REINER,richard@richardreiner.com,Procero AI,Board Member and Advisor,"I am a serial entrepreneur and company builder with multiple Fortune 1000 exits, and a leading global cybersecurity expert who has held C-level and VP roles at leading global companies. I'm active as an executive, investor, mentor, and Board member with many high-growth companies at the intersections of cybersecurity, AI, and IoT, the same spaces in which I have built and successfully exited multiple companies and hold numerous patents.

I am Founding Partner at CC Stratus Capital, an innovative investment firm with a strategic focus on cybersecurity and AI.

I was Executive Chair of dfuse / StreamingFast, the leading blockchain big data platform (acquired by The Graph) and Chair of Cybeats, the IoT endpoint security company (acquired by Relay Medical). I was previously Chief Technology Officer - Safe Identity in Intel's Security Group, and VP Safe Identity at McAfee. I was President of PasswordBox, the leading digital identity company, leading up to the company’s acquisition by Intel. I was Chairman & CEO of Enomaly, a global leader in cloud computing, up to Enomaly’s acquisition in 2011; and was the founder, CEO, and CTO of Assurent, a leading cybersecurity company, up to its acquisition in 2006.

I serve and have served on the Boards and Advisory Boards of many leading cybersecurity, cloud, AI, and IoT companies such as Autohost, Korbit AI, Shearwater Aerospace, Immunio, Elliptic Technologies, Virima, CloudeAssurance, Veracode, NetClarity, Virima, and Fonolo.

I'm often quoted by the press, in media such as the New York Times, CBS, NBC, USA Today, TechCrunch, etc., and hold a Ph.D. and numerous patents in cybersecurity, big data, and AI.",(N/A),(N/A),https://www.linkedin.com/in/richardreiner/,(N/A),https://www.richardreiner.com/,(N/A),Bringing AI to the Edge with Dynamic Optimization,English,AI Models & Infra,"Today’s LLMs and other GenAI applications have the ability to transform work as we know it, offloading routine tasks and freeing humans to focus on the creative, high-value contributions.

But this amazing capability comes at a high cost. 

Nearly all of today’s LLMs run on huge server clusters in the cloud, consuming gigawatts of power. The environmental impact is vast, and  translates into high financial costs as well – cloud AI can cost from $1 to $5 per million tokens processed.
Meanwhile, we all have devices in our pockets and on our desks that have powerful, energy-sipping processors – just not powerful enough for AI.

This is where Procero comes in.  Our unique dynamic optimization technology enhances the capabilities of the processors in phones, laptops, and IoT devices, enabling them to run bigger AI models, faster.","This is not just the static model quantization, pruning, or distillation that many people are familiar with. Procero’s optimizations are dynamic, meaning they occur as the model runs, activating only the parts of a model required for a specific task. This comes from 10+ years of research in multiple PhD-led university teams, and from Procero’s deep roots in the world-leading AI research community here Montreal, home of Yoshua Bengio and the MILA Institute.

Procero is already in discussions with leading global companies, including a $100B semiconductor company, a $110B laptop and tablet OEM, a $30B semiconductor company, and a $25B laptop manufacturer, some of which are in China, to integrate our technology in their devices, and we’d love to present the technology at GOSIM Hangzhou 2025!
",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
58,陈玉龙,chenyl@csdn.net,开心武汉市科技有限公司,CSDN开新院副院长,CSDN开新院副院长,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),仓颉在智慧医疗平台的应用开发实践,English,Cangjie Workshop,"仓颉在智慧医疗平台的应用开发实践，介绍仓颉在医疗领域，开发智慧医疗平台的开发实践
",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
57,张昊阳,SunnyFiee@MindSpire.cn,东北大学,学生仓颉布道师,张昊阳，东北大学人工智能（未来实验班）专业本科生，东北大学花粉俱乐部部长，HarmonyOS开发者。曾获开放原子开源大赛OpenHarmony应用创新赛二等奖，带领MindSpire团队参加2024HarmonyOS创新赛和2024极客马拉松，用时两个月上架一款应用至HarmonyOS NEXT应用商店，并贡献一个CodeLabs，获得跑跑码特活动三等奖。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),仓颉在鸿蒙应用：逸课表的应用开发实践,Chinese,Cangjie Workshop,仓颉在鸿蒙应用：逸课表的应用开发实践，从一个学生开发者角度介绍仓颉使用体验,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
56,唯伟,3461805030@qq.com,有点艺思哦,bilibili知名绘画UP主,毕业于中央美术学院，从事审美教育和科普,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),AI绘画的未来方向,Chinese,AI Next,AI绘画当下的局限，它和人的思考根本差异是什么，未来会有哪些方向,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
55,Yikai Zhu,zyksir@outlook.com,N/A,Software Engineer,Current Sglang committer,(N/A),(N/A),https://www.linkedin.com/in/zyksir/,https://github.com/zyksir,https://zyksir.github.io/,(N/A),SpecForge: Open Source Framework For Training Speculative Decoding Models,English,SGLang Workshop,"Speculative decoding is a powerful technique for accelerating Large Language Model (LLM) inference. In this presentation, I am excited to announce the open-sourcing of SpecForge, a new training framework for Eagle3-based speculative decoding. SpecForge is designed for ease of use and is tightly integrated with the SGLang inference engine, enabling a seamless transition from training to deployment.","First, I will introduce what is Speculative decoding, And why it can accelerate LLM inference
Second, I will introduce EAGLE, which is the state-of-art speculative decoding method.
Third, I will introduce the framework of SpecForge, which contains online training mode and offline training mode.
Last, I will introduce the experiment result of model trained by SpecForge",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
54,刘南兵,liunb573@gmail.com,四川饺子互动科技有限公司,CTO,饺子互动科技联合创始人，5ire.app 作者，中文写作社区 essay.ink 发起人。,(N/A),(N/A),https://linkedin.com/in/nanbing,https://github.com/nanbingxyz,https://ironben.essay.ink,https://twitter.com/1ronben,5ire：一个开源 AI 项目的从零到一,Chinese,Apps & Agents,5ire 从一个简单想法出发，逐步走向开源、获得社区反馈并持续演进的过程。我们将回顾从产品设计、技术选型到快速构建 MVP 的关键节点，分享过程中遇到的问题与转折，以及我们如何重新理解 AI 应用的价值定位，找到与大模型能力的互补点。希望这段经历能为正在构思、验证或打磨产品的开发者，提供一些参考和启发。,"1. 初衷：从“解决自己问题”出发
	•   背景：当时面对什么痛点，促使动手做了第一张草图
	• 	起心动念：产品的内核是“被需要”，不是“炫技”；易用比复杂强大更稀缺
	•	核心理念：不是做个强大的 AI 工具，而是一个“真正能被日常使用的助手”
	•	设计原则：被需要 > 强大，易用 > 漂亮
	•	初始草图 + 原型思考

⸻

2. AI 应用的边界与价值：与大模型能力互补
	•	大模型越来越强，但用户的问题始终是具体的、场景化的。模型是底座，应用是桥梁。
	•	真正有价值的 AI 应用，是放大模型在特定任务中的能力。
	•	不是“一个聊天工具”，而是一个能够承载“具体目标”的 AI 助手

⸻

3. 技术选型：为全球化产品打基础
	•	为什么选择 Electron + React + FluentUi
    •   为什么没有选择通过  AI SDK 来集成大模型接口
	•	使用生态更成熟的技术方案让后续的开发/社区参与更容易

⸻

4. 快速构建 MVP，加入 Microsoft Startup Founder Hub
	•	快速构建出 MVP
	•	如何整理材料和讲述产品故事，顺利加入 Microsoft Startup Founder Hub，获得 Azure 赞助
	•	这个阶段验证了：“你愿意认真对待这个项目，它就愿意给你反馈”

⸻

5. 遇到瓶颈：不确定的未来与短暂停滞
	•	对产品方向的怀疑，不知道该怎么走
	•	对目标模糊、方向感弱，思考是否还要继续
	•	重要思考：一个产品是功能的叠加，还是一个长期愿景？

⸻

6. 转机：遇见 MCP 协议，打开产品边界
	•	偶然了解 MCP（Model Context Protocol），发现可产品的边界可被极大拓展
	•	产品从“做完”变成“开放”，构想开始清晰

⸻

7. 选择开源，真正与用户对话
	•	把代码开源，社区用户开始提 issue、反馈 bug，参与构建
	•	用户反馈，推动你思考什么才是真正被需要的功能
	•	从一个人写代码，变成社区共同打磨的产品

⸻

8. 对接资本：从产品故事中寻找信任
	•	与投资人交流的过程，重新梳理产品的价值定位
	•	拿到天使轮，不是因为“功能多”，而是因为“相信你会持续推动这件事”
	•	尝试用 Agent 满足企业的长尾需求，探索商业路径

⸻

结语：开源项目的生命力不来自热度，而是清晰的产品愿景
	•	回望过去，产品的成长不是一条线，而是一组节奏：看见问题、暂停、探索再重启
	•	关键在于：不断迭代“你想为谁解决什么问题”
	•	如果你也在构思或构建一个项目，也许不需要一开始就很“完整”，只要开始，它就会告诉你接下来怎么走",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
53,Guang Liu,liuguang@baai.ac.cn,BAAI,Technical Lead of Data Research Team,"Guang Liu is the Technical Lead of the Data Research Team at the Beijing Academy of Artificial Intelligence (BAAI), where he leads the OpenSeek initiative. As the principal architect of the Aquila large language model (LLM) series and the Infinity-Instruct dataset family. His current research focuses on DataAgent, leveraging innovative synthetic data generation techniques to optimize training efficiency for next-generation AI systems.",(N/A),(N/A),(N/A),(N/A),(N/A),https://x.com/ZacLiu123,OpenSeek: Open-Source Driven Next AI Models,English,AI Models & Infra,"OpenSeek aims to unite global open-source communities to collaboratively advance algorithms, data, and systems for next-generation models. In stage one, we released CCI4.0, OpenSeek-small, and OpenSeek-Pipeline, developed the DualPipe-V strategy in FlagScale, and launched a collaborative task with the PAZHOU Competition to support community contributions.","OpenSeek aims to unite global open-source communities to drive collaborative innovation in algorithms, data, and systems for the development of next-generation models. The initiative is organized into three dedicated working groups, focusing respectively on data, algorithms, and systems.
In the first stage, we successfully built and released several key components: the CCI4.0 dataset, the OpenSeek-small model, and the OpenSeek-Pipeline. Additionally, we developed the DualPipe-V parallel training strategy within the FlagScale framework.
Currently, we are collaborating with the PAZHOU Competition to host a challenge that encourages contributors to actively participate in the OpenSeek ecosystem. We are excited to share several new achievements in this next phase of development.",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
52,张懿/Yi Zhang,1109276519@qq.com,阿里云计算有限公司,研发工程师/software engineer,"张懿，阿里云的研发工程师，SGLang Team的成员之一，目前主要关注构建高性能的LLM/VLM推理引擎。

Yi Zhang, a Software Engineer at Alibaba Cloud and a member of the SGLang Team, is currently focused on building high-performance LLM/VLM inference engines.",(N/A),(N/A),https://www.linkedin.com/in/yizhang2077,https://github.com/yizhang2077,(N/A),(N/A),SGLang: 一个高效的开源大规模LLM服务框架 / SGLang: An Efficient Open-Source Framework for Large-Scale LLM Serving,Chinese,SGLang Workshop,"SGLang是一个高效的开源大规模LLM服务框架。在过去的一年中，SGLang经历了快速的迭代和发展，本次Talk将概括性地介绍SGLang的核心特性，主要包括：KV Cache重用, Zero-overhead批调度，投机采样，Prefill & Decode分离和大规模专家并行。

SGLang is an efficient open-source framework for large-scale LLM serving. Over the past year, SGLang has experienced rapid iteration and significant advancements. This presentation presents an overview of SGLang’s leading features, including KV Cache Reuse, Zero-overhead Batch Scheduling, Speculative Decoding, Prefill/Decode Disaggregation, and Large-scale Expert Parallelism.","Leading Features
1. Efficient KV Cache Reuse with RadixAttention
2. Zero-Overhead Batch Scheduler
3. Speculative Decoding & SpecForge
4. Prefill and Decoding Disaggregation
5. Large-scale Expert Parallelism",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
51,Shangming Cai (蔡尚铭),csmthu@gmail.com,Alibaba Cloud,Senior Engineer,"Shangming Cai received the Ph.D. degree in computer science from the Department of Computer Science and Technology, Tsinghua University, China, in 2022. He is currently an Engineer and Researcher with Alibaba Cloud Computing and an active contributor to open-source LLM projects such as SGLang, Mooncake, vLLM. His main research interests include distributed machine learning training, large language models, efficient serving systems, and big data analytics.",(N/A),(N/A),(N/A),https://github.com/ShangmingCai,(N/A),(N/A),SGLang Prefill/Decode Disaggregation with Mooncake,English,SGLang Workshop,"Large Language Model (LLM) inference comprises two distinct phases: Prefill and Decode. The Prefill phase is computation-intensive, processing the entire input sequence, while the Decode phase is memory-intensive, managing the Key-Value (KV) cache for token generation. Traditionally, these phases are handled within a unified engine, where combined scheduling of prefill and decode batches introduces inefficiencies. To address these challenges, we introduce Prefill and Decoding (PD) Disaggregation in SGLang, which enables tailored optimizations for each.

This presentation will introduce the implementation of Mooncake backend in detail, which is also the first integrated and default PD disaggregation backend of sglang. In addition to explaining the overall process, this talk will also detail how PD disaggregation works with features such as DP attention and MTP, and how to achieve different TP sizes for PD. Moreover, this talk will also introduce some of the work we have done in fault tolerance to ensure stable operation in a production environment.",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
50,José Andrés Muñoz Arcentales,joseandres.munoz@upm.es,Universidad Politécnica de Madrid,Associate Professor,Associate Professor of Universidad Politécnica de Madrid ,(N/A),(N/A),www.linkedin.com/in/anmunozx,(N/A),(N/A),(N/A),Self-Sovereign Identity and Trust Infrastructure for Agentic IA in Data Spaces,English,Agentic Web,"As artificial intelligence increasingly operates across distributed and dynamic environments, the need for robust, verifiable, and interoperable identity infrastructures becomes critical. This talk introduces an identity verification protocol designed for Data Spaces that aligns with the European Union’s vision for secure digital ecosystems. By combining the Grant Negotiation and Authorization Protocol (GNAP) with OpenID Connect for Verifiable Presentations (OIDC4VP), and supporting Linked Verifiable Presentations (LVP), this solution enables a secure and privacy-preserving identity framework that supports both human-centric and fully autonomous agent interactions.

The proposal leverages the principles of Self-Sovereign Identity (SSI) to decentralize identity control, reduce trust assumptions, and create machine-readable identity assertions. This talk will explore how this infrastructure empowers AI agents to operate securely within regulated environments, in line with the mandates of the EU Data Act and AI Act. We will discuss the technical design, interaction flows, and real-world applicability of the GNAP4VP protocol in supporting trust and sovereignty at the identity layer—paving the way for scalable, verifiable, and automated interactions between intelligent systems.
","This session begins by addressing the challenge of identity in the context of intelligent agents operating within decentralized data ecosystems. Traditional authentication models fall short in enabling autonomous systems to assert their identity and access rights without centralized intermediaries. In Data Spaces—collaborative environments envisioned by the EU Data Act for secure and interoperable data sharing—identity must be both verifiable and sovereign. This becomes even more relevant under the AI Act, where high-risk systems are required to demonstrate transparency, reliability, and traceability in their operations. Identity is foundational to achieving this.

We introduce GNAP4VP, a protocol that extends the GNAP authorization framework with verifiable credential support, offering native compatibility with Self-Sovereign Identity (SSI) principles. GNAP4VP defines two distinct interaction models. The first—Wallet-Driven Interaction—empowers human users to approve credential sharing via their digital wallets, enabling selective disclosure in data transactions. This flow is ideal for hybrid human-AI ecosystems, where humans remain in the loop during negotiation or consent.

The second model—LVP Authorization—is designed for fully autonomous, machine-to-machine scenarios. In this flow, intelligent agents use Linked Verifiable Presentations hosted in decentralized identifiers (DIDs) to assert their identity and capabilities. These agents negotiate access dynamically, authenticate using cryptographic proofs, and do so without human involvement, making the flow ideal for backend services, digital twins, or AI-driven bots that must operate within trusted data infrastructures.

Throughout the talk, we will highlight how this architecture facilitates interoperability, scalability, and flexibility—key technical pillars in the EU’s strategy for AI and data. Unlike static identity models, GNAP4VP supports dynamic negotiation, modular trust boundaries, and the ability to adapt to various assurance levels. As AI systems become agents in their own right—interacting with data marketplaces, governmental platforms, and industrial automation networks—such an identity layer becomes indispensable.

The talk will showcase how identity infrastructure is no longer a peripheral concern but a core element of intelligent, compliant, and future-proof digital infrastructure. This contributes directly to the vision for a single digital market built on openness, trust, and technological sovereignty.
As future work, we will explore integration with agent-to-agent (A2A) communication protocols and Multi-Channel Protocol (MCP) patterns to enhance decentralized orchestration and interoperability among intelligent systems. Furthermore, linking GNAP4VP with Linked Web Storage mechanisms from the Solid project opens pathways for agents to autonomously manage, access, and store personal or contextual data under user control. This combination reinforces the vision of fully sovereign, intelligent agents that can securely operate and collaborate within data spaces and beyond.
",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
49,xuan xia,xiaxuan@cuhk.edu.cn,Shenzhen Institute of Artificial Intelligence and Robotics for Society,Associate Researcher,"Xia Xuan, who holds a Ph.D. from Shanghai Jiao Tong University, is currently an associate researcher at the Shenzhen Institute of Artificial Intelligence and Robotics for Society. He is the principal investigator of the National Natural Science Foundation of China, a recipient of the 2024 Wu Wenjun Artificial Intelligence Science and Technology Award for Progress in Science and Technology, a high-level talent in Shenzhen, and a high-level talent in Longgang District, Shenzhen. His research mainly focuses on embodied intelligence, multimodal learning, computer vision, defect detection, and generative models. He has led projects funded by the National Natural Science Foundation of China, the Guangdong Provincial Natural Science Foundation, and the China Postdoctoral Science Foundation. He has also participated in numerous national, provincial, and municipal fund projects as well as several joint projects with enterprises. He has published a monograph and over twenty papers, and has applied for more than ten invention patents.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),AIRSPEED：用于具身智能的开源通用数据生产平台,Chinese,Embodied AI,随着全球机器人数量的爆发式增长，预计未来机器人市场规模将达到10万亿美元，而数据作为驱动机器人智能决策的核心资产，其价值不言而喻。然而，当前厂商的数据生产方式存在诸多痛点：数据采集与生成服务零散、不可持续，技术门槛高，成本高昂，且难以适应多样化场景需求。AIRSPEED精准定位这一市场空白，以通用数据生产平台为切入点，整合上下游资源，满足从基础软硬件开发商到具身智能应用商的全方位数据需求。AIRSPEED平台在技术架构与功能设计上展现出卓越的创新性与前瞻性。其采用ROS 2架构，确保分布式灵活部署，通过通用软件接口实现设备快速调通，兼容多种遥操作设备、机器人本体以及末端执行器，无论是VR遥操作、手柄遥操作，还是外骨骼控制，都能无缝衔接，实现对任意机器人形态的适配控制。在数据生成方面，AIRSPEED支持预测生成、轨迹合成、资产合成等多种功能，可依据用户需求生成任意操作轨迹、可交互资产以及智能体决策，为具身智能模型训练与算法优化提供丰富、高质量的数据资源。,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
48,Joaquin Salvachua,joaquin.salvachua@upm.es,Universidad Politecnica De Madrid,Professor,"Joaquín Salvachúa is a Professor at the Universidad Politécnica de Madrid, In the specializing in the Department of Telematics Systems Engineering at the Telecommunication School. He is a member of the board at Gaia-X Hub España, FIWARE and BDVA and active contributor in Gaia-X AISBL. and actively participates in research on ML-OPS, Big data architectures, cloud computing, next-generation internet technologies, network science and formal methods. Has authored numerous academic publications.",https://bsky.app/profile/jsalvachua.bsky.social,(N/A),https://www.linkedin.com/in/jsalvachua/,(N/A),https://portalcientifico.upm.es/es/ipublic/researcher/305315,https://x.com/jsalvachua,A data space definition language (DSDL) to enable interoperability between data spaces and enable the integration with the Agentic AI Ecosystem. ,English,Open for SDG,"The data space paradigm, which could potentially foster trust among players in the data economy, encounters challenges due to the fragmentation of diverse implementations. Moreover, establishing data spaces from scratch presents a complex undertaking.

Our Data Space Definition Language (DSDL), based on PDDL 2.1, facilitates the definition of workflows within each data space definition and facilitates the establishment of an interoperability schema for the available implementations.

We have developed a Data Space Agent (Eunomia Agent) capable of comprehending and generating this definition language. This agent facilitates interoperability with various implementations through a double stack for the data spaces protocol.

The agent provides a Multi-Channel Protocol (MCP) implementation that enables seamless interaction with Agentic AI in a nearly transparent manner. It also offers a basic A2A protocol implementation.

Furthermore, this language can be utilized to define data services (and generate implementations) that can interact with AI agents and become integral components of their workflows. ","We extend the PDDL 2.1 in order to be used to define data spaces implementations and interoperability. This lenguaje, and the agent we had implemented will be used to help to implement data spaces from scratch, help with the interoperability and help with the integration between data spaces, data services and Agentic AI (for example allowing an agent to train an ML model to make a numeric prediction). ",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
47,张引,zhangyin@mail.neu.edu.cn,东北大学,副教授,张引是传统大学计算机科学（CS）和软件工程（SE）课程改革的积极促进者，致力于利用仓颉编程语言、现代应用开发框架、MVVM + IService架构模式、微服务参考架构和人工智能服务等丰富技术资源，将各种CS/SE课程相互关联，设计高度集成的CS/SE教育课程。他为技术社区贡献了“仓颉社区软件工程”等一系列免费的在线课程，展现出将尖端技术整合到传统大学的CS/SE课程中的潜力和优势。他还在东北大学软件学院组织了学生开源社区“仓颉兴趣组”，为仓颉社区贡献了一系列开源项目，并将这些开源项目引入到课程中，促进课程内容与开源社区的紧密融合。在未来的工作中，他会将持续集成、容器化、大语言模型等丰富的华为技术引入到课程中，帮助学生更好地理解现代开发技术。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),仓颉在高校开源软件工程教学实践分享,Chinese,Cangjie Workshop,他还在东北大学软件学院组织了学生开源社区“仓颉兴趣组”，为仓颉社区贡献了一系列开源项目，并将这些开源项目引入到课程中，促进课程内容与开源社区的紧密融合,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
46,吴京润,jingrun.wu@wifiin.com,服务器应用架构师 ,北京初联科技有限公司,北京初联科技有限公司 服务器应用架构师,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),基于仓颉的服务器应用套件：Fountain的开发实践,Chinese,Cangjie Workshop,"fountain：一个仓颉服务器应用开发套件
议题简介：
1. 深刻利用仓颉语言特性
2. 宏与注解有机结合
3. 简单的初始化方式
4. 各种服务器开发的工具API",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
45,董鑫,sean.dong@huawei.com,华为,华为中央软件院项目群总监,2008-2017微软 技术leader 从事微软Azure企业云Dynamics365平台研发工作 2017- 华为技术有限公司 技术专家/产品总监 从事研发工具链，编程语言，IDE等核心基础软件研发工作。 在华为公司工作期间，先后作为首席技术专家和项目经理从事华为移动端AI研发工具，公司级AI研发平台，华为昇腾AI芯片工具链，鸿蒙OS工具链等相关工作。 2021年起负责华为编程语言和IDE基础软件的研发业务，并担任项目群总监，从事自主可控的编程语言及IDE开发工具的核心技术研发工作，对国产应用编程语言的技术规划，产品化，产业落地进展等工作出了重要的贡献,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),CangjieMagic：基于仓颉语言的 Agent 开发框架实践,Chinese,Apps & Agents,"整体介绍仓颉编程语言以及基于仓颉编程语言的AI大模型开发框架CangjieMagic，该框架支持向Agent编程，为开发者提供高效Agent编程的Agent DSL，支持MCP协议方便Agent和工具相互调用，支持模块化调用，支持任务智能规划。提升开发者开发智慧鸿蒙应用效率，打造极致开发体验，探索未来大模型应用开发新范式
",(N/A),Reject,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
44,王学智,tony.wangxuezhi@huawei.com,华为,华为仓颉编程语言生态与产业发展总监,王学智，华为仓颉编程语言生态与产业发展总监,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),仓颉编程语言生态建设进展介绍,Chinese,Cangjie Workshop,整体仓颉编程语言整体生态进展,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
43,Cen Ming,m_cen0104@sina.com,Chongqing University of Posts and Telecommunications,professor ,"Cen Ming received the Ph.D. degree in optical engineering from Graduate School of the Chinese Academy of Sciences, in 2006.
He is currently a professor at the Chongqing University of Posts and Telecommunications. During his career, he worked as a software system analyst and deputy director of Automotive Electronics &Embedded System Research Center.  His research interests include information fusion, multi-target tracking, autonomous driving, and intelligent robot.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Map Generation and Path Planning Approach for Unstructured Environments,Chinese,Embodied AI,"Ground-based autonomous platforms are increasingly utilized in fields such as disaster rescue, mineral mining, field inspection, and agricultural operations. Localization and mapping technologies are critical for these platforms. However, in unstructured environments, obstacles and non-traversable areas exhibit diverse types and intricate features. Existing mapping and path planning approaches designed for structured scenarios fail to perform effectively. Consequently, research on map generation and path planning methods for unstructured environments holds substantial research value.","To enhance the autonomous navigation and exploration capabilities of ground-based autonomous platforms in unstructured environments, a map generation and path planning approach for unstructured environments is introduced. 
A 3D mapping method based on lidar point cloud density analysis is proposed. The method consists of two stages, modelling and mapping. In modelling stage, the map model and the lidar density model are established. The map model contains geometric and spatial density characteristics of the terrain, and the lidar density model is used to represent the spatial density normalization coefficient of the point cloud. In mapping stage, the lidar point cloud data is preprocessed firstly. Then, the voxel grid point cloud density is calculated, and the spatial density representation is obtained by combining the density normalization coefficient. The step height feature is derived by calculating the height difference between adjacent voxel columns. A local terrain region segmentation strategy is adopted to fit planes in each region and extract slope and roughness attributes. The spatial density, step height and slope are combined to obtain a 3D map finally.
Considering that autonomous platforms with different specifications have different traversability capabilities, the off-road performance of the platforms are analyzed, and two indicators, maximum traversable slope and maximum obstacle crossing ability, are combined with 3D map to generate optimal paths that consider both efficiency and safety.
",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
42,张雨博,zhangyubo@openubmc.cn,openUBMC,openUBMC社区技术委员会委员,openUBMC社区技术委员会委员，为行业提供开源可立即商用的基础设施设备管理解决方案。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),基于openUBMC构建下一代AI基础设施智能设备管理平台,Chinese,AI Models & Infra,openUBMC是一款架构领先、开发友好、标准开放的算力设备开源管理软件，为AI基础设施提供了高效、灵活的智能设备管理能力。本次议题将分享如何利用openUBMC实现AI基础设施设备管理、智能化的故障预测与自愈，从而打造高性能、高可靠的AI基础设施管理平台，推动开源技术在企业级场景的深度落地。,(N/A),Accept,[object Object],1756083475734,proposal-hangzhou-accepted,"[object Object],[object Object]",(N/A)
41,尹云鹏,yinyunpeng@openloong.net,人形机器人上海有限公司,运控算法与框架负责人,openloong控制框架开发者,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),从格物到致知，具身智能机器人开发范式的改变,Chinese,Embodied AI,在具身智能与人形机器人交汇发展的大背景下，以数据学习、模型训练为核心的机器人开发范式革命悄然展开。国家地方共建人形机器人创新中心推出“格物-致知”通用机器人开发平台，提供机器人从高层算法模型训练、任务流编排到底层具身硬件配置的全流程开发能力，搭配国地中心全开源OpenLoong控制框架，一站完成异构本体适配、计算架构适配、仿真实机适配，加速具身智能场景应用落地。,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
40,tao li,litao@kaihong.com,"Shenzhen Kaihong Digital Industry Development Co., Ltd.",Software Engineer,"I'm a software engineer at Shenkaihong. Currently, I serve as the main developer for the OpenHarmony open-source robotics system project.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Robot Operating System Based on OpenHarmony,Chinese,Embodied AI,"Shenkaihong, in collaboration with industry and academia, is developing an open-source, full-scenario, and intelligent full-stack robot operating system based on OpenHarmony. This system targets various robotic application scenarios, including education, industrial automation, inspection, and service robotics.
Compared to traditional solutions using an Ubuntu-based system with ROS (Robot Operating System) middleware, our approach leverages OpenHarmony as the foundational system combined with the Dora robot middleware. This architecture offers significant advantages in security, controllability, trustworthiness, cloud-edge-device collaboration, and application development language paradigms. Additionally, it fosters an open ecosystem, facilitating open-source co-creation and accelerating commercialization.",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
39,Kaichao You,youkaichao@gmail.com,vLLM,Core Maintainer,"Kaichao gets Ph.D. degree from Tsinghua University, and has been working on the vLLM project since his visit to UC Berkeley in 2024. He serves as a core maintainer in the vLLM project, working on the distributed inference architecture of vLLM, torch.compile integration of vLLM, open-source collaboration, and various aspects.",(N/A),(N/A),https://www.linkedin.com/in/youkaichao/,https://github.com/youkaichao,https://youkaichao.github.io/,https://x.com/KaichaoYou,"vLLM: Easy, Fast, and Cheap LLM Serving for Everyone",English,AI Models & Infra,"vLLM is a fast and easy-to-use library for LLM inference and serving. In this talk, I will briefly introduce the evolution of the vLLM project, the open-source community behind it, and highlight some features that are interesting to many users.",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
38,Jingya Huang,jingya@huggingface.co,Hugging Face,Machine Learning Engineer,"I’m a machine learning engineer at Hugging Face and a core developer of *Optimum*, the extension library of Hugging Face’s *Transformers*. At Hugging Face, I focus on accelerating model training and efficient deployment, as well as integrating the Hugging Face open-source ecosystem with emerging AI hardware accelerators.",(N/A),(N/A),https://www.linkedin.com/in/jingya-huang-96158b15b/,https://github.com/JingyaHuang,(N/A),https://x.com/Jhuaplin,Hardware-Agnostic Acceleration of Open-Source Models with Hugging Face,English,AI Models & Infra,"In this talk, I’ll share how Hugging Face works with a wide range of AI hardware partners beyond just NVIDIA, to make open-source models in our ecosystem run smoothly across different platforms via Optimum. From training to deployment, the Optimum library helps bring flexibility and performance to AMD, Intel, AWS chips and more. I’ll walk through what we’ve learned along the way and how we’re making hardware-agnostic ML a reality.","Introduce the optimum library, and our strategy on fast training and deployment.

Maybe a demo of Chinese open-source model with the work mentioned beyond and some collab with Chinese community.

(The talk can be either in English or Chinese. I'm slightly more comfortable explaining the technical terms in English though.",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
37,王鹏伟,pwwang@baai.ac.cn,北京智源人工智能研究院,身智能大模型负责人,北京智源人工智能研究院具身智能大模型负责人、目前主要负责具身大脑大模型RoboBrain以及大小脑框架RoboOS，研究方向是具身智能、多模态大模型、深度学习、自然语言处理和机器学习等方向，曾就职于阿里巴巴达摩院以及快手科技大模型中台部门，主要负责大规模语音语义一体化等多模态交互系统以及多模态预训练项目，具有丰富的多模态大模型、文本大模型以及机器智能等产学经验。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),具身大小脑操作框架与具身大脑模型构建,Chinese,Embodied AI,智源研究院发布首个跨本体具身大小脑协作框架RoboOS与开源具身大脑RoboBrain，可实现跨场景多任务轻量化快速部署与跨本体协作，推动单机智能迈向群体智能，为构建具身智能开源统一生态加速场景应用提供底层技术支持，为主流本体提供一站式大小脑部署流程，提供即插即用解决方案。,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
36,Ruping Cen,cenruping@cqupt.edu.cn,Chongqing University of Posts and Telecommunications,Ph. D.,"Cen Ruping, Ph.D., is currently affiliated with the School of Automation at Chongqing University of Posts and Telecommunications, where his research focuses on mobile robot localization and navigation as well as multi-sensor fusion localization. Driven by his academic expertise, he created the open-source project MickRobot, which engineers a dual-arm humanoid robotics platform from the ground up, spanning mechanical design, hardware integration, perception/localization, and navigation control systems. Extending its impact beyond code, he has authored technical blogs and tutorials documenting this development journey, garnering over 1.1 million page views and demonstrating significant community reach.",(N/A),(N/A),(N/A),https://github.com/RuPingCen,https://blog.csdn.net/crp997576280?type=blog,(N/A),Application of the DORA-RS High-Performance Computing Framework in Embodied Robotics,Chinese,Embodied AI,This presentation introduces the intrinsic advantages of the dora-rs framework and its concrete applications across multiple embodied robotics platforms — exemplified by dora-rs-enabled grasping and sorting systems.,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
35,Xuan Son Nguyen,contact@ngxson.com,Hugging Face,Software Engineer,"I'm software engineer at Hugging Face, core maintainer of llama.cpp",@ngxson.hf.co‬,(N/A),https://linkedin.com/in/ngxson,https://github.com/ngxson,https://ngxson.com,@ngxson,Overhauling Multimodal Support in llama.cpp,English,AI Models & Infra,"This talk details a major upgrade to llama.cpp's multimodal support, integrating libmtmd for stability and unifying interfaces. Successfully implemented in May, it now supports models like Qwen VL, Mistral Small, Gemma 3 and enables community development of vision-enabled and audio-enabled applications.","My talk details the comprehensive overhaul and reintegration of multimodal support within the llama.cpp project and its server component, llama-server. Addressing prior API fragility, server instability, and fragmented model-specific CLIs, this work involved refactoring the core vision/audio encoder, introducing the libmtmd (lib multimodal) for a stable API, unifying disparate CLIs into llama-mtmd-cli, and integrating these enhancements into llama-server, despite its original non-text input design. Successfully merged in May, this development significantly enhances usability and enables support for prominent vision and audio models like Qwen VL, Mistral Small, Pixtral, and Gemma 3, allowing the open-source community to build multimodal-enabled applications on top of llama.cpp.",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
34,陈海泉,chenhaiquan@bytedance.com,ByteDance,Developer,Developer at Volcano Engine and core contributor to the veRL project. Focus on agentic RL and cloud infrastructure.,(N/A),(N/A),(N/A),https://github.com/chenhaiq,(N/A),(N/A),verl: 面向智能体任务的开源LLM强化学习框架,Chinese,AI Models & Infra,"verl 是字节跳动 Seed 团队开发的一款开源的 LLM 强化学习框架，适用于智能体任务，具备灵活扩展多种 RL 算法、无缝集成现有 LLM 基础设施、支持高效分布式计算和多场景应用等特点，且拥有活跃社区。
",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
33,Sébastien Crozet,sebcrozet@dimforge.com,Dimforge,Founder,"Sébastien Crozet has been in love with the Rust programming language since its earliest days. He is the creator and maintainer of popular open-source libraries, including nalgebra and Rapier, for the Rust ecosystem that specialize in linear algebra, geometry, and physics. He is the founder of Dimforge where he focuses on contributing to the future of cross-platform scientific computing and AI.",(N/A),(N/A),(N/A),https://github.com/dimforge,https://dimforge.com,(N/A),Single-source cross-platform GPU scientific computing with Slang and Rust,English,Select a Track (or Be Assigned),"With the new Slang initiative from Khronos, the path forward for cross-platform GPU scientific computing has never been brighter. We are showcasing our early results of using Slang from Rust for cross-platform single-source GPU LLM inference and physics.","This is the general breakdown of the talk:
- Why single-sources is important for maintainability, contributors accessibility, and future extension to more platform. Show how typical LLM frameworks (llama.cpp, candle) rely on per-platform kernel implementations which is difficult too expand, read, and maintain; and how most research work on other scientific domains are generally focused on CUDA or other specific platforms.
- Explain what is Slang (https://shader-slang.org/) the new initiative from Khronos.
- Explain the slmath ecosystem  (`minislang`, `slang-hal`, `slinalg`, `slml`).
- Show code snippets to show how a single shader gets converted transparently to other backends. Show how easy it is to switch backend. Show the `derive(Shader)` proc-macro.
- Demo with slml running segment-anything/llama LLM models.
- Physics demo.",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
32,Edgar Riba,EDGAR.RIBA@GMAIL.COM,Bonsai Robotics,Staff Research Engineer,"Dr. Edgar Riba earned his PhD in Computer Science from Universitat Autònoma de Barcelona (UAB)—where his dissertation bridged classical computer vision and deep learning for low-level tasks—and holds an MSc in Automatic Control and Robotics from UPC (Barcelona).

He recently joined Bonsai Robotics as a Staff Research Engineer, spearheading work in agentic AI and vision–language action models and tools tailored for educational and research robotics. Prior to this, Edgar built autonomy pipelines—from navigation stacks and robot drivers to edge‑ML deployment infrastructure—at startups including Farm‑ng, LightningAI, and Arraiy. His academic and research background includes over a year as a Research Scientist at IRI‑CSIC/UPC and more than two years at Arraiy, focusing on advanced vision and spatial AI.

Edgar is the founder and project lead of Kornia, a differentiable computer vision library for PyTorch with over 10,000 GitHub stars and 2 million+ monthly downloads. He also presides over its non-profit organization and is admin of Kornia’s Google Summer of Code program—mentoring students and coordinating major open-source contributions.

A dedicated community builder, Edgar served also on the OpenCV Foundation steering committee, mentors Google Summer of Code participants, and organizes workshops, hackathons, and conference talks. With eight peer-reviewed publications—including the foundational Kornia paper—he expertly bridges classical CV, deep learning, and real-world robotics to deliver robust, scalable autonomy solutions.
",(N/A),(N/A),https://www.linkedin.com/in/edgarriba/,https://github.com/edgarriba,(N/A),https://x.com/edgarriba," Amiga: A Modular, AI‑First Platform for Smart Farming and Outdoor Logistics",English,Embodied AI,"This talk presents Amiga, a next-generation rover platform, specifically designed for modular robotics in farming and outdoor logistics. Engineered for rapid prototyping and real-world deployment, Amiga enables customizable electric utility vehicles that streamline labor-intensive tasks, reduce costs, and support organic regenerative farming practices.

We begin by showcasing Amiga’s hardware and software modularity, highlighting interchangeable toolkits and actuation systems that support a broad spectrum of field applications—from soil analysis to autonomous harvesting. Through the SDK examples, attendees will see firsthand how Amiga’s developer tool—offer easy-to-use APIs and edge‑ML pipelines that power agentic AI and visual-language action models for dynamic environmental responsiveness.

Next, we explore Amiga’s tight integration with Dora-rs, a low-latency, dataflow-driven middleware that enables composable robotic pipelines. We’ll walk through shared-memory, zero-copy execution models using the Amiga-Dora bridge to orchestrate real-time perception-action loops driven by edge-deployed visual-language agents and dataset collections for fine tuning models.

Finally, the session introduces the Farm‑ng Robotics Challenge, an open competition designed to test Amiga’s resilience and developer adaptability in real-world agricultural conditions with a very vibrant community. We’ll share key performance metrics and lessons learned from recent field trials, demonstrating reliable autonomy and reproducible deployment at scale.
","- introduction to the platform
- offline demos of the Amiga SDK 
- details of the dora‑rs integrations
- discussion on dataset collection strategies and active fine-tuning of visual-language action models",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
31,Jian Shi,jian.shi@kaust.edu.sa,Kornia AI,Co-founder,"Jian Shi is the co-founder of Kornia AI and a core maintainer of the Kornia library, a leading computer vision framework in PyTorch. With Kornia AI, he works to advance and democratize spatial artificial intelligence through open collaboration. He is a Ph.D. candidate at KAUST, focusing on generative models and stereo vision. Jian has published at major venues including ICCV, ECCV, and TPAMI. With prior research experience at NEC Labs, CUHK, and GE Power, his work spans medical imaging, LiDAR understanding, and generative 3D vision.",(N/A),(N/A),https://www.linkedin.com/in/jian-shi-1ba543110/,https://github.com/shijianjian,(N/A),(N/A),Accessible Agentic Computer Vision with Kornia,English,Embodied AI,"This talk introduces a groundbreaking approach to computer vision that combines the power of Kornia's vision library with large language models to create an agentic computer vision system. We demonstrate how the Machine Control Protocol (MCP) can be leveraged to transform complex computer vision operations into natural language interactions, making advanced image/video processing accessible to users regardless of their programming expertise.","Computer vision technology has become increasingly powerful, yet its accessibility remains a significant challenge. While libraries like Kornia offer sophisticated image processing capabilities, they often require extensive programming knowledge, making them inaccessible to many potential users. Imagine being able to simply tell your computer, ""resize these medical images and enhance their contrast"" instead of writing complex code.

We present our work on agentic computer vision, a system that bridges the gap by combining Kornia's powerful vision library with large language models. We've created an intelligent interface that translates natural language instructions into precise computer vision operations. This isn't just a command-line wrapper. It is an AI-powered assistant that understands context, makes intelligent decisions about processing pipelines, and provides meaningful feedback.

After several showcasing examples with naive computer vision operators and AI models, we give a short intro to MCP and how natural language understanding drives computer vision operations. Next, we show the technical architecture connecting LLMs with Kornia through MCP. We then present real-world applications and practical demonstrations for non-tech users such as medical imaging researchers. In the end, we talk about future directions.

We expect our solution democratizes access to advanced computer vision capabilities. Non-tech users can experiment with complex image transformations without diving into technical documentation. Tech geeks can save themselves from laborious day-to-day boiler templates code.",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
30,李亚飞,yafei@dao42.com,深圳至简天成科技有限公司,ClackyAI CEO,ClackyAI创始人，全栈工程师，连续创业者,(N/A),(N/A),(N/A),windy,yafeilee.com,(N/A),L3 Agentic CDE：全球AICoding发展趋势分享,Chinese,Apps & Agents,分享一款全球最新的云端Agentic全栈开发环境，分享全球3大AIcoding发展浪潮及趋势,"分享一款全球最新的云端Agentic全栈开发环境
分享全球3大AICoding发展浪潮及趋势
分享
Agentic CDE 的架构设计与重点",Reject,[object Object],(N/A),(N/A),"[object Object],[object Object]",(N/A)
29,Salim Nahle,salim.nahle@efrei.fr,Efrei Paris, Program Manager “Data & Artificial Intelligence” and Academic Manager of Executive Education,"Dr. Salim Nahle is Program Manager “Data & Artificial Intelligence” and Academic Manager of Executive Education at Efrei Paris. He holds an engineering degree in telecommunications and computer science from the Lebanese University (2005), a Master’s degree in computer science from Paris VI – UMPC (2006), and a Ph.D. in computer science from Sorbonne University (2009). His doctoral research focused on wireless mesh networks using Wi-Fi and WiMAX technologies, addressing scheduling, routing, and quality of service. From 2011 to 2014, he worked as a software engineer at GE Healthcare on the “CT Revolution” project. Between 2014 and 2019, he served as Head of the Cybersecurity and Big Data Department at ECE, where he created the “Big Data & Analytics” and “Defensive Cybersecurity” specializations. Today, he leads academic innovation in AI, Data and cloud at Efrei as a program manager. He also develops and deploys continuous education and executive education programs for partner companies. ",(N/A),(N/A),https://www.linkedin.com/in/salim-nahle-03672571/,(N/A),(N/A),(N/A),Generative AI in education : Open source solutions and challenges. ,English,AI Vision Forum,"This talk explores the role of generative AI in education, with a focus on open-source solutions. It addresses key considerations for deploying AI tools, including cost, infrastructure, and deployment challenges. The presentation also covers Retrieval-Augmented Generation (RAG) and agent-based systems, with practical examples and a reflection on the specific challenges faced in open educational environments.","In this presentation, we will examine the potential of generative AI to transform educational environments, emphasizing open-source approaches. As institutions increasingly explore AI integration, it becomes essential to consider practical aspects such as cost management, data governance, and infrastructure scalability—especially when deploying on cloud platforms.

The session will highlight critical deployment questions, from model selection to data privacy, and the balance between control and ease of use in open-source frameworks. We will also compare architectures such as Retrieval-Augmented Generation (RAG) and agent-based systems, showcasing how they can support personalized learning and institutional workflows.

Special attention will be given to the unique challenges of deploying open-source AI in education, including limited technical capacity, fast-evolving ecosystems, and the complexity of maintaining up-to-date, secure, and pedagogically relevant systems. Real use cases  will illustrate the potential and limitations of these tools in real-world settings.

Ultimately, this talk aims to provide both strategic insight and hands-on considerations for educational leaders, developers, and researchers navigating the intersection of AI, open-source, and pedagogy.",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
28,吴其力,fochive00@gmail.com,ImitationGame,Founder,"年轻，激情，Geek。从前的 Web3 Dreamer, 现在的 Web3 Builder，未来的 Web3 Leader。",(N/A),(N/A),(N/A),https://github.com/simplexforce/,(N/A),http://x.com/SimplexForce,激励在 web3 项目中的角色 - 根治开源项目的可持续性问题的关键,Chinese,Agentic Web,大多 web3 项目都会用这样一堆词堆砌： 去中心，抗审查，数据主权，隐私，透明性，groundbreaking 等等。却很少说激励是怎么设计的。我在这里直言，这是很多 web3 项目的病根之一。我将分享激励为什么重要，什么的激励是好的，怎么解决开源项目的可持续问题，以及 AI 在这里面又是什么角色。,"## 简单的故事
前段时间，有位朋友找到我，询问我一起做项目的意愿。他告诉我他在瑞士苏黎世参加了一个线下会议，并且跟很多人聊到 web3 的 github 项目，跟他聊的人都很期待这样一个项目面世。 他找到了我，因为我在几个月前在一些社交媒体上发表过相关的内容。我跟他聊了一些，聊到他的想法、计划。他告诉我他没有想过 tokenomic，只是想做一个抗审查的 git server。

后面又邀请我一起参加一个 web3 world computer 的 hackaphon。然后其中项目评分的其中一条是 market/mobetization strategy 的设计，我问了他的看法，我说我有过很多思考但还没有正式整理。他这时候跟我说，他猜这一点并不是很重要，因为过度关注这个会影响一些创新的出现。他觉得不管怎么样，他做的是一个核心组件，迟早要做。我五分理解三分震撼两分担忧。

## 激励关键性的印证

### 比特币白皮书中的激励
bitcoin whitepaper 中，专门单独一个章节讲述 激励。
挖矿的奖励，早期加入收益，都是激励。激励使节点持续支持bitcoin网络，激励使节点遵守规则，因为 bitcoin 的底层通过对激励的设计，遵守规则收益更高。

### 区块链经济设计原则中的激励
“数字经济之父” Don Tapscott 在《区块链革命》这本书中提到的区块链经济七大设计原则：
网络诚信化，分布式权力，把价值作为激励，安全性，隐私，权利保护，包容性。
其它几个原则，大多项目都会注意到，但把价值作为激励，却大多没有做好。所以很多都发展得不好。

实际上这本书在 16 年出版的时候，已经描绘了各行各业经过区块链革命之后的美丽图景，每一个都直指问题的关键、解决的关键。现在过了将近十年，加密行业又发展了那么多年，web3 依旧没有走向大众，项目依然以泡沫为主。

### 齐国政治改良中的激励
邹忌讽齐王纳谏中
齐王下令：群臣吏民能面刺寡人之过者，受上赏；上书谏寡人者，受中赏；能谤讥于市朝，闻寡人之耳者，受下赏。
令初下，群臣进谏，门庭若市；数月之后，时时而间进；期年之后，虽欲言，无可进者。燕、赵、韩、魏闻之，皆朝于齐。
对谏言的激励，让齐国能够战胜于朝廷。

大自然中的激励
有一部非常值得看的纪录片 《绿色星球》。
在森林中，植物结出果实，动物受到果实的营养和美味吸引，同时传播种子。
物种多样是它的去中心的特点，大自然的各种协同和相互依赖，各种价值激励，驱动着生态系统的演进，维持着其中的动态平衡。
我们人的创造，实际上是一种模仿游戏 The Imitation Game （此处致敬一下图灵）。

## 什么样的激励是一个好的激励
到底什么样的激励是一个好的激励？ 好的激励，体现出来的是社区的 “正义“。
激励去做好事，是积极的风气。做好事得到激励，是理所应当的。

春秋时期，鲁国有一道法律，凡是在他国见到沦为奴隶的鲁国人，可以先垫钱赎回，回国报销。这是一项激励救助同胞的善政。子贡赎回鲁国人，却拒绝了补偿，孔子严厉批评了他。

破坏了规则与公平，打击了大多数人的积极性，损害了社会正义。

如果一件事情对社区有价值，但消耗个体的时间精力，却没有激励，这样一个社区是正义的吗？白吃白喝的、甚至黑客攻击，获得的收益远比做有益的事情要多，凭什么社区会能够持续更好发展？

## 为什么我想要做一个 web3 github，以及怎么根治开源项目的可持续问题。
从问题出发，现在的开源项目经常会面临可持续不足、缺少生命力的问题。
开源项目的仓库，通常会有一个 owner、maintainer，这其实可以理解为一种中心化，即使 owner 是善良的，但是怎么保证不会单点故障？ 我这个月搞一个开源项目，下个月出车祸人走了，谁维护下去？ 我对这个项目兴趣淡了、被其它项目吸引了兴趣，谁又继续下去？所以很多项目很容易就 ""死"" 去。

我曾有过很多开源项目，我觉得 idea 都挺好，因为各种原因，最后的 ”死“ 了。

所以这一个 web3 github 是我给出的答案。激励，Token-Driven。
1.  应该激励别人提 issue，无论是 roadmap 讨论、bug 反馈、提需求，都是一个对项目有益的行为，项目方不应该白嫖，而且这样被动等待反馈也没有积极性也没有效率。需要像齐王下令激励进谏一样。
2.  处理 bug 会获得激励。我举个例子，很多没人维护的项目，却可能会有很多项目依赖它，然后issue 遍地 open 没有人解决。这里应该要有一个类似奖池累积的机制。但是又要小心谨慎，因为如果这个累积机制促成了开发者刻意放任等待累积，这里就会出现一个“恶“的激励。
3. Idea 提出，白皮书编写，商业计划补充，开发路线制定，代码 review, 为项目宣传，融资，等等，甚至作为用户的使用行为，都看作是一种对项目的贡献，都应该受到激励。
4. 由于 Token-Driven，实现更高的自动化程度。价值以 token 形式显式流动体现透明性。
5. 自举：这个 web3 github 的第一个里程碑将会是这个项目托管在它本身这个平台。同时这样让项目方本身又作为这个项目的用户，还能促进对用户体验的关注。
6. 托管在这个 web3 github 上的项目，将会获得这个 web3 github 的 token，根据项目活跃度、影响力进行分配。同时促进去中心程度。同时平台又分得一部分项目的 token，类似于风投，也是一部分收益来源。

## AI 在其中会扮演什么角色
激励数值的评定是其中最困难的问题之一。
AI 可以从中充当一个更加客观无情的调解者。当然也需要遵循 Human in the loop 的原则，当人还是有异议最终还要能够提出复审，这里面可能又会上升到更大范围的 DAO 决策。",Reject,[object Object],(N/A),(N/A),"[object Object],[object Object]",(N/A)
27,Yikai Zhu,zyksir@outlook.com,Baseten,"Software Engineer, Model Performance","SGLang committer, Previously worked in QWen Team for pretraining infra,",(N/A),(N/A),https://www.linkedin.com/in/zyksir?originalSubdomain=cn,https://github.com/zyksir/,https://zyksir.github.io/,@zyksir995,EAGLE3 Training,English,SGLang Workshop,How to training EAGLE3 for large models.,"about how to modify EAGLE official code to train draft model for large target models
- How to make sure every modification is correct in training case
- training optimization
- some other tips about training and finetuning",Hold,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
26,Shuangrui Chen,chenshuangrui@gmail.com,Huawei Technology Ltd.,Senior Engineer,"👨‍💻 Senior Engineer at Huawei | 🤖 AI Agent Expert
🎓 MSc in Machine Learning, University College London (UCL)
🧠 Specializing in multi-agent systems, model orchestration, and autonomous task execution
🚀 Project Lead of Nexent, an open-source agent platform enabling zero-code multimodal services
🌍 Passionate about connecting data, models, and tools to build truly usable intelligent systems",(N/A),(N/A),https://www.linkedin.com/in/shuangrui-chen,https://github.com/Phinease,(N/A),(N/A),如何用AI制造AI，智能体如何与世界交互,English,Apps & Agents,"在智能体时代，""用AI制造AI"" 正逐步成为现实。本次分享以开源平台 Nexent 为例，探讨如何通过自然语言描述，自动生成具备多模态能力的智能体，并实现与真实世界的数据、工具与用户交互。我们将展示：

- 如何使用大模型自己创造Agent;
- 智能体如何零代码生成并组合LLM、视觉模型、搜索引擎等能力；
- 知识可追溯、多模态理解、实时数据处理对Agent的意义是什么；
- 如何构建可扩展、可落地的AI系统。

通过深入解析Nexent的“从描述到智能体”的自动生成路径，以及其在工具选型、协作调度、交互方式和知识管理上的架构设计，本次演讲旨在帮助你：

理解“用AI造AI”的实现方法；
看到AI智能体如何与现实世界（用户、数据、知识）进行多维交互；
掌握构建可复用、可扩展、可解释AI系统的核心思路。

这不仅是技术的演进，更是AI应用方式的范式转变。欢迎对“如何用AI制造AI”本质和未来路径充满好奇的开发者、研究者与产品人共同参与，让我们一起探索下一个AI智能体时代。",(N/A),Accept,[object Object],1755759281729,proposal-hangzhou-accepted,"[object Object],[object Object],[object Object]",(N/A)
25,Yin Zhenxi,279875564@qq.com,Chaitin Tech,"Technical Director, AI Coding Products","Yin Zhenxi, technical director of AI Coding Products at Chaitin Tech and security researcher, graduated from Pennsylvania State University (Penn State), USA，with extensive experience in real-world offensive and defensive engagements. He has assisted multiple enterprises in building Robust security measures.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),MonkeyCode-Open-Source AI code assistant ,Chinese,Apps & Agents,"This talk focuses on the productivity revolution in AI - driven programming, with a focus on the practical path of MonkeyCode. It deeply dissects the complete workflow from demand - sensing to solution implementation. We'll explain how to leverage large language models to break through the bottlenecks of traditional coding. Real - world experiences in enhancing efficiency and optimizing processes using AI Coding in project development will be shared. Additionally, we'll explore the iterative directions of collaboration models within technical teams driven by AI. This presentation aims to show developers new possibilities for improving programming efficiency in the intelligent era and help the audience grasp the key practical points of AI - empowered R & D.","Project Introduction, Comparison with Similar Products, and Demonstration of Core Advantages
Features and Demonstration of AI Coding
Demonstration of Secure Coding and Fixing Capabilities
Future Development Models and Cooperation Models of the Project",Accept,[object Object],1755581017463,proposal-hangzhou-accepted,"[object Object],[object Object],[object Object]",(N/A)
24,Xavier Tao,tao.xavier@outlook.com,1ms.ai,Founder,"Founder of 1ms.ai, which is a startup that aim at building moonshot open source project in AI. 

One of those project is dora-rs which is a groundbreaking middleware that is able to share data between AI models, sensors and actuators with state of the art performance.

This enables to build very complex applications across modality: text, audio, vision and action. This has enabled us to create very complex robotic demos!",(N/A),(N/A),https://www.linkedin.com/in/haixuan-xavier-tao-7460b1102/,https://github.com/haixuanTao,(N/A),https://x.com/HaixuanT,Mixing of multi modal AI model to solve complex robotic task with dora-rs,English,Embodied AI,"Lately transformers model has enable groundbreaking result in many complex predicitive task, that now make some of the challenging task in robotics accesible.

In this talk, we're going to highlight what models has been decisive in robotics as well as their current limitation.

Hopefully, by the end of this talk, you'll be inspired on how to tackle this problem or build on top of those models for your own projects!",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
23,Zhiyu Li,lizy@iaar.ac.cn,"MemTensor (Shanghai) Technology Co., Ltd.",CTO,"Zhiyu Li, Ph.D., is the Co-founder and CTO of MemTensor (Shanghai) Technology Co., Ltd., Researcher at IAAR, and Industry Young Scientist at the SAI, Shanghai Jiao Tong University. His research focuses on large language models (LLMs) and Generative AI, particularly in Memory-Augmented Intelligence and Infrastructure for GAI. Dr. Li previously led core AI teams at Alibaba and Xiaohongshu, driving algorithmic innovations that generated billions in commercial revenue. At MemTensor, he led  the world’s first Memory Operating System for LLMs (MemOS). He has published over 40 papers in top AI venues including Patterns (Cell Press), ICLR, ACL, and AAAI, with over 1,000 citations and 10+ patents. His work has been featured as a cover story in MIT Technology Review.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),智能始于记忆：打造基于MemOS的记忆管理新范式,Chinese,Apps & Agents,"当前的大模型系统虽具备强大的生成与推理能力，但长期以来缺乏“记忆”的支撑，导致知识无法持续积累、上下文难以长期保持，幻觉和逻辑断裂频繁发生。MemOS（Memory Operating System）是面向大模型的首个工业级记忆操作系统，旨在为智能系统提供统一的记忆管理底座。

本次演讲将围绕“智能始于记忆”的核心理念，介绍 MemOS 的系统架构与开源进展，分享如何通过动态知识注入、分层记忆调度和跨模型记忆迁移，建立面向大模型的新一代记忆管理范式。演讲将结合行业应用场景的实际案例，探讨如何用 MemOS推动大模型更低成本、更高效、更可信地落地行业场景，迈向长期智能与可持续演化。",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
22,Zeming Zhao,zeming.zhao@gmail.com,WiseFlow (AI Chief Intelligence Officer),Founder and CEO,"Founder and CEO of WiseFlow (AI Chief Intelligence Officer)
Former HTC Viverse product/project leader
Former Senior Business Manager of NetEase Artificial Intelligence Division",(N/A),(N/A),(N/A),https://github.com/bigbrother666sh,(N/A),https://x.com/bigbrother666sh,From a dozen yogurts during the lockdown - AI assistant grassroots governance of Chinese residential areas,Chinese,AI Next,"As an engineer who has always been engaged in cutting-edge technology, I never thought that grassroots governance had anything to do with me. But in this chaos, I was invited to use technology to help provide solutions. The first problem I faced was to solve the distribution problem of a dozen yogurts... and from then on, I embarked on a wonderful path that continues to this day.","So far, I can be called one of the most practical pioneers in this field in China. Over the past three years, I have been invited as an external technical expert to participate in the construction of grassroots autonomous digitization solutions in several streets and towns in Shanghai, as well as to provide technical advice for the relevant work of Jing'an District Data Bureau, Social Work Department, and Jinan Public Security Bureau. Of course, most of the above work is based on the booming LLMs.",New,[object Object],(N/A),(N/A),[object Object],(N/A)
21,Paul Yang,paul@run.house,Runhouse,ML Infra,"Currently, Paul is working at Runhouse to build Kubetorch, a Kubernetes-native ML packaging and deployment system for iterable development at scale. Previously, he has worked at another startup acquired by Databricks that built an AI/ML platform, and also has experience as a practitioner across ML and causal inference. ",(N/A),(N/A),https://www.linkedin.com/in/paul-yang-54460aa6/,(N/A),(N/A),(N/A),Beat OpenAI and Build the Best AI For You: Mobilizing First-Party Data with Fine-Tuning,English,AI Models & Infra,"In late 2022, there was an alluring promise that large models can do everything - just prompt a sufficiently large model to solve your AI problem. But after two years of GenAI experimentation, it's clear that even the largest models still fall short for many use cases on quality, speed, cost, or reliability. Enter small language models (SLMs), distillation, and parameter-efficient fine-tuning - with these approaches, nimble, purpose-built models fine-tuned on first-party data to excel at specific use cases. In this talk, we'll give a concrete framework for thinking about fine-tuning and when it's necessary. Then, we will show how combining modern open-source fine-tuning libraries has made fine-tuning more accessible than ever before.",Gave this talk at PyTorch Day in Paris - https://www.youtube.com/watch?v=NPJtRqs90qo&list=PL_lsbAsL_o2DBxQBRA5SoqnTL_inXCOLU&index=12,Accept,[object Object],1756083511183,proposal-hangzhou-accepted,"[object Object],[object Object]",(N/A)
20,Paul Yang,paul@run.house,Runhouse,ML Infra,"Currently, Paul is working at Runhouse to build Kubetorch, a Kubernetes-native ML packaging and deployment system for iterable development at scale. Previously, he has worked at another startup acquired by Databricks that built an AI/ML platform, and also has experience as a practitioner across ML and causal inference. ",(N/A),(N/A),https://www.linkedin.com/in/paul-yang-54460aa6/,(N/A),(N/A),(N/A),Just What Is an ML Platform?,English,AI Models & Infra,"Platform engineering is the standardized, scalable set of tools and infrastructure that enables development teams to self-serve building, deploying, and maintaining software. But what does that look like for AI/ML teams? Companies are grappling with the challenge of architecting robust platforms that accommodate use cases from traditional ML to generative AI. This talk will explore the historical evolution of ML platforms, to document the lessons learned from a decade of evolution starting from the first reference platforms at 2014 Google and Facebook. Specifically, we highlight what makes ML development different from software development, and the traps that teams fall into trying to bridge the gap. Finally, we distill our learnings to offer a clear prescription for the requirements of a successful and effective AI and ML platform.",(N/A),Reject,[object Object],(N/A),(N/A),[object Object],(N/A)
19,Paul,Yang,Runhouse,ML Infra,"Currently, Paul is working at Runhouse to build Kubetorch, a Kubernetes-native ML packaging and deployment system for iterable development at scale. Previously, he has worked at another startup acquired by Databricks that built an AI/ML platform, and also has experience as a practitioner across ML and causal inference. ",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Implementing Fault Tolerance for ML Workloads at Scale,English,AI Models & Infra,"From training and tuning LLMs to mobilizing large vision datasets, training workloads have become significantly heavier in recent years. Distributed training with DDP or FSDP is widely adopted to enable training larger models over more batches of data without exploding the time it takes to run an experiment or recurring production. However, there are plenty of everyday pains as more teams tackle the issue of distributed training. Trainings have to be babied to avoid OOMs on a single replica, node failures are common on long-running workloads, spot instances are functionally unusable, and even finding the availability of N nodes of the same GPU on-demand can be challenging. In this talk, we will explore how real-world application TorchFT alongside other solutions can drive significant cost savings, reduce iteration time, and save ML engineers from gray hairs. ","This talk will highlight: 
-Common faults for at-scale distributed workloads (driver crashes, GPU failures, OOMs, etc.) 
-How to use libraries like TorchFT to handle the faults
-How to use driver programs to handle the faults
-How to configure infrastructure to handle the faults",Reject,[object Object],(N/A),(N/A),[object Object],(N/A)
18,Guofeng  Zhang,zhanggf@shanghaiopen.org.cn,Shanghai Open Source Information Technology Association,Founder,上海开源信息技术协会创始人，上海对外经贸大学开源创新与数字治理研究院院长。2013年开始开源、区块链教学及理论研究工作，2015-2018年组织多场开源、区块链社区活动。2018年发起成立上海开源信息技术协会，2020年11月组织编写并发布《中国开源创新社会工程宣言书》，2023年5月在上海对外经贸大学推动设立开源创新与数字治理微专业，2025年4月组织编著的开源领导干部读本《开源前沿课》由人民日报出版社出版。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),"开源创新国际合作示范区设想与实施Concept and Implementation of an Open-Source Innovation International Cooperation Demonstration Zone""",English,Select a Track (or Be Assigned),"开源的核心是制度创新，无论是美国、欧盟还是中国，开源的障碍都是各自国内数千年以来基于物理世界独占排他属性所形成的传统思想、文化、价值观及规则体系。另外，世界各国在发展数字经济及数字化转型过程中，迫切需要安全可靠的数字公共产品及服务，这远超传统基于地域空间所建立的现有国际组织体系所管辖的范畴，需要新技术、新思维、新模式，更需要更广泛的国际合作。
本演讲将介绍开源创新国际合作示范区的战略设想、实施路径、现状与问题。","1.开源创新国际合作问题的提出
2.开源创新国际合作的内容、必要性及重大意义
3.开源创新国际合作示范区战略构想、远景及使命
4.开源创新国际合作实施路径、现状与问题",Accept,[object Object],1756137488616,proposal-hangzhou-accepted,"[object Object],[object Object],[object Object]",null
17,Chenglong Li,chenglong.li@zilliz.com,Zilliz,Chief Open Source Engineer,"Li Chenglong, Chief Open Source Engineer at Zilliz / Head of the Milvus Open Source Community, and Committer of Milvus, the world's most popular open source vector database. He graduated from the Department of Computer Science at Xi'an Jiaotong University. After joining Zilliz, he has been active in the Milvus community and has assisted thousands of open source users worldwide in jointly exploring AI implementation solutions. He has extensive experience in mainstream Computer Vision algorithms, Embedding algorithms, LLMs applications, and RAG architectures, and has successively completed cases such as the Milvus image search system and video retrieval system. As a senior developer ecosystem evangelist in the Milvus open source technology community, he has been focusing on community technology sharing and evangelism for many years, helping tens of thousands of developers understand and use the Milvus vector database.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),Vector Database - Infrastructure for the AI Era,Chinese,AI Models & Infra,"With AI's rise, data is embedded as vectors and stored in vector databases—key to AI infrastructure. This session introduces vector DB basics, Milvus architecture and advantages, and common use cases.","With the advent of the AI era, massive amounts of data are encoded into vectors through AI models and stored in vector databases, which have become the infrastructure of the AI era. This sharing session will introduce the basic concepts of vector databases, the design architecture and core advantages of Milvus, a globally leading vector database, as well as the classic scenarios of vector databases. ",Reject,[object Object],(N/A),(N/A),[object Object],(N/A)
16,Matt White,matt.white@linuxfoundation.org,Linux Foundation/PyTorch Foundation,GM of AI/Executive Director,"Matt White is the Executive Director of the PyTorch Foundation and GM of AI at the Linux Foundation, as well as the Director of the Generative AI Commons under the LF AI & Data Foundation. With nearly 30 years of experience in AI research, standards, and applications across telecom, media, and gaming, he has specialized since 2012 in machine learning, simulations, and multi-sensory learning. He previously co-founded the Open Metaverse Foundation, chairs the Metaverse Standards Forum, and co-organizes both the Silicon Valley Generative AI paper reading group and the GenAI Collective.",(N/A),(N/A),https://www.linkedin.com/in/mdwdata,matthew-d-white,(N/A),matthew-d-white,How to be Successful with Open Source AI,English,Open for SDG,"Explore how to navigate the complexities of open source AI, including AI-specific licenses like OpenMDW, building strong communities, fostering vendor neutrality, and adopting open standards like Model Context Protocol and Agent to Agent Protocol to reduce barriers and enable agent-based AI collaboration.","As artificial intelligence (AI) continues to advance at an unprecedented pace, the open source AI ecosystem plays a critical role in driving innovation, collaboration, and the democratization of technology. However, the open-source landscape for AI presents unique challenges, particularly with the application of traditional software licenses like MIT and Apache 2.0, which were not designed to address the complexities of AI models, their usage, and their intellectual property.

This talk explores how to navigate the complexities of open source AI licensing and governance, focusing on emerging solutions like OpenMDW, an open source model development and deployment framework. We will delve into how OpenMDW, alongside other AI-specific licenses, helps clarify the usage and distribution rights for AI models, and why traditional open-source licenses are ill-suited for the dynamic, rapidly evolving nature of AI technologies.

In addition, we will discuss the importance of building a vibrant and sustainable community around open source AI projects. A strong community not only accelerates innovation but ensures the long-term success and ethical development of AI technologies. Successful open-source AI projects rely on the engagement of diverse contributors, transparent governance, and a shared vision that promotes collaboration across industries and disciplines.

Central to the long-term success of open-source AI is the concept of vendor neutrality. Ensuring that AI projects are not tethered to any single vendor allows them to remain independent, ensuring their relevance and adaptability in an ever-changing technology landscape. We will also address the critical need for open standards in AI, particularly around agentic frameworks like the Model Context Protocol (MCP) and the Agent to Agent Protocol (A2A), which reduce integration friction and improve the interoperability of AI systems. By adopting open standards, we can reduce barriers to entry, foster innovation, and enable more effective collaboration across diverse AI ecosystems.

Through case studies and real-world examples, this talk will provide insights into how open source AI projects can thrive, the challenges they face, and how they can navigate the evolving legal, technical, and community landscapes to create lasting impact in the AI field.",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
15,Xiaohu Zhu,xhzhu.nju@gmail.com,Center for Safe AGI,Founder,A Safe AGI Researcher,@xiaohuzhu.bsky.social,(N/A),https://www.linkedin.com/in/xiaohu-zhu-97686637/,http://github.com/tigerneil/,https://xiaohuzhu.xyz,@neil_csagi,Open Safe Superintelligence: Aligning Power with Collective Safety,English,AI Vision Forum,"The development of superintelligent AI systems—entities that surpass human capabilities across a wide range of cognitive domains—is no longer a distant theoretical possibility, but a rapidly approaching technological frontier. As we accelerate toward this threshold, the central question becomes not if we will build superintelligence, but how we will ensure it is safe, aligned, and open to oversight. This talk introduces the framework of Open Safe Superintelligence (OSSI)—a research and governance paradigm designed to ensure that the most powerful systems ever created serve humanity’s long-term interests.

This talk invites the research and policy community to converge on a shared vision: superintelligence that is safe, interpretable, and governed through openness and collective foresight. OSSI is not a utopian ideal—it is a pragmatic, security-oriented blueprint for a future we can survive and thrive in. ","The development of superintelligent AI systems—entities that surpass human capabilities across a wide range of cognitive domains—is no longer a distant theoretical possibility, but a rapidly approaching technological frontier. As we accelerate toward this threshold, the central question becomes not if we will build superintelligence, but how we will ensure it is safe, aligned, and open to oversight. This talk introduces the framework of Open Safe Superintelligence (OSSI)—a research and governance paradigm designed to ensure that the most powerful systems ever created serve humanity’s long-term interests.

At the heart of OSSI is a paradox: we must build systems that are vastly more capable than ourselves, while maintaining control, interpretability, and trust. Traditional closed models—shrouded in proprietary secrecy or national security constraints—are misaligned with this goal. They concentrate power, incentivize arms races, and increase the risk of catastrophic failure modes, including misalignment, misuse, or unrecoverable deployment. OSSI proposes a radical but grounded alternative: openness not in the sense of unfettered access, but of verifiability, accountability, and global cooperative security.

The talk unfolds in three parts:

Foundations of Safe Superintelligence: We present a structured definition of superintelligence rooted in capability thresholds, goal pursuit, and recursive self-improvement. Drawing from recent advances in mechanistic interpretability, formal verification, and reinforcement learning from human feedback, we explore the technical requirements for safe planning and corrigibility at superhuman scales. We argue that safety must be a first-class citizen of system design, not a post-hoc patch.

Openness as a Safety Mechanism: We analyze the strategic benefits and security challenges of open models. Using historical and analogical examples—from cryptography to nuclear nonproliferation—we highlight how transparent protocols and cooperative audits can create a foundation of trust and resilience. OSSI proposes global standards for open interpretability interfaces, reproducible evaluations, and safety-critical red-teaming conducted across institutional borders. We discuss how controlled openness enables distributed stewardship, reducing risks of both centralized failure and uncontrolled diffusion.

Governance for OSSI: Finally, we outline a governance architecture for OSSI, integrating ideas from constitutional AI, multi-stakeholder oversight, and cryptographic model attestation. We describe emerging institutions—such as alignment labs, safety accelerators, and AI watchdog coalitions—that could anchor an OSSI ecosystem. Importantly, we address the geopolitical challenge: OSSI is only viable if it can align incentives across competing actors. We introduce the concept of “incentive-aligned transparency”—where openness becomes a game-theoretic equilibrium rather than a liability.",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
14,Jason Song,songyi@ggsn.com,"DHForce, GuoGuangShunNeng Energy Technology, Shanghai",Co-Founder/AI Tech Lead,"Co-Founder of DHForce, AI Tech Lead",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),DHForce Intelligence: An energy AI agent and the road we've been through,Chinese,Apps & Agents,"1. Introduction: what're we and what we do now.
2. Why : why we turn into AI's track? 
3. How: how to make AI as part of business scenario?
4. What: what's our long-term objective? 
5. Words of experience: some insights on building AI Agents",(N/A),Reject,[object Object],(N/A),(N/A),"[object Object],[object Object]",(N/A)
13,张云飞,zhangyf80@chinatelecom.cn,中电信数智科技有限公司,中国电信智慧城市研究院副院长，中国电信首席专家,中国电信智慧城市研究院副院长，中国电信首席专家，教授级高级工程师，国家级人才计划特聘专家，交通运输部中青年领军人才、国际公路交通科技领军人才，5G产业方阵副理事长，中国通信标准化协会物联网委员会副主席，曾任腾讯未来网络实验室主任，腾讯智慧交通首席科学家。提出泛V2X技术体系和实践，在业界形成广泛影响。在IETF 创立P2P流媒体协议（PPSP）工作组并担任主席，在IETF、ITU-T等发布10多个国际标准。获得中华杰出工程师青年奖、国家专利银奖、国家标准奖、上海市技术发明一等奖、上海市科技进步奖一等奖、深圳市科技进步一等奖、金桥奖个人奖、中国车联网杰出人物奖、IEEE ITSC智慧交通和车路协同双冠军等省部级以上奖励20多项。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A), 超越现有范式：面向后数字时代AI生态系统的RVP协议,Chinese,Agentic Web,"随着AI技术迈入新纪元，传统数字化架构的局限性日益凸显。本次演讲将介绍革命性的RVP（Reality-Virtualization-Perception）协议，这是面向后数字时代设计的全新AI生态系统架构。演讲将深入解析RVP协议的三大核心：现实层的多源数据融合、虚拟化层的数字孪生技术、以及感知层的多模态AI能力整合。重点阐述该协议如何突破现有技术瓶颈，实现跨域协同、自适应进化的智能网络。通过智慧城市、自动驾驶、工业互联网等实际应用案例，展示RVP协议在解决数据孤岛、算力分散、模型割裂等关键问题上的独特优势。演讲还将探讨该协议的标准化路径与产业化前景。
作为下一代AI基础设施的技术蓝图，RVP协议代表着从工具化AI向生态化AI的根本转变。本演讲将为与会者提供前瞻性的技术洞察，共同探索人工智能的未来发展方向，推动产业数字化转型的深度变革。",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
12,常高伟,chgaowei@gmail.com,ANP开源技术社区,发起人,常高伟，ANP开源技术社区发起人，W3C AI Agent protocol CG联合主席，AgentNetworkProtocol(ANP)是全球最早发布的开源智能体通信协议，ANP的目标是成为智能体互联网时代的HTTP，ANP的愿景是定义智能体之间的连接方式，为数十亿智能体构建一个开放、安全、高效的协作网络。,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),智能体协议：引领互联网迈向 Agentic Web 时代,Chinese,Agentic Web,随着大模型技术的发展，智能体（Agent）正逐步成为互联网的核心参与者。本次演讲梳理了从语义网到Agentic Web的技术演进，提出构建标准化智能体网络协议的紧迫性与必要性。我们总结出Agentic Web的四大关键趋势：智能体替代传统软件、实现普遍互联、以协议为核心连接方式，以及具备自主协作能力。同时，本文指出当前互联网在接口、协作和数据孤岛等方面对智能体发展构成阻碍。为解决上述挑战，我们提出了智能体网络协议的设计原则与功能需求，并比较分析了MCP、A2A、ACP与ANP等主流协议。呼吁全球开发者与标准化组织共同推动智能体协议标准的制定，构建开放、高效、可信的Agentic Web。,(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
11,张敏,zhangmin3@chinatelecom.cn,中电信数智科技有限公司,资深专家,张敏，博士，高级工程师，研究方向集中在大数据及人工智能技术应用领域,(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),智慧城市新突破：RVP协议驱动程式智能体虚实协同,Chinese,Apps & Agents,"现代智慧城市需要物理IoT传感器、自动驾驶车辆、数字孪生和虚拟城市管理智
 能体间的无缝协调。传统的MCP和ANP协议无法处理城市场景中复杂的虚实映射关系。RVP协议引入异构通信框架，使交通信号灯能与虚拟交通优化智能体协调，应急救援机器人可
 与数字孪生灾害模拟系统同步，市民服务聊天机器人能连接物理基础设施传感器。本演讲将展示RVP在智能交通、能源网格管理和公共安全协调系统中的实际应用，揭示其如何革
 新传统城市管理和服务模式。",后续更新,Reject,[object Object],(N/A),(N/A),"[object Object],[object Object]",(N/A)
10,Shiwei Liu,s.liu3@tue.nl,University of Oxford,Newton International Fellow,"Shiwei Liu is a Royal Society Newton International Fellow at the University of Oxford. He previously served as a Postdoctoral Fellow at the University of Texas at Austin. He obtained his Ph.D. with Cum Laude from Eindhoven University of Technology in 2022. His research goal is to leverage, understand, and expand the role of low-dimentionanlity in neural networks for scalable and efficient AI. Dr. Liu has received two Rising Star Awards from KAUST and the Conference on Parsimony and Learning (CPAL). His Ph.D. thesis received the 2023 Best Dissertation Award from Informatics Europe.",(N/A),(N/A),(N/A),(N/A),https://shiweiliuiiiiiii.github.io/,(N/A),The Curse of Depth in Large Language Models,English,AI Next,"Large Language Models (LLMs) have demonstrated impressive achievements. However, recent research has shown that their deeper layers often contribute minimally, with effectiveness diminishing as layer depth increases. This pattern presents significant opportunities for model compression. In the first part of this seminar, we will explore how this phenomenon can be harnessed for efficient LLM inference. Despite these opportunities, the underutilization of deeper layers leads to inefficiencies, wasting resources that could be better used to enhance model performance. The second part of the talk will address the root cause of this ineffectiveness in deeper layers and propose a solution. We identify the issue as stemming from the prevalent use of Pre-Layer Normalization (Pre-LN) and introduce LayerNorm Scaling (LNS) to solve this issue. Our results demonstrate that LNS enables deeper layers to contribute more effectively with more diverse representations, yielding stronger pre-trained models with improved potential for downstream adaptation.",(N/A),Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
9,Ruoyu Ying,ruoyu.ying@intel.com,Intel,Cloud Software Engineer,"Ruoyu Ying is a cloud software engineer from department of STG, Intel. She used to worked on ONAP , networking, service mesh, confidential computing in different communities. GenAI Enablement on Cloud-Native Infrastructure is now one of her main focus. She also participated in the composition of the white paper and book on edge computing. And later she successfully delivered several presentations in OpenInfra and KubeCon summits.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),"Accelerating Enterprise AI Adoption: A Practical Path to Low-Cost, High-Efficiency, Seamless Integration",Chinese,Apps & Agents,"As Generative AI gains momentum across industries, enterprises are eager to harness its potential to enhance productivity and user experience. However, bringing AI into production environments remains challenging—especially under constraints of limited resources, tight budgets, and the complexity of integrating with existing enterprise systems. The key question today is: how can enterprises deploy AI faster, with lower cost, minimal disruption and even leverage their existing infrastructure?
This session introduces our open-source enterprise AI platform OPEA that enables enterprise to quickly build, deploy, and validate AI applications tailored to their needs. We'll walk through the project’s core architecture, modular design, and cloud-native deployment model, and show how it simplifies AI integration in real-world enterprise environments. In addition, we'll explore how OPEA integrates with InfiniEdge AI’s SPEAR project to support on-demand agent orchestration and cross-domain collaboration across cloud, edge, and device. A case study will demonstrate how the these technologies can be combined to implement a real-time voice assistant, showcasing the platform’s practical impact on enterprise AI transformation.",(N/A),Hold,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
8,Aurélien-Morgan CLAUDON,aurelien_claudon@yahoo.fr,Unaffiliated,Senior MLOps Lead,"French ML Engineer with 20+ years of hands-on experience in automation and data-driven delivery. Former Capgemini consultant, with big corp, startup, and freelance experience. An ESSEC Executive MBA graduate, he has been active in the ML space since 2017, with a sharp focus on MLOps for the past 5+ years. His work blends engineering pragmatism with deep product thinking.
He is the creator of `retrain-pipelines` (Apache 2), an open-source framework designed from first principles to address the MLOps field’s chronic lack of user-centricity. His mission: to empower ML Engineers with practical, scalable tools for continuous learning workflows.",(N/A),(N/A),https://www.linkedin.com/in/aurelienmorganclaudon/,https://github.com/aurelienmorgan/retrain-pipelines,https://huggingface.co/blog/Aurelien-Morgan/the-almighty-function-caller,https://x.com/AurelienMorgan_,Industrializing Continuous Learning: Building Retrainable Pipelines for tailored LLMs,English,AI Models & Infra,"Continuous learning is critical for production self-hosted LLMs, yet most enterprises struggle with automated retraining. We introduce a streamlined framework for retraining of pluggable domain adapters, LoRA specialization, and value-rich infra features.","Continuous learning for LLMs in production environments requires a systematic approach that distinguishes between different types of training. The talk will:

  - Present a complete end-to-end continuous learning system using `Unsloth` to optimize Qwen3-1.7B, progressing through all retraining phases
  - Showcase how CPT enables domain adaptation through unlabeled data, thus acquiring domain-specific knowledge
  - Illustrate how SFT builds upon CPT results to develop specific capabilities like function calling from newly extended intrinsic knowledge bank of thousands of tools, leading to a tool-calling expert LoRa adapter like no other
  - Highlight the framework's runtime-generated pipeline-cards that document each phase's configuration and results
  - Explain how multi-LoRA deployment enables flexible serving of agentic systems, by having one base model and possibly a constellation of task-expert LoRa adapters, all being served at once
  - Detail the benefits of leveraging the Hugging Face infrastructure as one comprehensive option for artifacts management and versioning throughout the continuous learning lifecycle.
  - Showcase the model inspector interface that enables quick navigation across model versions and performance metrics
  - Through a practical example, attendees will see how to operationalize continuous learning on LLMs. We'll focus on equipping ML Engineers with actionable ideas. The talk will conclude with implementation guidance for enterprise MLOps teams.

This matters for the Open-Source ecosystem as this framework addresses three key needs:
  - Democratizing MLOps: Simplifies continuous learning for indie developers and teams of all sizes
  - Accelerating Innovation: Speeds iteration from experiment to deployment
  - Sustainable Scaling: Enables specialization without full retraining

Format: 30' Talk with demo (pipeline cards + multi-LoRA inference).
Code/Resources: GitHub repository and blog post will be shared via QR code.

FYI : I was one of the volunteers at GOSIM Paris this year. Loved doing it.",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)
7,Yifei Sheng,api.privoce@gmail.com,Privoce,Software Engineer,"Yifei (Will) is currently a software engineer at Privoce, Inc. Yifei is the author of the GenUI framework.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),"GenUI, from declarative UI to generative UI",Chinese,AI Next,"GenUI is an innovative SFP front-end framework developed in the Rust language, was originally inspired by Vue3 and Makepad. Intended to help users write front-end projects using Rust more efficiently. With the help of LLMs, users can easily generate front-end based on GenUI.

","This talk will show how LLM generate a UI based on GenUI Components. GenUI Builtin Components is a Makepad component library that can be directly integrated into Makepad projects. As the core component library of GenUI, it can be used as the basic building block of GenUI projects to accelerate the development process of front-end developers. 

",Reject,[object Object],(N/A),(N/A),"[object Object],[object Object]",(N/A)
6,Wayne Gao,wayne.gao1@solidigm.com,Solidigm,Principle storage solution architect,"Wayne Gao is a Principal Engineer as Storage solution architect and worked on CSAL from PF to Alibaba commercial release. Wayne also takes main developer effort to finish CSAL pmem/DSA and cxl.mem PF from intel to Solidigm. Before joining Intel, Wayne has over 20 years of storage developer experience as previous DellEMC PowerScale Sr Principal software engineer in all flash object storage team and has 4 US patent filings/grants and 1 EuroSys2024 paper published. Wayne also have working experience at Alibaba as P8 engineer and build across network and connections with PRC enterprise storage and cloud storage developers. During spare time, Wayne like to play badminton, swimming, movies, and games.",(N/A),(N/A),(N/A),(N/A),(N/A),(N/A),BlueField-3 and Solidigm joint new AI storage stack for inference ,Chinese,AI Models & Infra,"CSAL is Cloud Storage Acceleration Layer for BigData and AI. it is open-source user mode FTL, cache and io trace component to accelerate AI and BigData storage system inside SPDK(upstreamed). It commercially helps Alibaba cloud storage system. 
refer https://www.solidigm.com/products/technology/cloud-storage-acceleration-layer-write-shaping-csal.html for basic understanding. 
Alibaba and Solidigm joint top computer conference paper Eurosys2024 https://dl.acm.org/doi/pdf/10.1145/3627703.3629566
BlueField-3 team and Solidigm SW work closely to define best AI inference network storage stack and infra. we will show the detail design for this.","Session Topics:
This session we will introduce below new progress and features that is joint development with NVIDIA DPU team and BeeGFS
1. CSAL NVMeOF offload feature on BlueField-3 disaggregated design.
2. QLC high density storage is favorable by AI industry since it save power and space for AI Data Center. BlueField-3 storage solution can achieve same thing; it is great combine two things together for end user to get best TCO with much more power and space saving.
3. CSAL deployed in DPU to bring advanced storage IO shaping, caching and data placement SW into BlueField-3 storage SW service, CSAL as software define cache, shaping and user mode FTL, we can tune storage for vLLM and VectorDB etc.
5. share CSAL 2026 other features progress from storage side
6. BlueField and CSAL perf experiment data sharing and report",Reject,[object Object],(N/A),(N/A),"[object Object],[object Object]",(N/A)
5,Chris Yang,api.privoce@gmail.com,Privoce,VP of Engineering,"Chris Yang is a core engineer at Privoce, Inc., now working on an open-sourced rust written Matrix server known as Palpo. Chris is also the author and main contributor of a most popular Rust web server named Salvo.",(N/A),(N/A),(N/A),https://github.com/chrislearn,(N/A),(N/A),"Palpo, an open-sourced Matrix server written in Rust.",English,Select a Track (or Be Assigned),"Palpo is a cutting-edge chat server written in Rust and supporting Matrix protocol and PostgreSQL database, aiming to deliver high performance, scalability, and robust federation capabilities. With Palpo, we aspire to redefine decentralized communication—providing real-time messaging and collaboration at minimal operational cost. We welcome open-source contributors and all kinds of help!

","High-Performance Rust Core
Based Salvo web server, Palpo leverages Rust’s safety and concurrency model, enabling a low-overhead server that is both fast and reliable.

Open Ecosystem
Portions of our code reference or derive inspiration from the excellent work in palpo and conduit. By building atop established open-source projects, we aim for compatibility and rapid iteration.

Federation & Standards
Palpo implements the Matrix protocol to ensure full interoperability with other Matrix homeservers, facilitating a truly decentralized network of real-time communication.

Demo Server

URL: https://matrix.palpo.im
To test quickly, open Cinny and use https://matrix.palpo.im as your custom homeserver.",Reject,[object Object],(N/A),(N/A),"[object Object],[object Object]",(N/A)
4,Loong Dai,long0dai@foxmail.com,Dapr,Maintainer,"Microsoft MVP, engaged in the cloud native industry for many years, have participated in the whole process of microservice splitting, development and governance, and have contact with the upstream and downstream needs of the microservice field.
Deeply cultivating open source, made a lot of contributions to many cloud native projects, have a unique understanding of the contribution and maintenance governance of open source communities. Currently, I am the maintainer of Dapr, Thanos, and Golangci-lint.
Now I mainly focus on the field of AI Agent.",(N/A),(N/A),(N/A),daixiang0,(N/A),(N/A),What's next AI native runtime,Chinese,AI Models & Infra,"In the era of digital transformation, distributed application runtime serves as the essential infrastructure for constructing large - scale, highly available application systems, while large language models (LLM) endow applications with powerful intelligent interaction and data processing capabilities. This paper focuses on exploring the seamless integration of LLM within the Dapr environment, aiming to optimize the application development process and revolutionize the user interaction experience through innovations like AI Agents and intelligent recommendations. By presenting real - world cases, it showcases the immense potential and innovative practices that arise from the convergence of these two key technologies, providing valuable insights for the development of the next - generation AI native application runtime.","- What is the application runtime and why we need it
- How to implement AI native runtime
- How AI native runtime help devlopment",Reject,[object Object],(N/A),(N/A),"[object Object],[object Object]",(N/A)
3,Baihuidong,3291191@qq.com,Beijing Elesec Co. Ltd.,CEO,"2、	在IT行业26年，从程序员，PM，架构师到技术副总，2003年规划并带队实现过中国电信集团覆盖全网的22个省公司加集团的综合性信息管理支撑系统，曾完整规划了武汉绿网公司的专利等技术资产，四个月内帮该公司规划了73项发明专利，制定了公司研发管理过程构建，曾经从零开始构建了一支跨越六个子公司的研发管理团队，十多年前就曾在电信集团负责全国八个开发商的管理和协调工作，曾为绿网筹建一支机器学习团队。
3、	用九年时间积累并独立撰写了一本技术专著《软件工程之全程建模实现》，分别于2004年（电子工业出版社）和2010年（机械工业出版社）出版，成为国内UML建模领域方法论的主要推动者之一。
4、	创立的软件企业可度量绩效管理模型可以解决企业中软件开发人员的工作绩效量化问题，曾在灵动进行了绩效管理量化的推进解决了以往绩效评估中的很多争议，此前在武汉绿网进行了10个月的数据采集。该方法全称为抽象化劳动的量化研究体系，目前考虑在这几个维度中推进：可度量绩效管理模型，软件项目量化模型，量化部门管理模型，企业量化生产率模型。该方法的早期版本被厦大管理学院的博士全文抄袭到其2012年的博士学位论文中，2014年在网络上发酵，如果不是因为她对我进行辱骂（诬陷我是她举报的厦大管理学院院长的走狗），我本无意参与这件事情，但后来南方系厦门站发表了对她的采访，我不得已为了名声出来与之PK，并在次年应厦大管理学院和研究生院的邀请（厦大出费用），到厦大管理学院进行了一次现场学术辩论，与六个博导和六个厦大领导针锋相对的讨论了2个多小时，至今厦大都没有给我任何答复。但因为工作忙碌，加上公司暂时还不需要宣传，这件事情被暂时搁置，随时可以启用。
5、	在行业软件、互联网/移动互联网产品设计和研发上都有着十年以上的经验。
6、	已经申请五个发明专利，三个实审，其中一个申请的同名实用新型专利已授权。2009和2011年曾申请两个实用新型专利。此前负责绿网的专利管理和战略布局，绿网我接手前12年只有3个获批和3个待批发明专利，接手后5个月内形成了73个发明专利的筛选，我给绿网撰写并署名的发明专利完成6项的提交，属于着眼于5到10年后的dpi产品方向的技术实现战略规划思考成果，其中5个获得授权。",(N/A),(N/A),tsingrun,tsingrun,blog.csdn.net/qingrun,tsingrun,跨物种的语言通信技术——谈AI应用于传感器实现动物语言解析的可能,Chinese,Select a Track (or Be Assigned),"经过9年的产品设计和数据积累分析，实现了动物穿戴产品设计三原则的提出与第一批产品的落地。
经过对动物语言的深入研究，首次提出了地球动物语言三次突变假说，该假说有着分子形态学指标和相应的化石证据，并定义了拟态语言，一次语言和二次语言的概念，后两种语言的定义，确定了动物语言和人类高级语言之间的递进关系。一方面恪守了达尔文进化论的突变原理，也强调了拉马克用进废退理论在语言进化中的重大意义。
传感器的发展奠定了进行动物细节行为数据采集的可能性，确认了动物语言和行为之间的联系。","经过9年的产品设计和数据积累分析，实现了动物穿戴产品设计三原则的提出与第一批产品的落地。
针对动物行为数据的采集和分析，发现了动物行为和动物语言之间的关系。
经过对动物语言的深入研究，首次提出了地球动物语言三次突变假说（相关论文已经提交），该假说有着分子形态学指标和相应的化石证据，并定义了拟态语言，一次语言和二次语言的概念，尤其是后两种语言的定义，确定了动物语言和人类高级语言之间的递进关系。一方面恪守了达尔文进化论中的进化与基因突变原理，也遵守了拉马克用进废退理论在语言进化中的重大意义和作用。
而近年来的微型传感器的发展奠定了进行动物细节行为数据采集的可能性，同时，让我们发现并确认了动物语言和行为之间的必然联系，使得通过环境，行为细节与结果结合动物发出和听到的声音，进行动物语言解析的可行性，并已经经过了初步的论证。
",Reject,[object Object],(N/A),(N/A),"[object Object],[object Object]",(N/A)
2,Wilson Wang,wilsonny371@gmail.com,ByteDance Inc.,SW Engineer,"Software Engineer at ByteDance’s Global Edge Team, specializing in Virtual Machines and WebAssembly. I have a strong interest in operating systems, distributed systems, cloud-native technologies, edge computing, and serverless architecture.",(N/A),(N/A),https://www.linkedin.com/in/wilson-wang/,https://github.com/wilsonwang371,(N/A),(N/A),SPEAR - A Scalable and Distributed AI Agents Framework Across Edge and Cloud,Chinese,Apps & Agents,"SPEAR is a next‑generation open‑source framework under the LF Edge InfiniEdge AI umbrella. Designed for flexible and scalable AI agent workloads, SPEAR enables execution across various runtimes—from local processes and Docker containers today, to planned support for WebAssembly and Kubernetes. SPEAR empowers developers to build intelligent agents with customizable capabilities and future-ready extensibility for edge‑centric applications.",(N/A),Accept,[object Object],1755580619200,proposal-hangzhou-accepted,"[object Object],[object Object],[object Object]",(N/A)
1,Florian Hönicke,florian.hoenicke@jina.ai,Jina AI,Founding Engineer,"Florian has more than 10 years of experience in the Field of AI, working at Axel-Springer, Deloitte, and SoundCloud. He works as a Founding Engineer at Jina AI, rapidly prototyping AI solutions. His expert domain is Agentic Search and synthetic data generation. Florian is serving as an AI policy advisor, providing explanations and insights to members of the European Parliament to enhance their understanding of artificial intelligence.",(N/A),(N/A),https://www.linkedin.com/in/florian-h%C3%B6nicke-b902b6aa/,https://github.com/florian-hoenicke,https://jina.ai/,https://x.com/florianhoenicke,Size Bias in Text Embeddings: Visualization and Impact on Search,English,Apps & Agents,Longer texts inflate cosine similarity; CISI demos expose the bias and show asymmetric encoding + hybrid reranking to fix it.,"Embedding-based search often surfaces long, off-topic documents simply because length inflates similarity scores. In this 30-minute session I’ll: Define size bias and its real-world impact on relevance. Walk through CISI experiments: Document vs. sentence embeddings. Concatenated-document tests. Cosine histograms and statistical summaries. Analyze causes: why longer texts “spread” over semantic space. Evaluate mitigation: asymmetric query/passage encoding in jina-embeddings-v3, reranker normalization, and LLM-based re-scoring. Best practices: hybrid pipelines, task-specific thresholds, and when to ditch cosine cut-offs. You’ll leave with clear, hands-on guidance for building more reliable embedding search at scale.",Accept,[object Object],(N/A),(N/A),"[object Object],[object Object],[object Object]",(N/A)